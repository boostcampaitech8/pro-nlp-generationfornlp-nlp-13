{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b908c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from datasets import load_dataset, Dataset\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "\n",
    "src_parent_path = \"/data/ephemeral/pro-nlp-generationfornlp-nlp-13/\"\n",
    "if src_parent_path not in sys.path:\n",
    "    sys.path.append(src_parent_path)\n",
    "\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b80db227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Optional, Tuple, Union, Callable\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "import faiss\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "class HybridRetriever:\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        # 공통\n",
    "        self.model = BGEM3FlagModel(model_name,  use_fp16=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # self.current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        # sparse 관련\n",
    "\n",
    "        self.bm25 = None\n",
    "        # pickle_name = \"wikipedia_sparse_vecs.pkl\"\n",
    "        # bm_path = os.path.join(self.current_dir, pickle_name)\n",
    "\n",
    "        # if os.path.isfile(bm_path):\n",
    "        #     print(\"피클 찾음!\")\n",
    "        #     with open(bm_path, \"rb\") as file:\n",
    "        #         self.bm25 = pickle.load(file)\n",
    "        #         self.set_data()\n",
    "        #     print(f\"Sparse Embedding (BM25) loaded: {pickle_name}\")     \n",
    "\n",
    "        # dense 관련\n",
    "\n",
    "\n",
    "    def get_sparse_embedding(self) -> None:\n",
    "        pickle_name = \"wikipedia_sparse_vecs.pkl\"\n",
    "\n",
    "        bm_path = os.path.join(self.data_path, pickle_name)\n",
    "\n",
    "        if os.path.isfile(bm_path):\n",
    "            with open(bm_path, \"rb\") as file:\n",
    "                self.bm25 = pickle.load(file)\n",
    "                self.set_data()\n",
    "            print(f\"Sparse Embedding (BM25) loaded: {pickle_name}\")     \n",
    "        else:\n",
    "            print(\"피클 파일 빌드부터 하세요.\")\n",
    "\n",
    "        \n",
    "    def _compute_sparse_score(q_dict, d_dict):\n",
    "        \"\"\"두 딕셔너리 간의 가중치 곱 합산\"\"\"\n",
    "        score = 0\n",
    "        for token, weight in q_dict.items():\n",
    "            if token in d_dict:\n",
    "                score += weight * d_dict[token]\n",
    "        return score\n",
    "    \n",
    "    \n",
    "    def retrieve_sparse(self, query_text, k=5, topk: Optional[int] = 5, n_jobs: Optional[int] = None):\n",
    "        # 질문에서 sparse 가중치 추출\n",
    "        query_output = self.model.encode([query_text], return_dense=False, return_sparse=True)\n",
    "        query_sparse = query_output['lexical_weights'][0]\n",
    "\n",
    "        # 전체 sparse_vecs에 대해 점수 계산 (List Comprehension으로 속도 확보)\n",
    "        all_scores = [self._compute_sparse_score(query_sparse, d_vec) for d_vec in self.bm25]\n",
    "        \n",
    "        # 상위 k개 인덱스 추출\n",
    "        top_indices = np.argsort(all_scores)[::-1][:k]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'index': idx,\n",
    "                'score': all_scores[idx],\n",
    "                'title': self.df_meta.iloc[idx]['title'],\n",
    "                'text': self.df_meta.iloc[idx]['text']\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "\n",
    "    def retrive_dense(self,     \n",
    "                    question_df: pd.DataFrame,  # 원본 데이터셋 (df4)\n",
    "                    meta_df: pd.DataFrame,      # 검색 대상 문서 (df)\n",
    "                    index: faiss.Index,         # FAISS 인덱스\n",
    "                    n: int = 10,                # 샘플링 개수 (전체를 하려면 len(df4) 넣으면 됨)\n",
    "                    k: int = 5,                 # Top-K (몇 배로 늘릴지)\n",
    "                    seed: int = 42              # 랜덤 시드\n",
    "    ):\n",
    "        if index.ntotal != len(meta_df):\n",
    "            print(f\"[주의] 인덱스({index.ntotal})와 문서({len(meta_df)}) 개수 불일치\")\n",
    "    \n",
    "        real_n = min(n, len(question_df))\n",
    "        samples = question_df.sample(n=real_n, random_state=seed).copy()\n",
    "        \n",
    "        print(f\"{real_n}개의 질문에 대해 Top-{k} 검색을 수행합니다.\")\n",
    "        print(f\"   예상되는 결과 행의 개수: {real_n * k}개\\n\")\n",
    "        \n",
    "        merged_results = []\n",
    "\n",
    "        for i, (idx, row) in enumerate(tqdm(samples.iterrows(), total=len(samples), desc=\"Processing\")):\n",
    "        \n",
    "            # 쿼리 생성\n",
    "            qid = row['id']\n",
    "            query = f\"{row['paragraph']} \\n\\n {row['question']}\"\n",
    "            \n",
    "            # --- 검색 로직 ---\n",
    "            q_vec = self.model.encode([query], batch_size=1, max_length=1024)['dense_vecs']\n",
    "            q_vec = q_vec.astype(\"float32\")\n",
    "            faiss.normalize_L2(q_vec)\n",
    "            D, I = index.search(q_vec, k)\n",
    "            # ----------------\n",
    "            \n",
    "            # Top-K만큼 반복하며 원본 데이터 + 검색 데이터 결합\n",
    "            for rank, doc_idx in enumerate(I[0]):\n",
    "                if doc_idx < 0 or doc_idx >= len(meta_df):\n",
    "                    continue\n",
    "                \n",
    "                # 검색된 문서 가져오기\n",
    "                retrieved_doc = meta_df.iloc[doc_idx]\n",
    "                similarity_score = float(D[0][rank])\n",
    "                \n",
    "                # 이렇게 하면 id, paragraph, question, choices, answer 등이 다 들어감\n",
    "                combined_row = row.to_dict()\n",
    "                \n",
    "                # 검색 결과 데이터 추가 (컬럼명 구분)\n",
    "                combined_row['ctx_rank'] = rank + 1                # 순위\n",
    "                combined_row['ctx_score'] = similarity_score       # 유사도 점수\n",
    "                combined_row['ctx_title'] = retrieved_doc['title'] # 검색된 문서 제목\n",
    "                combined_row['ctx_text'] = retrieved_doc['text']   # 검색된 문서 내용\n",
    "                combined_row['ctx_id'] = retrieved_doc['doc_id']   # (있다면) 문서 ID\n",
    "                \n",
    "                merged_results.append(combined_row)\n",
    "\n",
    "        # 4. DataFrame 생성\n",
    "        final_df = pd.DataFrame(merged_results)\n",
    "        \n",
    "        print(f\"\\n완료! 총 {len(final_df)}개의 행이 생성되었습니다.\")\n",
    "        return final_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3865a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/data/ephemeral/pro-nlp-generationfornlp-nlp-13'\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "dataset = pd.read_csv(os.path.join(DATA_DIR,'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22f95270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the JSON dataset\n",
    "records = []\n",
    "for _, row in dataset.iterrows():\n",
    "    problems = literal_eval(row['problems'])\n",
    "    record = {\n",
    "        'id': row['id'],\n",
    "        'paragraph': row['paragraph'],\n",
    "        'question': problems['question'],\n",
    "        'choices': problems['choices'],\n",
    "        'answer': problems.get('answer', None),\n",
    "        \"question_plus\": problems.get('question_plus', None),\n",
    "    }\n",
    "    # Include 'question_plus' if it exists\n",
    "    if 'question_plus' in problems:\n",
    "        record['question_plus'] = problems['question_plus']\n",
    "    records.append(record)\n",
    "        \n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dff79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"choices_len\"] = df[\"choices\"].apply(len)\n",
    "df4 = df[df['choices_len'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33e72d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"/data/ephemeral/pro-nlp-generationfornlp-nlp-13/notebooks/Jang/wikipedia_bge_m3.index\")\n",
    "meta_df = pd.read_parquet(\"/data/ephemeral/pro-nlp-generationfornlp-nlp-13/notebooks/Jang/wikipedia_chunks_meta.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eddbfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133a9a6f9bed4fb6bbc8ef53f8155cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hybrid_retriever = HybridRetriever('BAAI/bge-m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9089dca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10개의 질문에 대해 Top-5 검색을 수행합니다.\n",
      "   예상되는 결과 행의 개수: 50개\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9ac9f9b3544f1aab5b6250d8477217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00, 228.11it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.99it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00, 566.34it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:00<00:00, 60.58it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00, 612.84it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.29it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00, 657.00it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:00<00:00, 60.37it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00, 826.30it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:00<00:00, 60.45it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00, 1208.38it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:00<00:00, 60.19it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00, 1329.41it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:00<00:00, 58.86it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00, 822.57it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:00<00:00, 60.23it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00, 756.96it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:00<00:00, 57.29it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00, 639.86it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "완료! 총 50개의 행이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "df_dense = hybrid_retriever.retrive_dense(df4, meta_df, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf51e7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_plus</th>\n",
       "      <th>choices_len</th>\n",
       "      <th>ctx_rank</th>\n",
       "      <th>ctx_score</th>\n",
       "      <th>ctx_title</th>\n",
       "      <th>ctx_text</th>\n",
       "      <th>ctx_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>generation-for-nlp-1261</td>\n",
       "      <td>오, 수치스럽도다, 불쌍한 겨울의 왕이여! 그대는 도대체 무슨 짓을 벌인 것인가? ...</td>\n",
       "      <td>다음 중 위 노래에 영감을 준 사건은?</td>\n",
       "      <td>[아우스부르크의 평화, 스페인 왕위 계승 전쟁, 낭트칙령, 30년 전쟁]</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571697</td>\n",
       "      <td>프리드리히 5세 폰 데어 팔츠</td>\n",
       "      <td>보헤미아 국왕시절의 베드르지흐(프리드리히 5세) '''프리드리히 5세'''(Frie...</td>\n",
       "      <td>75492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>generation-for-nlp-1261</td>\n",
       "      <td>오, 수치스럽도다, 불쌍한 겨울의 왕이여! 그대는 도대체 무슨 짓을 벌인 것인가? ...</td>\n",
       "      <td>다음 중 위 노래에 영감을 준 사건은?</td>\n",
       "      <td>[아우스부르크의 평화, 스페인 왕위 계승 전쟁, 낭트칙령, 30년 전쟁]</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.569315</td>\n",
       "      <td>보리스 고두노프 (오페라)</td>\n",
       "      <td>위에 있는 지도를 페오도르에게 펼쳐 보이며 \"이 넓은 러시아의 영토가 마침내 너의 ...</td>\n",
       "      <td>26124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>generation-for-nlp-1261</td>\n",
       "      <td>오, 수치스럽도다, 불쌍한 겨울의 왕이여! 그대는 도대체 무슨 짓을 벌인 것인가? ...</td>\n",
       "      <td>다음 중 위 노래에 영감을 준 사건은?</td>\n",
       "      <td>[아우스부르크의 평화, 스페인 왕위 계승 전쟁, 낭트칙령, 30년 전쟁]</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.558124</td>\n",
       "      <td>페르디난트 1세 (오스트리아)</td>\n",
       "      <td>상적인 섭정정치를 이루었고 이는 오스트리아 제국을 혼란에 빠트려 1846년부터 18...</td>\n",
       "      <td>91712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generation-for-nlp-1261</td>\n",
       "      <td>오, 수치스럽도다, 불쌍한 겨울의 왕이여! 그대는 도대체 무슨 짓을 벌인 것인가? ...</td>\n",
       "      <td>다음 중 위 노래에 영감을 준 사건은?</td>\n",
       "      <td>[아우스부르크의 평화, 스페인 왕위 계승 전쟁, 낭트칙령, 30년 전쟁]</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.554392</td>\n",
       "      <td>30년 전쟁</td>\n",
       "      <td>쪽|200px|백산 전투의 재현 보헤미아 분쟁은 여전히 지역적인 분란으로 남아있었다...</td>\n",
       "      <td>33280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>generation-for-nlp-1261</td>\n",
       "      <td>오, 수치스럽도다, 불쌍한 겨울의 왕이여! 그대는 도대체 무슨 짓을 벌인 것인가? ...</td>\n",
       "      <td>다음 중 위 노래에 영감을 준 사건은?</td>\n",
       "      <td>[아우스부르크의 평화, 스페인 왕위 계승 전쟁, 낭트칙령, 30년 전쟁]</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.551977</td>\n",
       "      <td>황제 찬가</td>\n",
       "      <td>Franz, den Kaiser, :Unsern guten Kaiser Franz!...</td>\n",
       "      <td>10287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                          paragraph  \\\n",
       "0  generation-for-nlp-1261  오, 수치스럽도다, 불쌍한 겨울의 왕이여! 그대는 도대체 무슨 짓을 벌인 것인가? ...   \n",
       "1  generation-for-nlp-1261  오, 수치스럽도다, 불쌍한 겨울의 왕이여! 그대는 도대체 무슨 짓을 벌인 것인가? ...   \n",
       "2  generation-for-nlp-1261  오, 수치스럽도다, 불쌍한 겨울의 왕이여! 그대는 도대체 무슨 짓을 벌인 것인가? ...   \n",
       "3  generation-for-nlp-1261  오, 수치스럽도다, 불쌍한 겨울의 왕이여! 그대는 도대체 무슨 짓을 벌인 것인가? ...   \n",
       "4  generation-for-nlp-1261  오, 수치스럽도다, 불쌍한 겨울의 왕이여! 그대는 도대체 무슨 짓을 벌인 것인가? ...   \n",
       "\n",
       "                question                                   choices  answer  \\\n",
       "0  다음 중 위 노래에 영감을 준 사건은?  [아우스부르크의 평화, 스페인 왕위 계승 전쟁, 낭트칙령, 30년 전쟁]       4   \n",
       "1  다음 중 위 노래에 영감을 준 사건은?  [아우스부르크의 평화, 스페인 왕위 계승 전쟁, 낭트칙령, 30년 전쟁]       4   \n",
       "2  다음 중 위 노래에 영감을 준 사건은?  [아우스부르크의 평화, 스페인 왕위 계승 전쟁, 낭트칙령, 30년 전쟁]       4   \n",
       "3  다음 중 위 노래에 영감을 준 사건은?  [아우스부르크의 평화, 스페인 왕위 계승 전쟁, 낭트칙령, 30년 전쟁]       4   \n",
       "4  다음 중 위 노래에 영감을 준 사건은?  [아우스부르크의 평화, 스페인 왕위 계승 전쟁, 낭트칙령, 30년 전쟁]       4   \n",
       "\n",
       "  question_plus  choices_len  ctx_rank  ctx_score         ctx_title  \\\n",
       "0          None            4         1   0.571697  프리드리히 5세 폰 데어 팔츠   \n",
       "1          None            4         2   0.569315    보리스 고두노프 (오페라)   \n",
       "2          None            4         3   0.558124  페르디난트 1세 (오스트리아)   \n",
       "3          None            4         4   0.554392            30년 전쟁   \n",
       "4          None            4         5   0.551977             황제 찬가   \n",
       "\n",
       "                                            ctx_text  ctx_id  \n",
       "0  보헤미아 국왕시절의 베드르지흐(프리드리히 5세) '''프리드리히 5세'''(Frie...   75492  \n",
       "1  위에 있는 지도를 페오도르에게 펼쳐 보이며 \"이 넓은 러시아의 영토가 마침내 너의 ...   26124  \n",
       "2  상적인 섭정정치를 이루었고 이는 오스트리아 제국을 혼란에 빠트려 1846년부터 18...   91712  \n",
       "3  쪽|200px|백산 전투의 재현 보헤미아 분쟁은 여전히 지역적인 분란으로 남아있었다...   33280  \n",
       "4  Franz, den Kaiser, :Unsern guten Kaiser Franz!...   10287  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dense.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
