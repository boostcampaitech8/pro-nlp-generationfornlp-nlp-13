{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "18b16e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from ast import literal_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48c54c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_root: /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n",
      "sys.path[0]: /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "nb_dir = Path(os.getcwd())\n",
    "\n",
    "project_root = nb_dir.parents[1]\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"project_root:\", project_root)\n",
    "print(\"sys.path[0]:\", sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4751ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocessor import parse_problems_column, add_choices_len\n",
    "from src.data.data_loader import DataConfig, make_train_valid_dataset\n",
    "from src.prompt.prompt_registry import PromptRegistry\n",
    "from src.prompt.prompt_builder import PromptBuilder, PromptConfig\n",
    "from src.data.data_loader import DataConfig, make_train_valid_dataset\n",
    "from src.data.tokenizer_wrapper import TokenizerConfig\n",
    "\n",
    "policy = {\n",
    "    \"system\": {4: \"fewshot\", 5: \"fewshot\"},\n",
    "    \"user\":   {4: \"fewshot\", 5: \"fewshot\"},\n",
    "}\n",
    "\n",
    "prompt_cfg = PromptConfig(\n",
    "    policy=policy,\n",
    "    mode=\"train\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "data_cfg = DataConfig(\n",
    "    train_path=project_root / \"data\" / \"train.csv\",\n",
    "    valid_ratio=0.1,\n",
    "    seed=42,\n",
    "    do_split=True,\n",
    ")\n",
    "\n",
    "tokenize_cfg_train = TokenizerConfig(\n",
    "    max_length=2048,\n",
    "    truncation=True,\n",
    "    padding=False,\n",
    "    add_generation_prompt=False,\n",
    ")\n",
    "\n",
    "tokenize_cfg_gen = TokenizerConfig(\n",
    "    max_length=2048,\n",
    "    truncation=True,\n",
    "    padding=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen3-14B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2b09df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template loading 완료: system=5, user_4=6, user_5=4\n",
      "template loading 완료: system=5, user_4=6, user_5=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0d632a141242118d19fef24c6ac6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build train messages:   0%|          | 0/1827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9cbf30ccc24f5da0d7ff510c7fb5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Serialize train to text:   0%|          | 0/1827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5e0183422e42118ab85b5f9aa78f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build valid messages (teacher forcing):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4959952ec6c4e1ba08c41e3e7454b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Serialize valid to text:   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8ee48ac631406a821ca29ecd2c5e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build valid_gen messages (prompt only):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812d05cbff7e4245bd9a433b83833d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Serialize valid_gen to text (+meta):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = make_train_valid_dataset(\n",
    "    data_cfg=data_cfg,\n",
    "    prompt_cfg=prompt_cfg,\n",
    "    tokenize_cfg_train=tokenize_cfg_train,\n",
    "    tokenize_cfg_gen=tokenize_cfg_gen,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40dff263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'generation-for-nlp-2661',\n",
       " 'label': 3,\n",
       " 'text': \"<|im_start|>system\\n당신은 객관식 문제풀이의 달인입니다.<|im_end|>\\n<|im_start|>user\\n밑의 예시와 같이 추론과정을 통해 문제를 해결하세요.\\n[예시]\\n지문:\\n성낙송 수원지방법원장이 대법원장 후보로 있다. 성 원장은 법원행정처 사법정책심의관과 공보관, 서울고법 부장판사 등을 지냈다. 양형위원회 초대 상임위원으로 양형 기준 기초를 마련했으며 서울중앙지법에서 일할 때는 성폭력 피해자 증인지원 프로그램을 처음 도입했다.\\n질문:\\n성낙송 수원지방법원장이 주력해온 분야는 무엇인가?\\n선택지:\\n1 형사법\\n2 민법\\n3 상법\\n4 행정법\\n5 가사법\\n추론:\\n1. 지문 분석. 성낙송 원장은 '양형 기준 기초' 마련, '성폭력 피해자 증인지원 프로그램' 도입\\n2. 개념연결. 지문의 '양형'은 유죄 판결을 받은 피고인에게 형벌의 정도를 정하는 형사 재판의 핵심 절차. 민법, 상법, 행정법 등에서 사용하지 않는 개념\\n3. 개념 연결. '성폭력'은 형법상 범죄 행위, 이를 다루는 재판은 형사 재판.\\n4. 선택지 대조. 정답은 1번.\\n\\n### 지문\\n“올해 미국 경제에는 태양과 달과 별이 한 줄로 서는 행운이 다가오고 있다.”제이미 다이먼 JP모간체이스 최고경영자(CEO·사진)는 지난주 실적발표 후 투자자들과의 화상 회의에서 이렇게 말했다. 평소 미국 경제를 “조심스럽게 낙관한다”고 말해온 다이먼 CEO는 이날 ‘조심스러운’이라는 단어를 사용하지 않았다. 그는 “실제로 경제 전망이 낙관적이기 때문에 ‘낙관적’이라고 말하는 것”이라며 “대기업, 중소기업, 주식시장, 주택시장 등 어느 한 곳에서도 취약한 부분을 찾기 어렵다”고 덧붙였다.다이먼 CEO뿐 아니다. 월스트리트 대형 은행의 최고 경영진도 잇따라 미국 경제에 대한 장밋빛 전망을 쏟아내고 있다. 기업 대출이 사상 최대 수준으로 늘어났기 때문이다. 미국 중앙은행(Fed)에 따르면 작년 말 현재 미국 기업의 대출 잔액은 1조6100억달러로 2008년 기록했던 사상 최고치를 넘어섰다. CNBC는 은행 CEO들이 기업 대출 증가를 더 빠른 경제 성장의 전주곡으로 보고 있다고 전했다. 존 스텀프 웰스파고 CEO는 “고객과 대화를 나누다 보면 뭔가를 짓고, 추가하고, 어딘가에 투자하고 싶다는 이야기를 점점 더 많이 듣게 된다”며 “미국에서 더 많은 경제활동이 일어나고 있다”고 말했다. 뱅크오브아메리카(BoA) 메릴린치의 브루스 톰슨 최고재무책임자(CFO)는 “올 들어 대기업과 헬스케어, 상업용 부동산 업체들을 중심으로 대출 수요가 점점 증가하고 있다”고 전했다. 마이클 코뱃 씨티그룹 CEO도 “성장 전망은 개선되고 경제는 계속 치유되고 있다”고 말했다.한편 Fed의 양적완화 축소(테이퍼링)가 신흥국에 미친 영향도 크지 않았던 것으로 나타났다. 테이퍼링에 따른 신흥시장 위기는 올해 세계 경제의 최대 리스크로 꼽혀왔다. BoA메릴린치에 따르면 벤 버냉키 Fed 의장이 처음 테이퍼링을 거론한 지난해 5월부터 11월까지 14개 신흥국에서 현지 통화 표시 국채에 대한 외국인 보유액은 0.3% 줄어드는 데 그쳤다. “이는 테이퍼링이 시장 혼란으로 이어질 것이라는 우려가 기우였다는 뜻”이라고 파이낸셜타임스(FT)는 분석했다.\\n\\n### 질문\\n제이미 다이먼 JP모간체이스 CEO가 언급한 미국 경제의 전망은 어떤가?\\n\\n### 선택지\\n1. 비관적이다\\n2. 조심스럽게 낙관적이다\\n3. 낙관적이다\\n4. 부정적이다\\n5. 불확실하다\\n\\n정답은 1~5 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\\n정답:<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n3<|im_end|>\\n\"}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "02d199d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template loading 완료: system=5, user_4=6, user_5=4\n"
     ]
    }
   ],
   "source": [
    "prompt_cfg = PromptConfig(\n",
    "    policy=policy,\n",
    "    mode=\"train\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "builder = PromptBuilder(prompt_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e8a03df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1239 entries, 792 to 2030\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             1239 non-null   object \n",
      " 1   paragraph      1239 non-null   object \n",
      " 2   question_plus  0 non-null      float64\n",
      " 3   question       1239 non-null   object \n",
      " 4   choices        1239 non-null   object \n",
      " 5   answer         1239 non-null   int64  \n",
      " 6   choices_len    1239 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 77.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_path = project_root / \"data\" / \"train.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df = df[df['problems'].apply(lambda x: len(literal_eval(x)['choices']) == 5)]\n",
    "\n",
    "df = parse_problems_column(df)\n",
    "df = add_choices_len(df)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "358605bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                         generation-for-nlp-1943\n",
       "paragraph        서울시가 2030년까지 ‘4대문 안 한양도성’과 ‘강남’ ‘영등포·여의도’ 등을 국...\n",
       "question_plus                                                  NaN\n",
       "question         서울시의 2030 도시기본계획에서 강남과 영등포·여의도가 각각 특화된 중심지는 무엇...\n",
       "choices          [국제업무중심지, 세계적 역사문화중심지, 국제금융중심지, 광역교통망 중심지, 자족기...\n",
       "answer                                                           1\n",
       "choices_len                                                      5\n",
       "Name: 1240, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = df.sort_values(by='paragraph', key=lambda x: x.str.len(), ascending=False)\n",
    "sorted_df.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "11708b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = builder.build_message(sorted_df.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09b84d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "\tex['messages'],\n",
    "\tadd_generation_prompt=True,\n",
    "\ttokenize=True,\n",
    "\treturn_dict=True,\n",
    "\treturn_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc65699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 수: 1998\n"
     ]
    }
   ],
   "source": [
    "token_count = len(inputs['input_ids'][0]) \n",
    "\n",
    "print(f\"토큰 수: {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e6744d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2824"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.decode(inputs['input_ids'][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
