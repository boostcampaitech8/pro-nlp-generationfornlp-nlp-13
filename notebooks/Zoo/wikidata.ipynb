{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e0a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "import ast\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import gc\n",
    "from ast import literal_eval\n",
    "from transformers import AutoTokenizer\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "ds = load_dataset(\"lcw99/wikipedia-korean-20240501\")\n",
    "test_df = pd.read_csv('/data/ephemeral/pro-nlp-generationfornlp-nlp-13/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "498ea8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>section_titles</th>\n",
       "      <th>section_texts</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì§€ë¯¸ ì¹´í„°</td>\n",
       "      <td>[Introduction, ì•½ë ¥, ìƒì• , ëŒ€í†µë ¹ ì¬ì„, í‡´ì„ ì´í›„, í‰ê°€, ê°™ì´ ë³´...</td>\n",
       "      <td>[\\n\\n'''ì œì„ìŠ¤ ì–¼ â€œì§€ë¯¸â€ ì¹´í„° ì£¼ë‹ˆì–´'''(, 1924ë…„ 10ì›” 1ì¼~)ëŠ”...</td>\n",
       "      <td>'''ì œì„ìŠ¤ ì–¼ â€œì§€ë¯¸â€ ì¹´í„° ì£¼ë‹ˆì–´'''(, 1924ë…„ 10ì›” 1ì¼~)ëŠ” ë¯¼ì£¼ë‹¹ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ìˆ˜í•™</td>\n",
       "      <td>[Introduction, ì—­ì‚¬, ì„¸ë¶€ ë¶„ì•¼, ì˜í–¥, ê°™ì´ ë³´ê¸°, ì°¸ê³  ë¬¸í—Œ, ì™¸ë¶€...</td>\n",
       "      <td>[\\n\\n'''ìˆ˜í•™'''(, , '''math''')ì€ ìˆ˜, ì–‘, êµ¬ì¡°, ê³µê°„, ë³€...</td>\n",
       "      <td>'''ìˆ˜í•™'''(, , '''math''')ì€ ìˆ˜, ì–‘, êµ¬ì¡°, ê³µê°„, ë³€í™” ë“±ì˜ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ìˆ˜í•™ ìƒìˆ˜</td>\n",
       "      <td>[Introduction, ìˆ˜í•™ ìƒìˆ˜í‘œ, ê´€ë ¨ ìƒìˆ˜ë“¤, ê¸°íƒ€ ìƒìˆ˜ë“¤, ê°™ì´ ë³´ê¸°]</td>\n",
       "      <td>[\\n'''ìˆ˜í•™'''ì—ì„œ '''ìƒìˆ˜'''ë€ ê·¸ ê°’ì´ ë³€í•˜ì§€ ì•ŠëŠ” ë¶ˆë³€ëŸ‰ìœ¼ë¡œ, ë³€ìˆ˜ì˜...</td>\n",
       "      <td>'''ìˆ˜í•™'''ì—ì„œ '''ìƒìˆ˜'''ë€ ê·¸ ê°’ì´ ë³€í•˜ì§€ ì•ŠëŠ” ë¶ˆë³€ëŸ‰ìœ¼ë¡œ, ë³€ìˆ˜ì˜ ë°˜ëŒ€...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë¬¸í•™</td>\n",
       "      <td>[Introduction, ì¼ë°˜ì ì¸ ë¬¸í•™ì˜ ë¶„ë¥˜, ëŒ€ì¤‘ë¬¸í•™ì˜ ë¶„ë¥˜, ë¬¸í•™ ì‚¬ì¡°, ë¬¸...</td>\n",
       "      <td>[\\n\\n\\níŒŒì¼:Fragonard, The Reader.jpg|ì„¬ë„¤ì¼|250px|...</td>\n",
       "      <td>íŒŒì¼:Fragonard, The Reader.jpg|ì„¬ë„¤ì¼|250px|ì¥ì˜¤ë…¸ë ˆ í”„ë¼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ë‚˜ë¼ ëª©ë¡</td>\n",
       "      <td>[Introduction, ê¸°ì¤€, ë‚¨ê·¹, EU, ì°¸ê³ , ëª°íƒ€ ê¸°ì‚¬ë‹¨, [[ë§ˆì´í¬ë¡œë„¤...</td>\n",
       "      <td>[\\nìŠ¤ìœ„ìŠ¤ ì œë„¤ë°”ì— ìˆëŠ” êµ­ì œ ì—°í•© íšŒì›êµ­ ë° ë¹„íšŒì› GA ì˜µì„œë²„ì˜ êµ­ê¸°\\n\\nì´...</td>\n",
       "      <td>ìŠ¤ìœ„ìŠ¤ ì œë„¤ë°”ì— ìˆëŠ” êµ­ì œ ì—°í•© íšŒì›êµ­ ë° ë¹„íšŒì› GA ì˜µì„œë²„ì˜ êµ­ê¸°\\nì´ ëª©ë¡ì— ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515420</th>\n",
       "      <td>ì†¡ê³³ë¶€ë¦¬ë„ìš”</td>\n",
       "      <td>[Introduction, ìƒê¹€ìƒˆ, ì„œì‹ì§€]</td>\n",
       "      <td>[\\n\\n'''ì†¡ê³³ë¶€ë¦¬ë„ìš”'''(, )ëŠ” ë„ìš”ëª© ë„ìš”ê³¼ì— ì†í•˜ëŠ” ë‚˜ê·¸ë„¤ìƒˆì´ë‹¤.\\n,...</td>\n",
       "      <td>'''ì†¡ê³³ë¶€ë¦¬ë„ìš”'''(, )ëŠ” ë„ìš”ëª© ë„ìš”ê³¼ì— ì†í•˜ëŠ” ë‚˜ê·¸ë„¤ìƒˆì´ë‹¤.\\ní° ëˆˆì¹ì„ ê³¼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515421</th>\n",
       "      <td>í‘ì–‘</td>\n",
       "      <td>[Introduction, ì„¤ëª…, ë¶„í¬, ì™¸ë¶€ ë§í¬, ì°¸ê³ ë¬¸í—Œ]</td>\n",
       "      <td>[\\n\\n\\n\\n'''í‘ì–‘'''(é»‘æ¥Š. ''Populus nigra'')ì€ ìœ ëŸ½, ...</td>\n",
       "      <td>'''í‘ì–‘'''(é»‘æ¥Š. ''Populus nigra'')ì€ ìœ ëŸ½, ì„œë‚¨ì•„ì‹œì•„ ë° ì¤‘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515422</th>\n",
       "      <td>ë‹ˆì‹œí•˜íƒ€ ìœ í‚¤ì˜¤</td>\n",
       "      <td>[Introduction, ì €ì„œ, ì™¸ë¶€ ë§í¬]</td>\n",
       "      <td>[\\n'''ë‹ˆì‹œí•˜íƒ€ ìœ í‚¤ì˜¤'''(, 1946ë…„~)ëŠ” ì¼ë³¸ì˜ ì–¸ì–´í•™ìì´ë‹¤.\\n, * ...</td>\n",
       "      <td>'''ë‹ˆì‹œí•˜íƒ€ ìœ í‚¤ì˜¤'''(, 1946ë…„~)ëŠ” ì¼ë³¸ì˜ ì–¸ì–´í•™ìì´ë‹¤.\\n* ã€Œê³ ëŒ€ ì¡°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515423</th>\n",
       "      <td>ì•ˆë“œë¦¬ ìŠ¤íƒ€ë“œë‹ˆí¬</td>\n",
       "      <td>[Introduction, ê°œì¸ì‚¬, ì™¸ë¶€ ë§í¬]</td>\n",
       "      <td>[\\n\\n'''ì•ˆë“œë¦¬ ë³¼ë¡œë””ë¯¸ë¡œë¹„ì¹˜ ìŠ¤íƒ€ë“œë‹ˆí¬'''(, 1982ë…„ 4ì›” 15ì¼~)ëŠ”...</td>\n",
       "      <td>'''ì•ˆë“œë¦¬ ë³¼ë¡œë””ë¯¸ë¡œë¹„ì¹˜ ìŠ¤íƒ€ë“œë‹ˆí¬'''(, 1982ë…„ 4ì›” 15ì¼~)ëŠ” ìš°í¬ë¼ì´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515424</th>\n",
       "      <td>íƒ€ë¼ìŠ¤ ë‹¨ì½”</td>\n",
       "      <td>[Introduction, ì™¸ë¶€ ë§í¬]</td>\n",
       "      <td>[\\n\\n'''íƒ€ë¼ìŠ¤ íë¦¬í˜¸ë¦¬ìš”ë¹„ì¹˜ ë‹¨ì½”'''(, 1980ë…„ 7ì›” 3ì¼~)ëŠ” ìš°í¬ë¼...</td>\n",
       "      <td>'''íƒ€ë¼ìŠ¤ íë¦¬í˜¸ë¦¬ìš”ë¹„ì¹˜ ë‹¨ì½”'''(, 1980ë…„ 7ì›” 3ì¼~)ëŠ” ìš°í¬ë¼ì´ë‚˜ì˜ ì „...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515425 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            title                                     section_titles  \\\n",
       "0           ì§€ë¯¸ ì¹´í„°  [Introduction, ì•½ë ¥, ìƒì• , ëŒ€í†µë ¹ ì¬ì„, í‡´ì„ ì´í›„, í‰ê°€, ê°™ì´ ë³´...   \n",
       "1              ìˆ˜í•™  [Introduction, ì—­ì‚¬, ì„¸ë¶€ ë¶„ì•¼, ì˜í–¥, ê°™ì´ ë³´ê¸°, ì°¸ê³  ë¬¸í—Œ, ì™¸ë¶€...   \n",
       "2           ìˆ˜í•™ ìƒìˆ˜      [Introduction, ìˆ˜í•™ ìƒìˆ˜í‘œ, ê´€ë ¨ ìƒìˆ˜ë“¤, ê¸°íƒ€ ìƒìˆ˜ë“¤, ê°™ì´ ë³´ê¸°]   \n",
       "3              ë¬¸í•™  [Introduction, ì¼ë°˜ì ì¸ ë¬¸í•™ì˜ ë¶„ë¥˜, ëŒ€ì¤‘ë¬¸í•™ì˜ ë¶„ë¥˜, ë¬¸í•™ ì‚¬ì¡°, ë¬¸...   \n",
       "4           ë‚˜ë¼ ëª©ë¡  [Introduction, ê¸°ì¤€, ë‚¨ê·¹, EU, ì°¸ê³ , ëª°íƒ€ ê¸°ì‚¬ë‹¨, [[ë§ˆì´í¬ë¡œë„¤...   \n",
       "...           ...                                                ...   \n",
       "515420     ì†¡ê³³ë¶€ë¦¬ë„ìš”                           [Introduction, ìƒê¹€ìƒˆ, ì„œì‹ì§€]   \n",
       "515421         í‘ì–‘                [Introduction, ì„¤ëª…, ë¶„í¬, ì™¸ë¶€ ë§í¬, ì°¸ê³ ë¬¸í—Œ]   \n",
       "515422   ë‹ˆì‹œí•˜íƒ€ ìœ í‚¤ì˜¤                          [Introduction, ì €ì„œ, ì™¸ë¶€ ë§í¬]   \n",
       "515423  ì•ˆë“œë¦¬ ìŠ¤íƒ€ë“œë‹ˆí¬                         [Introduction, ê°œì¸ì‚¬, ì™¸ë¶€ ë§í¬]   \n",
       "515424     íƒ€ë¼ìŠ¤ ë‹¨ì½”                              [Introduction, ì™¸ë¶€ ë§í¬]   \n",
       "\n",
       "                                            section_texts  \\\n",
       "0       [\\n\\n'''ì œì„ìŠ¤ ì–¼ â€œì§€ë¯¸â€ ì¹´í„° ì£¼ë‹ˆì–´'''(, 1924ë…„ 10ì›” 1ì¼~)ëŠ”...   \n",
       "1       [\\n\\n'''ìˆ˜í•™'''(, , '''math''')ì€ ìˆ˜, ì–‘, êµ¬ì¡°, ê³µê°„, ë³€...   \n",
       "2       [\\n'''ìˆ˜í•™'''ì—ì„œ '''ìƒìˆ˜'''ë€ ê·¸ ê°’ì´ ë³€í•˜ì§€ ì•ŠëŠ” ë¶ˆë³€ëŸ‰ìœ¼ë¡œ, ë³€ìˆ˜ì˜...   \n",
       "3       [\\n\\n\\níŒŒì¼:Fragonard, The Reader.jpg|ì„¬ë„¤ì¼|250px|...   \n",
       "4       [\\nìŠ¤ìœ„ìŠ¤ ì œë„¤ë°”ì— ìˆëŠ” êµ­ì œ ì—°í•© íšŒì›êµ­ ë° ë¹„íšŒì› GA ì˜µì„œë²„ì˜ êµ­ê¸°\\n\\nì´...   \n",
       "...                                                   ...   \n",
       "515420  [\\n\\n'''ì†¡ê³³ë¶€ë¦¬ë„ìš”'''(, )ëŠ” ë„ìš”ëª© ë„ìš”ê³¼ì— ì†í•˜ëŠ” ë‚˜ê·¸ë„¤ìƒˆì´ë‹¤.\\n,...   \n",
       "515421  [\\n\\n\\n\\n'''í‘ì–‘'''(é»‘æ¥Š. ''Populus nigra'')ì€ ìœ ëŸ½, ...   \n",
       "515422  [\\n'''ë‹ˆì‹œí•˜íƒ€ ìœ í‚¤ì˜¤'''(, 1946ë…„~)ëŠ” ì¼ë³¸ì˜ ì–¸ì–´í•™ìì´ë‹¤.\\n, * ...   \n",
       "515423  [\\n\\n'''ì•ˆë“œë¦¬ ë³¼ë¡œë””ë¯¸ë¡œë¹„ì¹˜ ìŠ¤íƒ€ë“œë‹ˆí¬'''(, 1982ë…„ 4ì›” 15ì¼~)ëŠ”...   \n",
       "515424  [\\n\\n'''íƒ€ë¼ìŠ¤ íë¦¬í˜¸ë¦¬ìš”ë¹„ì¹˜ ë‹¨ì½”'''(, 1980ë…„ 7ì›” 3ì¼~)ëŠ” ìš°í¬ë¼...   \n",
       "\n",
       "                                                     text  \n",
       "0       '''ì œì„ìŠ¤ ì–¼ â€œì§€ë¯¸â€ ì¹´í„° ì£¼ë‹ˆì–´'''(, 1924ë…„ 10ì›” 1ì¼~)ëŠ” ë¯¼ì£¼ë‹¹ ...  \n",
       "1       '''ìˆ˜í•™'''(, , '''math''')ì€ ìˆ˜, ì–‘, êµ¬ì¡°, ê³µê°„, ë³€í™” ë“±ì˜ ...  \n",
       "2       '''ìˆ˜í•™'''ì—ì„œ '''ìƒìˆ˜'''ë€ ê·¸ ê°’ì´ ë³€í•˜ì§€ ì•ŠëŠ” ë¶ˆë³€ëŸ‰ìœ¼ë¡œ, ë³€ìˆ˜ì˜ ë°˜ëŒ€...  \n",
       "3       íŒŒì¼:Fragonard, The Reader.jpg|ì„¬ë„¤ì¼|250px|ì¥ì˜¤ë…¸ë ˆ í”„ë¼...  \n",
       "4       ìŠ¤ìœ„ìŠ¤ ì œë„¤ë°”ì— ìˆëŠ” êµ­ì œ ì—°í•© íšŒì›êµ­ ë° ë¹„íšŒì› GA ì˜µì„œë²„ì˜ êµ­ê¸°\\nì´ ëª©ë¡ì— ...  \n",
       "...                                                   ...  \n",
       "515420  '''ì†¡ê³³ë¶€ë¦¬ë„ìš”'''(, )ëŠ” ë„ìš”ëª© ë„ìš”ê³¼ì— ì†í•˜ëŠ” ë‚˜ê·¸ë„¤ìƒˆì´ë‹¤.\\ní° ëˆˆì¹ì„ ê³¼...  \n",
       "515421  '''í‘ì–‘'''(é»‘æ¥Š. ''Populus nigra'')ì€ ìœ ëŸ½, ì„œë‚¨ì•„ì‹œì•„ ë° ì¤‘...  \n",
       "515422  '''ë‹ˆì‹œí•˜íƒ€ ìœ í‚¤ì˜¤'''(, 1946ë…„~)ëŠ” ì¼ë³¸ì˜ ì–¸ì–´í•™ìì´ë‹¤.\\n* ã€Œê³ ëŒ€ ì¡°...  \n",
       "515423  '''ì•ˆë“œë¦¬ ë³¼ë¡œë””ë¯¸ë¡œë¹„ì¹˜ ìŠ¤íƒ€ë“œë‹ˆí¬'''(, 1982ë…„ 4ì›” 15ì¼~)ëŠ” ìš°í¬ë¼ì´...  \n",
       "515424  '''íƒ€ë¼ìŠ¤ íë¦¬í˜¸ë¦¬ìš”ë¹„ì¹˜ ë‹¨ì½”'''(, 1980ë…„ 7ì›” 3ì¼~)ëŠ” ìš°í¬ë¼ì´ë‚˜ì˜ ì „...  \n",
       "\n",
       "[515425 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = pd.DataFrame(ds['train']);wiki_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2ed3c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for _, row in test_df.iterrows():\n",
    "    problems = literal_eval(row['problems'])\n",
    "    record = {\n",
    "        'id': row['id'],\n",
    "        'paragraph': row['paragraph'],\n",
    "        'question': problems['question'],\n",
    "        'choices': problems['choices'],\n",
    "        'answer': problems.get('answer', None),\n",
    "        'question_plus': problems.get('question_plus', None),\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "test_df = pd.DataFrame(records)\n",
    "test_df['num_choices'] = test_df['choices'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae6c1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df.num_choices==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64f72a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_plus</th>\n",
       "      <th>num_choices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>generation-for-nlp-997</td>\n",
       "      <td>ììœ ì¸ì´ í•­ìƒ ê°€ì¥ ì• ì¨ì„œ ì§€ì¼œì˜¨ ê¶Œë¦¬ ì¤‘ í•˜ë‚˜ëŠ” ìì‹ ì˜ ê·¼ë©´ì— ëŒ€í•œ ë³´ìƒì„ ì¦ê¸¸ ...</td>\n",
       "      <td>ìœ„ì˜ êµ¬ì ˆì—ì„œ ì¿¨ë¦¬ì§€ëŠ” ë‹¤ìŒ ì¤‘ ë¬´ì—‡ì— ë°˜ì‘í•©ë‹ˆê¹Œ?</td>\n",
       "      <td>[ì „ì„ì ì›Œë Œ G. í•˜ë”©ì˜ ê²½ì œì •ì±…, ëŸ¬ì‹œì•„ í˜ëª… ì´í›„ ë¯¸êµ­ ë‚´ ì„±ì¥í•œ ê¸‰ì§„ ì •ì¹˜,...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>generation-for-nlp-990</td>\n",
       "      <td>1980ë…„ëŒ€ëŠ” í˜¼ë€, ê°ˆë“±, ë³€í™” ì†ì—ì„œ íƒ„ìƒí–ˆìŠµë‹ˆë‹¤. ì§€ê¸ˆì€ ìš°ë¦¬ì˜ ê´€ì‹¬ê³¼ ê°€ì¹˜ê°€...</td>\n",
       "      <td>ì¹´í„°ê°€ ì„¤ëª…í•œ ìƒí™©ìœ¼ë¡œ ì¸í•´ ê°€ì¥ ì§ì ‘ì ìœ¼ë¡œ ì´ì–´ì§„ ê²ƒì€ ë‹¤ìŒ ì¤‘ ì–´ë–¤ ìƒí™©ì…ë‹ˆê¹Œ?</td>\n",
       "      <td>[ë¶ëŒ€ì„œì–‘ì¡°ì•½ê¸°êµ¬(NATO) ì°½ì„¤, ì°¨ê¸° ëŒ€ì„ ì—ì„œ ì¹´í„°ì˜ íŒ¨ë°°, ë¯¸êµ­ì˜ ì¤‘ë™ ì¹¨ê³µ,...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>generation-for-nlp-1032</td>\n",
       "      <td>\"ì˜¤ëª…ìœ¼ë¡œ ë‚¨ì„ ì–´ì œ 1941ë…„ 12ì›” 7ì¼ ë¯¸êµ­ì€ ì¼ë³¸ ì œêµ­ì˜ í•´ê³µêµ°ìœ¼ë¡œë¶€í„° ê°‘ì‘...</td>\n",
       "      <td>ìœ„ ì§„ìˆ ì´ ì‘ì„±ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ì€ ì‹œì ì€ ë‹¤ìŒ ì¤‘ ì–´ë–¤ ì‚¬ê±´ ì´í›„ì…ë‹ˆê¹Œ?</td>\n",
       "      <td>[ì§„ì£¼ë§Œ í­ê²©, ë¯¸êµ­ ë©”ì¸í˜¸ ì¹¨ëª°, U.S.S. ë¦¬ë²„í‹°í˜¸ í­ê²©, ë³µì„œ ë°˜ë€]</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>generation-for-nlp-1343</td>\n",
       "      <td>ë„ˆëŠ” ë¯¸í•©ì¤‘êµ­ì´ë‹¤, ì¸ë””ì–¸ì˜ í˜ˆí†µì´ë©° ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ì—ê²Œ ê¸°ë„í•˜ê³  ìŠ¤í˜ì¸ì–´ë¥¼ ë§í•˜ëŠ” ...</td>\n",
       "      <td>ì‹œì¸ì´ \"ê³ ëŒ€ë¶€í„° ì‹œì¸ë“¤ì´ ìˆì—ˆê³ , . . . ë³„ì„ ë°”ë¼ë³´ë˜ ìš°ë¦¬ ë¯¸êµ­\" ì„ ë…¼í•œ ...</td>\n",
       "      <td>[ë¼í‹´ì•„ë©”ë¦¬ì¹´ëŠ” ì‹œì— ë›°ì–´ë‚¬ë‹¤., ë¼í‹´ ì•„ë©”ë¦¬ì¹´ëŠ” ìƒë‹¹í•œ ê³¼í•™ì  ê¸°ì—¬ë¥¼ ì´ë£¨ì—ˆë‹¤.,...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>generation-for-nlp-1292</td>\n",
       "      <td>ê·¸ëŠ” ëª¨ë“  ì‘ì—…ê³¼ ìš•ë§, ëª¨ë“  í–¥ê¸°, ëª¨ë“  ë§›ì„ ë‹´ê³  ìˆë‹¤. ê·¸ëŠ” ëª¨ë“  ìš°ì£¼ë¥¼ í’ˆìœ¼...</td>\n",
       "      <td>ìœ„ ì¸ìš©ë¬¸ì— ê¸°ë°˜í•  ë•Œ ë‹¤ìŒ ì¤‘ í™”ìì˜ ì¢…êµì— ëŒ€í•´ ì˜¬ë°”ë¥¸ ê²ƒì€?</td>\n",
       "      <td>[êµ¬ì›ì€ ì˜ì‹ì„ ì˜¬ë°”ë¥´ê²Œ ëë‚´ëŠ” ë°ì— ê¸°ë°˜í•œë‹¤., ë‚´ì„¸ì— ëŒ€í•œ ê¸°ëŒ€ê°€ ì¡´ì¬í•œë‹¤., ...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>generation-for-nlp-1252</td>\n",
       "      <td>ìì•„ë¥¼ ì•„ëŠ” ê²ƒì€ ì „ì°¨ì— ì•‰ì•„ ìˆëŠ” ê²ƒì´ê³ , ìœ¡ì²´ëŠ” ì „ì°¨ì´ë©°, ì§€ì„±ì€ ì „ì°¨ì˜ ìš´ì „ìˆ˜...</td>\n",
       "      <td>ë‹¤ìŒ ì¤‘ ë°œì·Œë¬¸ì—ì„œ ì „ë‹¬ëœ ë©”ì‹œì§€ì™€ ë¶ˆêµì˜ í™˜ìƒì— ê´€í•œ êµë¦¬ê°€ íŒë‘êµì™€ ê°€ì¥ ë‹®ì€ ...</td>\n",
       "      <td>[ì—…ë³´ì— ëŒ€í•œ ê°œë…ì„ ê°€ì§€ê³  ìˆë‹¤., ì‚¬í›„ ì²œêµ­ì— ëŒ€í•œ ê°œë…ì„ ì œì•ˆí•œë‹¤., ëª¨ë“  ì‹ ...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>generation-for-nlp-609</td>\n",
       "      <td>\"í•˜ì§€ë§Œ ì¹œì• í•˜ëŠ” íŒ¡ê¸€ë¡œìŠ¤.\" ìº‰ë””ë“œê°€ ë§í–ˆë‹¤. \"ë‚´ê°€ ì–´ì°Œ ë‹¹ì‹ ì„ ë‹¤ì‹œ ë³¼ ìˆ˜ ìˆ...</td>\n",
       "      <td>íŒ¡ê¸€ë¡œìŠ¤ë¥¼ êµìˆ˜í˜•ì— ì²˜í•˜ì§€ ëª»í•œ ì´ë‹¨ì‹¬íŒ ì§‘í–‰ìë¥¼ ì¡°ë¡±í•œ ê²ƒì€ ì‹œëŒ€ì˜ ì–´ë–¤ ëª¨ìŠµì„ ...</td>\n",
       "      <td>[í† ë¥´ì¼€ë§ˆë‹¤ì˜ ê°œì¸ì  ê²½í—˜, ì´ìŠ¬ëŒ ìƒí™œ ì–‘ì‹ ìˆ˜ìš©, ê°€í†¨ë¦­ êµë¦¬ì— ëŒ€í•œ ì¼ë°˜ì  ê±°...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>generation-for-nlp-906</td>\n",
       "      <td>ì´ì›ƒì§‘ ê°œê°€ ê°‘ìê¸° ì§–ì–´ëŒ€ì ì•„ì´ê°€ ê²ì„ ë¨¹ìŠµë‹ˆë‹¤. ì—„ë§ˆê°€ ì•„ì´ë¥¼ ì•ˆìœ¼ë©´ ì•ˆì •ì„ ë˜...</td>\n",
       "      <td>ì´ëŠ” ë‹¤ìŒ ì¤‘ ì–´ë–¤ ìƒë¬¼í•™ì  í”„ë¡œì„¸ìŠ¤ê°€ ë°œìƒí•˜ê¸° ë•Œë¬¸ì…ë‹ˆê¹Œ?</td>\n",
       "      <td>[ë¶€êµê°ì‹ ê²½ê³„ëŠ” ì œì–´ë¥¼ ì¬ê°œí•˜ê³  êµê° ë°˜ì‘ì„ ì›ë˜ì˜ ìƒíƒœë¡œ ë³µê·€ì‹œí‚µë‹ˆë‹¤., êµê°ì‹ ê²½...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>generation-for-nlp-731</td>\n",
       "      <td>ì†Œë¹„ì ë¬¼ê°€ì§€ìˆ˜(CPI)ê°€ 2% ìƒìŠ¹í•˜ê³  ëª…ëª© ì†Œë“ì´ 8% ì¦ê°€í•˜ë©´ ì‹¤ì§ˆ ì†Œë“ì€ ëŒ€ëµ</td>\n",
       "      <td>ì†Œë¹„ì ë¬¼ê°€ì§€ìˆ˜(CPI)ê°€ 2% ìƒìŠ¹í•˜ê³  ëª…ëª© ì†Œë“ì´ 8% ì¦ê°€í•˜ë©´ ì‹¤ì§ˆ ì†Œë“ì€ ëŒ€ëµ?</td>\n",
       "      <td>[4% ì¦ê°€í•œë‹¤., 4% ê°ì†Œí•œë‹¤., 6% ì¦ê°€í•œë‹¤., 6% ê°ì†Œí•œë‹¤.]</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>generation-for-nlp-702</td>\n",
       "      <td>ì¬ì • ì •ì±…    ì‹¤ì§ˆ GDP    ì‹¤ì—…</td>\n",
       "      <td>ê²½ì œê°€ ê²½ê¸° ì¹¨ì²´ê¸°ë¥¼ ê²ªê³  ìˆë‹¤ë©´, ê·¸ ê²©ì°¨ë¥¼ ì—†ì• ê¸° ìœ„í•œ ì ì ˆí•œ ì¬ì • ì •ì±…ê³¼ ê·¸ ...</td>\n",
       "      <td>[ì„¸ê¸ˆ ì¦ê°€ Â Â Â  ì¦ê°€ Â Â Â  ê°ì†Œ, ì§€ì¶œ ê°ì†Œ Â Â Â  ê°ì†Œ Â Â Â  ì¦ê°€, ì„¸ê¸ˆ ...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  \\\n",
       "425   generation-for-nlp-997   \n",
       "426   generation-for-nlp-990   \n",
       "428  generation-for-nlp-1032   \n",
       "430  generation-for-nlp-1343   \n",
       "433  generation-for-nlp-1292   \n",
       "..                       ...   \n",
       "857  generation-for-nlp-1252   \n",
       "858   generation-for-nlp-609   \n",
       "859   generation-for-nlp-906   \n",
       "860   generation-for-nlp-731   \n",
       "867   generation-for-nlp-702   \n",
       "\n",
       "                                             paragraph  \\\n",
       "425  ììœ ì¸ì´ í•­ìƒ ê°€ì¥ ì• ì¨ì„œ ì§€ì¼œì˜¨ ê¶Œë¦¬ ì¤‘ í•˜ë‚˜ëŠ” ìì‹ ì˜ ê·¼ë©´ì— ëŒ€í•œ ë³´ìƒì„ ì¦ê¸¸ ...   \n",
       "426  1980ë…„ëŒ€ëŠ” í˜¼ë€, ê°ˆë“±, ë³€í™” ì†ì—ì„œ íƒ„ìƒí–ˆìŠµë‹ˆë‹¤. ì§€ê¸ˆì€ ìš°ë¦¬ì˜ ê´€ì‹¬ê³¼ ê°€ì¹˜ê°€...   \n",
       "428  \"ì˜¤ëª…ìœ¼ë¡œ ë‚¨ì„ ì–´ì œ 1941ë…„ 12ì›” 7ì¼ ë¯¸êµ­ì€ ì¼ë³¸ ì œêµ­ì˜ í•´ê³µêµ°ìœ¼ë¡œë¶€í„° ê°‘ì‘...   \n",
       "430  ë„ˆëŠ” ë¯¸í•©ì¤‘êµ­ì´ë‹¤, ì¸ë””ì–¸ì˜ í˜ˆí†µì´ë©° ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ì—ê²Œ ê¸°ë„í•˜ê³  ìŠ¤í˜ì¸ì–´ë¥¼ ë§í•˜ëŠ” ...   \n",
       "433  ê·¸ëŠ” ëª¨ë“  ì‘ì—…ê³¼ ìš•ë§, ëª¨ë“  í–¥ê¸°, ëª¨ë“  ë§›ì„ ë‹´ê³  ìˆë‹¤. ê·¸ëŠ” ëª¨ë“  ìš°ì£¼ë¥¼ í’ˆìœ¼...   \n",
       "..                                                 ...   \n",
       "857  ìì•„ë¥¼ ì•„ëŠ” ê²ƒì€ ì „ì°¨ì— ì•‰ì•„ ìˆëŠ” ê²ƒì´ê³ , ìœ¡ì²´ëŠ” ì „ì°¨ì´ë©°, ì§€ì„±ì€ ì „ì°¨ì˜ ìš´ì „ìˆ˜...   \n",
       "858  \"í•˜ì§€ë§Œ ì¹œì• í•˜ëŠ” íŒ¡ê¸€ë¡œìŠ¤.\" ìº‰ë””ë“œê°€ ë§í–ˆë‹¤. \"ë‚´ê°€ ì–´ì°Œ ë‹¹ì‹ ì„ ë‹¤ì‹œ ë³¼ ìˆ˜ ìˆ...   \n",
       "859  ì´ì›ƒì§‘ ê°œê°€ ê°‘ìê¸° ì§–ì–´ëŒ€ì ì•„ì´ê°€ ê²ì„ ë¨¹ìŠµë‹ˆë‹¤. ì—„ë§ˆê°€ ì•„ì´ë¥¼ ì•ˆìœ¼ë©´ ì•ˆì •ì„ ë˜...   \n",
       "860    ì†Œë¹„ì ë¬¼ê°€ì§€ìˆ˜(CPI)ê°€ 2% ìƒìŠ¹í•˜ê³  ëª…ëª© ì†Œë“ì´ 8% ì¦ê°€í•˜ë©´ ì‹¤ì§ˆ ì†Œë“ì€ ëŒ€ëµ   \n",
       "867                              ì¬ì • ì •ì±…    ì‹¤ì§ˆ GDP    ì‹¤ì—…   \n",
       "\n",
       "                                              question  \\\n",
       "425                       ìœ„ì˜ êµ¬ì ˆì—ì„œ ì¿¨ë¦¬ì§€ëŠ” ë‹¤ìŒ ì¤‘ ë¬´ì—‡ì— ë°˜ì‘í•©ë‹ˆê¹Œ?   \n",
       "426     ì¹´í„°ê°€ ì„¤ëª…í•œ ìƒí™©ìœ¼ë¡œ ì¸í•´ ê°€ì¥ ì§ì ‘ì ìœ¼ë¡œ ì´ì–´ì§„ ê²ƒì€ ë‹¤ìŒ ì¤‘ ì–´ë–¤ ìƒí™©ì…ë‹ˆê¹Œ?   \n",
       "428       ìœ„ ì§„ìˆ ì´ ì‘ì„±ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ì€ ì‹œì ì€ ë‹¤ìŒ ì¤‘ ì–´ë–¤ ì‚¬ê±´ ì´í›„ì…ë‹ˆê¹Œ?   \n",
       "430  ì‹œì¸ì´ \"ê³ ëŒ€ë¶€í„° ì‹œì¸ë“¤ì´ ìˆì—ˆê³ , . . . ë³„ì„ ë°”ë¼ë³´ë˜ ìš°ë¦¬ ë¯¸êµ­\" ì„ ë…¼í•œ ...   \n",
       "433               ìœ„ ì¸ìš©ë¬¸ì— ê¸°ë°˜í•  ë•Œ ë‹¤ìŒ ì¤‘ í™”ìì˜ ì¢…êµì— ëŒ€í•´ ì˜¬ë°”ë¥¸ ê²ƒì€?   \n",
       "..                                                 ...   \n",
       "857  ë‹¤ìŒ ì¤‘ ë°œì·Œë¬¸ì—ì„œ ì „ë‹¬ëœ ë©”ì‹œì§€ì™€ ë¶ˆêµì˜ í™˜ìƒì— ê´€í•œ êµë¦¬ê°€ íŒë‘êµì™€ ê°€ì¥ ë‹®ì€ ...   \n",
       "858  íŒ¡ê¸€ë¡œìŠ¤ë¥¼ êµìˆ˜í˜•ì— ì²˜í•˜ì§€ ëª»í•œ ì´ë‹¨ì‹¬íŒ ì§‘í–‰ìë¥¼ ì¡°ë¡±í•œ ê²ƒì€ ì‹œëŒ€ì˜ ì–´ë–¤ ëª¨ìŠµì„ ...   \n",
       "859                  ì´ëŠ” ë‹¤ìŒ ì¤‘ ì–´ë–¤ ìƒë¬¼í•™ì  í”„ë¡œì„¸ìŠ¤ê°€ ë°œìƒí•˜ê¸° ë•Œë¬¸ì…ë‹ˆê¹Œ?   \n",
       "860   ì†Œë¹„ì ë¬¼ê°€ì§€ìˆ˜(CPI)ê°€ 2% ìƒìŠ¹í•˜ê³  ëª…ëª© ì†Œë“ì´ 8% ì¦ê°€í•˜ë©´ ì‹¤ì§ˆ ì†Œë“ì€ ëŒ€ëµ?   \n",
       "867  ê²½ì œê°€ ê²½ê¸° ì¹¨ì²´ê¸°ë¥¼ ê²ªê³  ìˆë‹¤ë©´, ê·¸ ê²©ì°¨ë¥¼ ì—†ì• ê¸° ìœ„í•œ ì ì ˆí•œ ì¬ì • ì •ì±…ê³¼ ê·¸ ...   \n",
       "\n",
       "                                               choices answer question_plus  \\\n",
       "425  [ì „ì„ì ì›Œë Œ G. í•˜ë”©ì˜ ê²½ì œì •ì±…, ëŸ¬ì‹œì•„ í˜ëª… ì´í›„ ë¯¸êµ­ ë‚´ ì„±ì¥í•œ ê¸‰ì§„ ì •ì¹˜,...                 None   \n",
       "426  [ë¶ëŒ€ì„œì–‘ì¡°ì•½ê¸°êµ¬(NATO) ì°½ì„¤, ì°¨ê¸° ëŒ€ì„ ì—ì„œ ì¹´í„°ì˜ íŒ¨ë°°, ë¯¸êµ­ì˜ ì¤‘ë™ ì¹¨ê³µ,...                 None   \n",
       "428         [ì§„ì£¼ë§Œ í­ê²©, ë¯¸êµ­ ë©”ì¸í˜¸ ì¹¨ëª°, U.S.S. ë¦¬ë²„í‹°í˜¸ í­ê²©, ë³µì„œ ë°˜ë€]                 None   \n",
       "430  [ë¼í‹´ì•„ë©”ë¦¬ì¹´ëŠ” ì‹œì— ë›°ì–´ë‚¬ë‹¤., ë¼í‹´ ì•„ë©”ë¦¬ì¹´ëŠ” ìƒë‹¹í•œ ê³¼í•™ì  ê¸°ì—¬ë¥¼ ì´ë£¨ì—ˆë‹¤.,...                 None   \n",
       "433  [êµ¬ì›ì€ ì˜ì‹ì„ ì˜¬ë°”ë¥´ê²Œ ëë‚´ëŠ” ë°ì— ê¸°ë°˜í•œë‹¤., ë‚´ì„¸ì— ëŒ€í•œ ê¸°ëŒ€ê°€ ì¡´ì¬í•œë‹¤., ...                 None   \n",
       "..                                                 ...    ...           ...   \n",
       "857  [ì—…ë³´ì— ëŒ€í•œ ê°œë…ì„ ê°€ì§€ê³  ìˆë‹¤., ì‚¬í›„ ì²œêµ­ì— ëŒ€í•œ ê°œë…ì„ ì œì•ˆí•œë‹¤., ëª¨ë“  ì‹ ...                 None   \n",
       "858  [í† ë¥´ì¼€ë§ˆë‹¤ì˜ ê°œì¸ì  ê²½í—˜, ì´ìŠ¬ëŒ ìƒí™œ ì–‘ì‹ ìˆ˜ìš©, ê°€í†¨ë¦­ êµë¦¬ì— ëŒ€í•œ ì¼ë°˜ì  ê±°...                 None   \n",
       "859  [ë¶€êµê°ì‹ ê²½ê³„ëŠ” ì œì–´ë¥¼ ì¬ê°œí•˜ê³  êµê° ë°˜ì‘ì„ ì›ë˜ì˜ ìƒíƒœë¡œ ë³µê·€ì‹œí‚µë‹ˆë‹¤., êµê°ì‹ ê²½...                 None   \n",
       "860           [4% ì¦ê°€í•œë‹¤., 4% ê°ì†Œí•œë‹¤., 6% ì¦ê°€í•œë‹¤., 6% ê°ì†Œí•œë‹¤.]                 None   \n",
       "867  [ì„¸ê¸ˆ ì¦ê°€ Â Â Â  ì¦ê°€ Â Â Â  ê°ì†Œ, ì§€ì¶œ ê°ì†Œ Â Â Â  ê°ì†Œ Â Â Â  ì¦ê°€, ì„¸ê¸ˆ ...                 None   \n",
       "\n",
       "     num_choices  \n",
       "425            4  \n",
       "426            4  \n",
       "428            4  \n",
       "430            4  \n",
       "433            4  \n",
       "..           ...  \n",
       "857            4  \n",
       "858            4  \n",
       "859            4  \n",
       "860            4  \n",
       "867            4  \n",
       "\n",
       "[163 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e1052ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkDataset(Dataset):\n",
    "    \"\"\"Chunk ë°©ì‹\"\"\"\n",
    "    def __init__(self, dataset, tokenizer, max_length, overlap=50):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "        \n",
    "        print(\"ì²­í¬ ìƒì„± ì¤‘...\")\n",
    "        for item in dataset:\n",
    "            question = item['question']\n",
    "            context = item['context']\n",
    "            \n",
    "            c_tokens = tokenizer.encode(context, add_special_tokens=False)\n",
    "            \n",
    "            if len(c_tokens) > max_length - 2:\n",
    "                stride = max_length - overlap - 2\n",
    "                for i in range(0, len(c_tokens), stride):\n",
    "                    chunk = c_tokens[i:i + max_length - 2]\n",
    "                    if len(chunk) >= 10:\n",
    "                        chunk_text = tokenizer.decode(chunk)\n",
    "                        self.data.append({\n",
    "                            'question': question,\n",
    "                            'context': chunk_text,\n",
    "                            'original_context': context\n",
    "                        })\n",
    "            else:\n",
    "                self.data.append({\n",
    "                    'question': question,\n",
    "                    'context': context,\n",
    "                    'original_context': context\n",
    "                })\n",
    "        \n",
    "        print(f\"ì²­í¬ ìƒì„± ì™„ë£Œ: {len(self.data)}ê°œ\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        q_encoding = self.tokenizer(\n",
    "            item['question'],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        c_encoding = self.tokenizer(\n",
    "            item['context'],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'q_input_ids': q_encoding['input_ids'].squeeze(),\n",
    "            'q_attention_mask': q_encoding['attention_mask'].squeeze(),\n",
    "            'c_input_ids': c_encoding['input_ids'].squeeze(),\n",
    "            'c_attention_mask': c_encoding['attention_mask'].squeeze(),\n",
    "            # 'context': item['original_context']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffae8927",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"dragonkue/BGE-m3-ko\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64426ee7",
   "metadata": {},
   "outputs": [],
   "source": "def chunk_tokenize(text, tokenizer, max_length=512, stride=128):\n    \"\"\"í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•œ í›„ ì²­í‚¹\"\"\"\n    tokens = tokenizer.encode(text, add_special_tokens=False)\n    \n    chunks = []\n    for i in range(0, len(tokens), max_length - stride):\n        chunk = tokens[i:i + max_length]\n        if len(chunk) >= 10:  # ë„ˆë¬´ ì§§ì€ ì²­í¬ëŠ” ì œì™¸\n            chunks.append(chunk)\n    \n    return chunks"
  },
  {
   "cell_type": "code",
   "id": "xeiquk9ekvn",
   "source": "# wiki_dfì˜ text ì²­í‚¹\nprint(\"wiki_df text ì²­í‚¹ ì¤‘...\")\nwiki_chunks = []\nfor idx, row in tqdm(wiki_df.iterrows(), total=len(wiki_df)):\n    chunks = chunk_tokenize(row['text'], tokenizer, max_length=512, stride=128)\n    for chunk_idx, chunk in enumerate(chunks):\n        wiki_chunks.append({\n            'original_idx': idx,\n            'title': row['title'],\n            'chunk_idx': chunk_idx,\n            'token_ids': chunk,\n            'num_tokens': len(chunk)\n        })\n\nwiki_chunks_df = pd.DataFrame(wiki_chunks)\nprint(f\"wiki_df ì²­í‚¹ ì™„ë£Œ: {len(wiki_chunks_df)}ê°œ ì²­í¬ ìƒì„±\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "xgri4f3xo9q",
   "source": "# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ\nmodel = SentenceTransformer(MODEL_NAME)\nmodel.eval()\nif torch.cuda.is_available():\n    model = model.cuda()\n    \nprint(f\"Model loaded on {'cuda' if torch.cuda.is_available() else 'cpu'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "kw21a0h8kgm",
   "source": "# wiki ì²­í¬ ì„ë² ë”© ìƒì„±\nprint(\"wiki ì²­í¬ ì„ë² ë”© ìƒì„± ì¤‘...\")\nwiki_texts = [tokenizer.decode(tokens) for tokens in wiki_chunks_df['token_ids'].tolist()]\n\nbatch_size = 32\nwiki_embeddings = []\n\nfor i in tqdm(range(0, len(wiki_texts), batch_size)):\n    batch = wiki_texts[i:i+batch_size]\n    with torch.no_grad():\n        embeddings = model.encode(batch, convert_to_numpy=True, show_progress_bar=False)\n    wiki_embeddings.append(embeddings)\n    \n    # ë©”ëª¨ë¦¬ ê´€ë¦¬\n    if i % 1000 == 0:\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\nwiki_embeddings = np.vstack(wiki_embeddings)\nprint(f\"wiki ì„ë² ë”© ì™„ë£Œ: {wiki_embeddings.shape}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "krxg2we5cf",
   "source": "# FAISS ì¸ë±ìŠ¤ ìƒì„±\nprint(\"FAISS ì¸ë±ìŠ¤ ìƒì„± ì¤‘...\")\ndimension = wiki_embeddings.shape[1]\nindex = faiss.IndexFlatIP(dimension)  # Inner Product (cosine similarity)\n\n# ì •ê·œí™” (cosine similarityë¥¼ ìœ„í•´)\nfaiss.normalize_L2(wiki_embeddings)\nindex.add(wiki_embeddings)\n\nprint(f\"FAISS ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {index.ntotal}ê°œ ë²¡í„°\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ulu1g9iqcks",
   "source": "# test_df paragraph í† í°í™” (512 í† í°, íŒ¨ë”© í—ˆìš©)\nprint(\"test_df paragraph í† í°í™” ì¤‘...\")\ntest_tokenized = []\nfor paragraph in tqdm(test_df['paragraph'].tolist()):\n    tokens = tokenizer.encode(\n        paragraph,\n        add_special_tokens=False,\n        max_length=512,\n        truncation=True,\n        padding='max_length'\n    )\n    test_tokenized.append(tokens)\n\ntest_df['token_ids'] = test_tokenized\ntest_df['num_tokens'] = test_df['token_ids'].apply(len)\nprint(f\"test_df í† í°í™” ì™„ë£Œ: {len(test_df)}ê°œ\")\n\n# test_df paragraph ì„ë² ë”© ìƒì„±\nprint(\"test_df paragraph ì„ë² ë”© ìƒì„± ì¤‘...\")\ntest_texts = [tokenizer.decode(tokens) for tokens in test_tokenized]\n\ntest_embeddings = []\nfor i in tqdm(range(0, len(test_texts), batch_size)):\n    batch = test_texts[i:i+batch_size]\n    with torch.no_grad():\n        embeddings = model.encode(batch, convert_to_numpy=True, show_progress_bar=False)\n    test_embeddings.append(embeddings)\n\ntest_embeddings = np.vstack(test_embeddings)\nfaiss.normalize_L2(test_embeddings)\n\nprint(f\"test ì„ë² ë”© ì™„ë£Œ: {test_embeddings.shape}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bpjkux2ta9",
   "source": "# FAISSë¡œ ìœ ì‚¬í•œ wiki ì²­í¬ ê²€ìƒ‰ (Top 5)\nprint(\"ìœ ì‚¬í•œ wiki ì²­í¬ ê²€ìƒ‰ ì¤‘...\")\nk = 5  # ìƒìœ„ 5ê°œ\ndistances, indices = index.search(test_embeddings, k)\n\nprint(f\"ê²€ìƒ‰ ì™„ë£Œ: ê° test_dfì— ëŒ€í•´ {k}ê°œì˜ ìœ ì‚¬ ì²­í¬ ë°œê²¬\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "pdlzk2nj9j8",
   "source": "# ê²°ê³¼ ì •ë¦¬\nresults = []\nfor i, (test_idx, row) in enumerate(test_df.iterrows()):\n    top_k_indices = indices[i]\n    top_k_distances = distances[i]\n    \n    retrieved_chunks = []\n    retrieved_texts = []\n    for rank, (chunk_idx, score) in enumerate(zip(top_k_indices, top_k_distances)):\n        chunk_info = wiki_chunks_df.iloc[chunk_idx]\n        text = tokenizer.decode(chunk_info['token_ids'])\n        \n        retrieved_chunks.append({\n            'rank': rank + 1,\n            'score': float(score),\n            'title': chunk_info['title'],\n            'chunk_idx': chunk_info['chunk_idx'],\n            'token_ids': chunk_info['token_ids'],\n            'text': text\n        })\n        retrieved_texts.append(text)\n    \n    results.append({\n        'test_idx': test_idx,\n        'id': row['id'],\n        'paragraph': row['paragraph'],\n        'question': row['question'],\n        'retrieved_chunks': retrieved_chunks,\n        'retrieved_texts': retrieved_texts\n    })\n\nresults_df = pd.DataFrame(results)\nprint(f\"ê²°ê³¼ ì •ë¦¬ ì™„ë£Œ: {len(results_df)}ê°œ í•­ëª©\")\nresults_df.head()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7s2o6145ovl",
   "source": "# í˜„ì¬ ë©”ëª¨ë¦¬ì— ìˆëŠ” results_dfì—ì„œ retrieved_chunksì˜ textë§Œ ì¶”ì¶œ\n# retrieved_chunksëŠ” ì´ë¯¸ ë¦¬ìŠ¤íŠ¸[ë”•ì…”ë„ˆë¦¬] í˜•íƒœ\n\nretrieved_texts_list = []\nfor chunks in results_df['retrieved_chunks']:\n    if isinstance(chunks, str):\n        # CSVì—ì„œ ì½ì€ ê²½ìš° ë¬¸ìì—´ì´ë¯€ë¡œ íŒŒì‹±\n        chunks = literal_eval(chunks)\n    texts = [chunk['text'] for chunk in chunks]\n    retrieved_texts_list.append(texts)\n\nresults_df['retrieved_texts'] = retrieved_texts_list\nresults_df[['id', 'question', 'retrieved_texts']].head()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "vyqv1s0e99",
   "source": "# retrieved_chunksì—ì„œ ìœ ì‚¬ë„(score), text, paragraph ìŒìœ¼ë¡œ df ìƒì„±\nvector_db_data = []\n\nfor idx, row in results_df.iterrows():\n    test_id = row['id']\n    question = row['question']\n    paragraph = row['paragraph']\n    retrieved_chunks = row['retrieved_chunks']\n    \n    # retrieved_chunksê°€ ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±\n    if isinstance(retrieved_chunks, str):\n        retrieved_chunks = literal_eval(retrieved_chunks)\n    \n    for chunk in retrieved_chunks:\n        vector_db_data.append({\n            'test_id': test_id,\n            'question': question,\n            'paragraph': paragraph,\n            'rank': chunk['rank'],\n            'score': chunk['score'],\n            'title': chunk['title'],\n            'retrieved_text': chunk['text']\n        })\n\nvector_db_df = pd.DataFrame(vector_db_data)\nprint(f\"ë²¡í„° DBìš© ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(vector_db_df)}ê°œ í…ìŠ¤íŠ¸\")\nvector_db_df.head(10)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ovkh43lqym",
   "source": "# í˜„ì¬ ë°ì´í„°ì˜ í† í° ìˆ˜ í™•ì¸\n\n# 1. Wiki chunks í† í° ìˆ˜\nwiki_total_tokens = wiki_chunks_df['num_tokens'].sum()\nwiki_num_chunks = len(wiki_chunks_df)\n\n# 2. Test data í† í° ìˆ˜\ntest_total_tokens = test_df['num_tokens'].sum()\ntest_num_samples = len(test_df)\n\n# 3. Retrieved texts í† í° ìˆ˜ (vector_db_df ê¸°ì¤€)\nretrieved_texts = vector_db_df['retrieved_text'].tolist()\nretrieved_tokens = [len(tokenizer.encode(text, add_special_tokens=False)) for text in retrieved_texts]\nretrieved_total_tokens = sum(retrieved_tokens)\nretrieved_num_texts = len(retrieved_texts)\n\nprint(\"=\" * 60)\nprint(\"ğŸ“Š í† í° ìˆ˜ í†µê³„\")\nprint(\"=\" * 60)\nprint(f\"\\n1. Wiki Chunks:\")\nprint(f\"   - ì²­í¬ ê°œìˆ˜: {wiki_num_chunks:,}ê°œ\")\nprint(f\"   - ì´ í† í° ìˆ˜: {wiki_total_tokens:,} tokens\")\nprint(f\"   - í‰ê·  í† í°/ì²­í¬: {wiki_total_tokens/wiki_num_chunks:.1f} tokens\")\n\nprint(f\"\\n2. Test Data (Paragraphs):\")\nprint(f\"   - ìƒ˜í”Œ ê°œìˆ˜: {test_num_samples:,}ê°œ\")\nprint(f\"   - ì´ í† í° ìˆ˜: {test_total_tokens:,} tokens\")\nprint(f\"   - í‰ê·  í† í°/ìƒ˜í”Œ: {test_total_tokens/test_num_samples:.1f} tokens\")\n\nprint(f\"\\n3. Retrieved Texts (ê²€ìƒ‰ëœ ìœ„í‚¤ í…ìŠ¤íŠ¸):\")\nprint(f\"   - í…ìŠ¤íŠ¸ ê°œìˆ˜: {retrieved_num_texts:,}ê°œ\")\nprint(f\"   - ì´ í† í° ìˆ˜: {retrieved_total_tokens:,} tokens\")\nprint(f\"   - í‰ê·  í† í°/í…ìŠ¤íŠ¸: {retrieved_total_tokens/retrieved_num_texts:.1f} tokens\")\n\nprint(f\"\\n4. ì „ì²´ ì„ë² ë”©í•´ì•¼ í•  í† í°:\")\nprint(f\"   - Wiki: {wiki_total_tokens:,} tokens\")\nprint(f\"   - Test: {test_total_tokens:,} tokens\")\nprint(f\"   - í•©ê³„: {wiki_total_tokens + test_total_tokens:,} tokens\")\n\n# OpenAI API ë¹„ìš© ì˜ˆìƒ (text-embedding-3-small ê¸°ì¤€: $0.02 / 1M tokens)\ntotal_for_embedding = wiki_total_tokens + test_total_tokens\nopenai_cost = (total_for_embedding / 1_000_000) * 0.02\n\nprint(f\"\\nğŸ’° ì˜ˆìƒ ë¹„ìš© (OpenAI text-embedding-3-small):\")\nprint(f\"   - ì´ ì„ë² ë”© í† í°: {total_for_embedding:,} tokens\")\nprint(f\"   - ì˜ˆìƒ ë¹„ìš©: ${openai_cost:.4f}\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}