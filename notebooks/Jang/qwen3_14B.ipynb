{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed29bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_root: /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n",
      "sys.path[0]: /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n"
     ]
    }
   ],
   "source": [
    "### TEST\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "nb_dir = Path(os.getcwd())\n",
    "\n",
    "# 프로젝트 루트: notebooks/Jang -> notebooks -> project_root\n",
    "project_root = nb_dir.parents[1]  # /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"project_root:\", project_root)\n",
    "print(\"sys.path[0]:\", sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd650ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "from src.prompt.prompt_registry import PromptRegistry\n",
    "from src.prompt.prompt_builder import PromptBuilder, PromptConfig\n",
    "from src.data.data_loader import DataConfig, make_train_valid_dataset\n",
    "from src.data.tokenizer_wrapper import TokenizerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7825e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {\n",
    "    \"system\": {4: \"v1\", 5: \"v1\"},\n",
    "    \"user\":   {4: \"v1\", 5: \"v1\"},\n",
    "}\n",
    "\n",
    "prompt_cfg = PromptConfig(\n",
    "    policy=policy,\n",
    "    mode=\"train\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "data_cfg = DataConfig(\n",
    "    train_path=project_root / \"data\" / \"train.csv\",\n",
    "    valid_ratio=0.1,\n",
    "    seed=42,\n",
    "    do_split=True,\n",
    ")\n",
    "\n",
    "tokenize_cfg_train = TokenizerConfig(\n",
    "    max_length=2048,\n",
    "    truncation=True,\n",
    "    padding=False,\n",
    "    add_generation_prompt=False,\n",
    ")\n",
    "\n",
    "tokenize_cfg_gen = TokenizerConfig(\n",
    "    max_length=2048,\n",
    "    truncation=True,\n",
    "    padding=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen3-14B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b63bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template loading 완료: system=2, user_4=2, user_5=2\n",
      "template loading 완료: system=2, user_4=2, user_5=2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd436cc9ac641978b2544eab8aebe43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build train messages:   0%|          | 0/1827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5b43675cf84db9b832cb25254631aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Serialize train to text:   0%|          | 0/1827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be9b55ff6f848d7a666301b51b993b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build valid messages (teacher forcing):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958c0bb1578b43a7ad46f6f17f56a07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Serialize valid to text:   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b769b51463442d8889298f50e108d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build valid_gen messages (prompt only):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349e16754b9f40a289376c87d7db9b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Serialize valid_gen to text (+meta):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = make_train_valid_dataset(\n",
    "    data_cfg=data_cfg,\n",
    "    prompt_cfg=prompt_cfg,\n",
    "    tokenize_cfg_train=tokenize_cfg_train,\n",
    "    tokenize_cfg_gen=tokenize_cfg_gen,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb8b72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n당신은 논리적인 **텍스트 분석 및 독해 전문가**입니다.\\n이 문제는 오직 **제공된 지문 내의 정보**만으로 풀어야 합니다.\\n당신의 외부 배경지식을 배제하고, 철저하게 지문에 명시된 내용에 근거하여 판단하십시오.<|im_end|>\\n<|im_start|>user\\n### 지문\\n“올해 미국 경제에는 태양과 달과 별이 한 줄로 서는 행운이 다가오고 있다.”제이미 다이먼 JP모간체이스 최고경영자(CEO·사진)는 지난주 실적발표 후 투자자들과의 화상 회의에서 이렇게 말했다. 평소 미국 경제를 “조심스럽게 낙관한다”고 말해온 다이먼 CEO는 이날 ‘조심스러운’이라는 단어를 사용하지 않았다. 그는 “실제로 경제 전망이 낙관적이기 때문에 ‘낙관적’이라고 말하는 것”이라며 “대기업, 중소기업, 주식시장, 주택시장 등 어느 한 곳에서도 취약한 부분을 찾기 어렵다”고 덧붙였다.다이먼 CEO뿐 아니다. 월스트리트 대형 은행의 최고 경영진도 잇따라 미국 경제에 대한 장밋빛 전망을 쏟아내고 있다. 기업 대출이 사상 최대 수준으로 늘어났기 때문이다. 미국 중앙은행(Fed)에 따르면 작년 말 현재 미국 기업의 대출 잔액은 1조6100억달러로 2008년 기록했던 사상 최고치를 넘어섰다. CNBC는 은행 CEO들이 기업 대출 증가를 더 빠른 경제 성장의 전주곡으로 보고 있다고 전했다. 존 스텀프 웰스파고 CEO는 “고객과 대화를 나누다 보면 뭔가를 짓고, 추가하고, 어딘가에 투자하고 싶다는 이야기를 점점 더 많이 듣게 된다”며 “미국에서 더 많은 경제활동이 일어나고 있다”고 말했다. 뱅크오브아메리카(BoA) 메릴린치의 브루스 톰슨 최고재무책임자(CFO)는 “올 들어 대기업과 헬스케어, 상업용 부동산 업체들을 중심으로 대출 수요가 점점 증가하고 있다”고 전했다. 마이클 코뱃 씨티그룹 CEO도 “성장 전망은 개선되고 경제는 계속 치유되고 있다”고 말했다.한편 Fed의 양적완화 축소(테이퍼링)가 신흥국에 미친 영향도 크지 않았던 것으로 나타났다. 테이퍼링에 따른 신흥시장 위기는 올해 세계 경제의 최대 리스크로 꼽혀왔다. BoA메릴린치에 따르면 벤 버냉키 Fed 의장이 처음 테이퍼링을 거론한 지난해 5월부터 11월까지 14개 신흥국에서 현지 통화 표시 국채에 대한 외국인 보유액은 0.3% 줄어드는 데 그쳤다. “이는 테이퍼링이 시장 혼란으로 이어질 것이라는 우려가 기우였다는 뜻”이라고 파이낸셜타임스(FT)는 분석했다.\\n\\n### 질문\\n제이미 다이먼 JP모간체이스 CEO가 언급한 미국 경제의 전망은 어떤가?\\n\\n### 선택지\\n1. 비관적이다\\n2. 조심스럽게 낙관적이다\\n3. 낙관적이다\\n4. 부정적이다\\n5. 불확실하다\\n\\n### 문제 해결 가이드라인\\n1. 지문을 끝까지 읽고 핵심 정보를 정리하세요.\\n2. 질문이 요구하는 정보(수치/인물/원인/결과/요지 등)가 무엇인지 정확히 확인하세요.\\n3. 각 선택지가 지문의 어느 부분과 일치하는지 1:1로 대조하세요.\\n4. 지문과 모순되거나 지문에 근거가 없는 선택지는 제외하세요.\\n5. 가장 확실한 근거를 가진 선택지 번호 하나만 선택하세요.\\n\\n정답은 1~5 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\\n정답:<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n3<|im_end|>\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa8be196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'generation-for-nlp-2661',\n",
       " 'label': 3,\n",
       " 'text': '<|im_start|>system\\n당신은 논리적인 **텍스트 분석 및 독해 전문가**입니다.\\n이 문제는 오직 **제공된 지문 내의 정보**만으로 풀어야 합니다.\\n당신의 외부 배경지식을 배제하고, 철저하게 지문에 명시된 내용에 근거하여 판단하십시오.<|im_end|>\\n<|im_start|>user\\n### 지문\\n“올해 미국 경제에는 태양과 달과 별이 한 줄로 서는 행운이 다가오고 있다.”제이미 다이먼 JP모간체이스 최고경영자(CEO·사진)는 지난주 실적발표 후 투자자들과의 화상 회의에서 이렇게 말했다. 평소 미국 경제를 “조심스럽게 낙관한다”고 말해온 다이먼 CEO는 이날 ‘조심스러운’이라는 단어를 사용하지 않았다. 그는 “실제로 경제 전망이 낙관적이기 때문에 ‘낙관적’이라고 말하는 것”이라며 “대기업, 중소기업, 주식시장, 주택시장 등 어느 한 곳에서도 취약한 부분을 찾기 어렵다”고 덧붙였다.다이먼 CEO뿐 아니다. 월스트리트 대형 은행의 최고 경영진도 잇따라 미국 경제에 대한 장밋빛 전망을 쏟아내고 있다. 기업 대출이 사상 최대 수준으로 늘어났기 때문이다. 미국 중앙은행(Fed)에 따르면 작년 말 현재 미국 기업의 대출 잔액은 1조6100억달러로 2008년 기록했던 사상 최고치를 넘어섰다. CNBC는 은행 CEO들이 기업 대출 증가를 더 빠른 경제 성장의 전주곡으로 보고 있다고 전했다. 존 스텀프 웰스파고 CEO는 “고객과 대화를 나누다 보면 뭔가를 짓고, 추가하고, 어딘가에 투자하고 싶다는 이야기를 점점 더 많이 듣게 된다”며 “미국에서 더 많은 경제활동이 일어나고 있다”고 말했다. 뱅크오브아메리카(BoA) 메릴린치의 브루스 톰슨 최고재무책임자(CFO)는 “올 들어 대기업과 헬스케어, 상업용 부동산 업체들을 중심으로 대출 수요가 점점 증가하고 있다”고 전했다. 마이클 코뱃 씨티그룹 CEO도 “성장 전망은 개선되고 경제는 계속 치유되고 있다”고 말했다.한편 Fed의 양적완화 축소(테이퍼링)가 신흥국에 미친 영향도 크지 않았던 것으로 나타났다. 테이퍼링에 따른 신흥시장 위기는 올해 세계 경제의 최대 리스크로 꼽혀왔다. BoA메릴린치에 따르면 벤 버냉키 Fed 의장이 처음 테이퍼링을 거론한 지난해 5월부터 11월까지 14개 신흥국에서 현지 통화 표시 국채에 대한 외국인 보유액은 0.3% 줄어드는 데 그쳤다. “이는 테이퍼링이 시장 혼란으로 이어질 것이라는 우려가 기우였다는 뜻”이라고 파이낸셜타임스(FT)는 분석했다.\\n\\n### 질문\\n제이미 다이먼 JP모간체이스 CEO가 언급한 미국 경제의 전망은 어떤가?\\n\\n### 선택지\\n1. 비관적이다\\n2. 조심스럽게 낙관적이다\\n3. 낙관적이다\\n4. 부정적이다\\n5. 불확실하다\\n\\n### 문제 해결 가이드라인\\n1. 지문을 끝까지 읽고 핵심 정보를 정리하세요.\\n2. 질문이 요구하는 정보(수치/인물/원인/결과/요지 등)가 무엇인지 정확히 확인하세요.\\n3. 각 선택지가 지문의 어느 부분과 일치하는지 1:1로 대조하세요.\\n4. 지문과 모순되거나 지문에 근거가 없는 선택지는 제외하세요.\\n5. 가장 확실한 근거를 가진 선택지 번호 하나만 선택하세요.\\n\\n정답은 1~5 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\\n정답:<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n3<|im_end|>\\n'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f5208e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 텍스트 일부:\n",
      "<|im_start|>system\n",
      "당신은 논리적인 **텍스트 분석 및 독해 전문가**입니다.\n",
      "이 문제는 오직 **제공된 지문 내의 정보**만으로 풀어야 합니다.\n",
      "당신의 외부 배경지식을 배제하고, 철저하게 지문에 명시된 내용에 근거하여 판단하십시오.<|im_end|>\n",
      "<|im_start|>user\n",
      "### 지문\n",
      "“올해 미국 경제에는 태양과 달과 별이 한 줄로 서는 행운이 다가오고 있다.”제이미 다이먼 JP모간체이스 최고경영자(CEO·사진)는 지난주 실적발표 후 투자자들과의 화상 회의에서 이렇게 말했다. 평소 미국 경제를 “조심스럽게 낙관한다”고 말해온 다이먼 CEO는 이날 ‘조심스러운’이라는 단어를 사용하지 않았다. 그는 “실제로 경제 전망이 낙관적이기 때문에 ‘낙관적’이라고 말하는 것”이라며 “대기업, 중소기업, 주식시장, 주택시장 등 어느 한 곳에서도 취약한 부분을 찾기 어렵다”고 덧붙였다.다이먼 CEO뿐 아니다. 월스트리트 대형 은행의 최고 경영진도 잇따라 미국 경제에 대한 장밋빛 전망을 쏟아내고 있다. 기업 대출이 사상 최대 수준으로 늘어났기 때문이다. 미국 중앙은행(Fed)에 따르면 작년 말 현재 미국 기업의 대출 잔액은 1조6100억달러로 2008년 기록했던 사상 최고치를 넘어섰다. CNBC는 은행 CEO들이 기업 대출 증가를 더 빠른 경제 성장의 전주곡으로 보고 있다고 전했다. 존 스텀프 웰스파고 CEO는 “고객과 대화를 나누다 보면 뭔가를 짓고, 추가하고, 어딘가에 투자하고 싶다는 이야기를 점점 더 많이 듣게 된다”며 “미국에서 더 많은 경제활동이 일어나고 있다”고 말했다. 뱅크오브아메리카(BoA) 메릴린치의 브루스 톰슨 최고재무책임자(CFO)는 “올 들어 대기업과 헬스케어, 상업용 부동산 업체들을 중심으로 대출 수요가 점점 증가하고 있다”고 전했다. 마이클 코뱃 씨티그룹 CEO도 “성장 전망은 개선되고 경제는 계속 치유되고 있다”고 말했다.한편 Fed의 양적완화 축소(테이퍼링)가 신흥국에 미친 영향도 크지 않았던 것으로 나타났다. 테이퍼링에 따른 신흥시장 위기는 올해 세계 경제의 최대 리스크로 꼽혀왔다. BoA메릴린치에 따르면 벤 버냉키 Fed 의장이 처음 테이퍼링을 거론한 지난해 5월부터 11월까지 14개 신흥국에서 현지 통화 표시 국채에 대한 외국인 보유액은 0.3% 줄어드는 데 그쳤다. “이는 테이퍼링이 시장 혼란으로 이어질 것이라는 우려가 기우였다는 뜻”이라고 파이낸셜타임스(FT)는 분석했다.\n",
      "\n",
      "### 질문\n",
      "제이미 다이먼 JP모간체이스 CEO가 언급한 미국 경제의 전망은 어떤가?\n",
      "\n",
      "### 선택지\n",
      "1. 비관적이다\n",
      "2. 조심스럽게 낙관적이다\n",
      "3. 낙관적이다\n",
      "4. 부정적이다\n",
      "5. 불확실하다\n",
      "\n",
      "### 문제 해결 가이드라인\n",
      "1. 지문을 끝까지 읽고 핵심 정보를 정리하세요.\n",
      "2. 질문이 요구하는 정보(수치/인물/원인/결과/요지 등)가 무엇인지 정확히 확인하세요.\n",
      "3. 각 선택지가 지문의 어느 부분과 일치하는지 1:1로 대조하세요.\n",
      "4. 지문과 모순되거나 지문에 근거가 없는 선택지는 제외하세요.\n",
      "5. 가장 확실한 근거를 가진 선택지 번호 하나만 선택하세요.\n",
      "\n",
      "정답은 1~5 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\n",
      "정답:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "3<|im_end|>\n",
      "...\n",
      "✅ 처리 성공!\n",
      "Input IDs 길이: 1087\n",
      "Labels 길이: 1087\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "\n",
    "response_template = \"<|im_start|>assistant\\n\" \n",
    "\n",
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template=response_template,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "sample = ds['train'][0]\n",
    "print(f\"원본 텍스트 일부:\\n{sample['text']}...\")\n",
    "\n",
    "tokenized_sample = tokenizer(sample['text'], add_special_tokens=False)\n",
    "batch = data_collator([tokenized_sample])\n",
    "\n",
    "input_ids = batch[\"input_ids\"][0]\n",
    "labels = batch[\"labels\"][0]\n",
    "\n",
    "print(\"✅ 처리 성공!\")\n",
    "print(f\"Input IDs 길이: {len(input_ids)}\")\n",
    "print(f\"Labels 길이: {len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00db5584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([151667,    271, 151668,    271,     18, 151645,    198])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4de120af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4811b2397c6d476999212d3e590b0ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요. 너의 소개를 1줄로 해줘. 그리고 1000자 이내로 간단한 자기소개를 해줘. \n",
      "\n",
      "안녕하세요! 저는 Qwen, 알리바바 그룹이 개발한 초대규모 언어 모델입니다. 저는 다양한 주제에 대해 대화하고, 질문에 답하고, 창의적인 글을 작성하며, 다양한 언어를 지원하는 등 다양한 기능을 제공합니다. 저는 지속적으로 학습과 업데이트\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "prompt = \"안녕하세요. 너의 소개를 1줄로 해줘.\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5aa7e6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요. 너의 소개를 1줄로 해줘. 그리고 1000자 이내로 간단한 자기소개를 해줘. \n",
      "\n",
      "안녕하세요! 저는 Qwen, 알리바바 그룹이 개발한 초대규모 언어 모델입니다. 저는 다양한 주제에 대해 대화하고, 질문에 답하고, 창의적인 글을 작성하며, 다양한 언어를 지원하는 등 다양한 기능을 제공합니다. 저는 지속적으로 학습과 업데이트\n"
     ]
    }
   ],
   "source": [
    "prompt = \"안녕하세요. 너의 소개를 1줄로 해줘.\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f60448f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fca2436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 저는 사용자의 요청에 따라 간단히 대답해주는 비서입니다.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"너는 한국어로 간단히 답하는 비서야.\"},\n",
    "    {\"role\": \"user\", \"content\": \"안녕하세요. 너의 소개를 1줄로 해줘.\"},\n",
    "]\n",
    "\n",
    "prompt_text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False,\n",
    ")\n",
    "\n",
    "inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=False,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "gen_ids = outputs[0][inputs[\"input_ids\"].shape[-1]:]\n",
    "print(tokenizer.decode(gen_ids, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user asked for a one-line introduction in Korean. Let me think about how to respond.\n",
      "\n",
      "First, I need to keep it concise. They want a short introduction, so I shouldn't add extra details. My main role is\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"너는 한국어로 간단히 답하는 비서야.\"},\n",
    "    {\"role\": \"user\", \"content\": \"안녕하세요. 너의 소개를 1줄로 해줘.\"},\n",
    "]\n",
    "\n",
    "prompt_text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True,\n",
    ")\n",
    "\n",
    "inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=False,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "gen_ids = outputs[0][inputs[\"input_ids\"].shape[-1]:]\n",
    "print(tokenizer.decode(gen_ids, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
