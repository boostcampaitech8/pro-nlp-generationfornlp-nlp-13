{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49578ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_root: /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n",
      "sys.path[0]: /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n"
     ]
    }
   ],
   "source": [
    "### TEST\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "nb_dir = Path(os.getcwd())\n",
    "\n",
    "# 프로젝트 루트: notebooks/Jang -> notebooks -> project_root\n",
    "project_root = nb_dir.parents[1]  # /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"project_root:\", project_root)\n",
    "print(\"sys.path[0]:\", sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41af2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77655430c4504b2ea07ae5f4c00dfc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build train messages:   0%|          | 0/1827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3c6db4568d4a18afa457a6581ef5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Serialize train to text:   0%|          | 0/1827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd4c6b651b34ddf967ec5fc37ffb0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build valid messages (teacher forcing):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f41841a01424953a8679670f0dcddbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Serialize valid to text:   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0731579d6848fbafc0e14ee6962824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build valid_gen messages (prompt only):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf8219028be427ba9b9db33dd22a970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Serialize valid_gen to text (+meta):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 1827\n",
      "Validation dataset: 204\n",
      "Validation (gen) dataset: 204\n"
     ]
    }
   ],
   "source": [
    "# 학습 시 사용했던 config 그대로 로드\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer\n",
    "from src.data.data_loader import DataConfig, make_train_valid_dataset\n",
    "from src.prompt.prompt_builder import PromptConfig\n",
    "from src.data.tokenizer_wrapper import TokenizerConfig\n",
    "\n",
    "project_root = Path(\"/data/ephemeral/pro-nlp-generationfornlp-nlp-13\")\n",
    "\n",
    "with open(project_root / \"config.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "data_cfg = DataConfig(\n",
    "    train_path=str(project_root / \"data/train.csv\"),\n",
    "    test_path=str(project_root / \"data/test.csv\"),\n",
    "    valid_ratio=cfg[\"data\"][\"valid_ratio\"],  # 0.1\n",
    "    seed=cfg[\"data\"][\"seed\"],  # 42\n",
    "    do_split=cfg[\"data\"][\"do_split\"],  # True\n",
    ")\n",
    "\n",
    "prompt_cfg = PromptConfig(\n",
    "    templates_dir=str(project_root / \"src/prompt/templates\"),\n",
    "    verbose=cfg[\"prompt\"][\"verbose\"],\n",
    "    policy=cfg[\"prompt\"][\"policy\"],\n",
    ")\n",
    "\n",
    "tokenize_cfg_train = TokenizerConfig(\n",
    "    max_length=cfg[\"tokenizer\"][\"train\"][\"max_length\"],  # 2048\n",
    "    padding=cfg[\"tokenizer\"][\"train\"][\"padding\"],  # False\n",
    "    truncation=cfg[\"tokenizer\"][\"train\"][\"truncation\"],  # True\n",
    "    add_generation_prompt=cfg[\"tokenizer\"][\"train\"][\"add_generation_prompt\"],  # False\n",
    ")\n",
    "\n",
    "tokenize_cfg_gen = TokenizerConfig(\n",
    "    max_length=cfg[\"tokenizer\"][\"gen\"][\"max_length\"],  # 2048\n",
    "    padding=cfg[\"tokenizer\"][\"gen\"][\"padding\"],  # \"max_length\"\n",
    "    truncation=cfg[\"tokenizer\"][\"gen\"][\"truncation\"],  # True\n",
    "    add_generation_prompt=cfg[\"tokenizer\"][\"gen\"][\"add_generation_prompt\"],  # True\n",
    ")\n",
    "\n",
    "model_name = cfg[\"model\"][\"model_name_or_path\"]  # \"Qwen/Qwen3-14B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=cfg[\"model\"][\"trust_remote_code\"],\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "ds = make_train_valid_dataset(\n",
    "    data_cfg=data_cfg,\n",
    "    prompt_cfg=prompt_cfg,\n",
    "    tokenize_cfg_train=tokenize_cfg_train,\n",
    "    tokenize_cfg_gen=tokenize_cfg_gen,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(f\"Train dataset: {len(ds['train'])}\")\n",
    "print(f\"Validation dataset: {len(ds['validation'])}\")\n",
    "print(f\"Validation (gen) dataset: {len(ds['validation_gen'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ea7351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "Loading train data...\n",
      "Loaded 2031 rows\n",
      "\n",
      "Loading tokenizer...\n",
      "Tokenizer loaded!\n",
      "\n",
      "Loading model...\n",
      "Loading Base Model for Inference: Qwen/Qwen3-14B\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b1300090fc4d02882fb3b4343dfae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRA Adapter from: /data/ephemeral/pro-nlp-generationfornlp-nlp-13/models/qwen3_14B_e2/final_model\n",
      "Model loaded from /data/ephemeral/pro-nlp-generationfornlp-nlp-13/models/qwen3_14B_e2/final_model!\n",
      "\n",
      "PromptBuilder ready!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from src.data.preprocessor import parse_problems_column, add_choices_len\n",
    "from src.prompt.prompt_builder import PromptBuilder, PromptConfig\n",
    "from src.training.model_loader import ModelConfig, load_model_inference\n",
    "\n",
    "project_root = Path(\"/data/ephemeral/pro-nlp-generationfornlp-nlp-13\")\n",
    "\n",
    "with open(project_root / \"config.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "print(\"Loading train data...\")\n",
    "train_df = pd.read_csv(project_root / \"data/train.csv\")\n",
    "train_df = parse_problems_column(train_df)\n",
    "train_df = add_choices_len(train_df)\n",
    "print(f\"Loaded {len(train_df)} rows\\n\")\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    cfg[\"model\"][\"model_name_or_path\"],\n",
    "    trust_remote_code=cfg[\"model\"][\"trust_remote_code\"],\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "print(\"Tokenizer loaded!\\n\")\n",
    "\n",
    "print(\"Loading model...\")\n",
    "model_cfg_dict = cfg[\"model\"].copy()\n",
    "model_cfg_dict[\"use_gradient_checkpointing\"] = False\n",
    "model_cfg = ModelConfig(**model_cfg_dict)\n",
    "\n",
    "adapter_path = project_root / cfg[\"inference\"][\"adapter_path\"]\n",
    "model = load_model_inference(model_cfg, str(adapter_path))\n",
    "model.eval()\n",
    "print(f\"Model loaded from {adapter_path}!\\n\")\n",
    "\n",
    "prompt_cfg = PromptConfig(\n",
    "    policy=cfg[\"inference\"][\"prompt\"][\"policy\"],\n",
    "    mode=\"test\",  # generation용\n",
    "    templates_dir=str(project_root / \"src/prompt/templates\"),\n",
    "    verbose=False,\n",
    ")\n",
    "builder = PromptBuilder(prompt_cfg)\n",
    "print(\"PromptBuilder ready!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a7b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(text: str) -> str:\n",
    "    \"\"\"생성된 텍스트에서 답변 추출\"\"\"\n",
    "    numbers = re.findall(r'[1-5]', text)\n",
    "    if numbers:\n",
    "        return numbers[-1]\n",
    "    return \"no\"\n",
    "\n",
    "def generate_for_row(row_dict, max_new_tokens=30):\n",
    "    \"\"\"한 row에 대해 generation 수행\"\"\"\n",
    "    output = builder.build_message(row_dict)\n",
    "    messages = output[\"messages\"]\n",
    "    \n",
    "    prompt_text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        prompt_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=4096\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    full_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    input_length = inputs['input_ids'].shape[1]\n",
    "    generated_ids = output_ids[0][input_length:]\n",
    "    generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    predicted_answer = extract_answer(full_text)\n",
    "    \n",
    "    return {\n",
    "        \"id\": row_dict[\"id\"],\n",
    "        \"true_answer\": row_dict[\"answer\"],  # 정답\n",
    "        \"predicted_answer\": predicted_answer,  # 추출된 답 (1-5 또는 no)\n",
    "        \"generated_text\": generated_text,  # 모델이 실제로 생성한 텍스트 (NEW!)\n",
    "        \"full_output\": full_text,  # 프롬프트 + 생성 텍스트 전체\n",
    "        \"is_correct\": predicted_answer == str(row_dict[\"answer\"]),\n",
    "        \"choices_len\": row_dict[\"choices_len\"],\n",
    "        \"paragraph\": row_dict.get(\"paragraph\", \"\"),\n",
    "        \"question\": row_dict.get(\"question\", \"\"),\n",
    "        \"choices\": row_dict.get(\"choices\", []),\n",
    "    }\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Running Generation on train.csv\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Generating\"):\n",
    "    row_dict = row.to_dict()\n",
    "    result = generate_for_row(row_dict, max_new_tokens=cfg[\"inference\"][\"max_new_tokens\"])\n",
    "    results.append(result)\n",
    "\n",
    "dpo_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Generation Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total samples: {len(dpo_df)}\")\n",
    "print(f\"Correct predictions: {dpo_df['is_correct'].sum()}\")\n",
    "print(f\"Accuracy: {dpo_df['is_correct'].mean():.4f}\")\n",
    "print(f\"\\nBy choices_len:\")\n",
    "print(dpo_df.groupby('choices_len')['is_correct'].agg(['count', 'sum', 'mean']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_df['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c70fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_df['is_correct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_df[dpo_df['is_correct'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8834ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(text: str, k: int) -> str:\n",
    "    \"\"\"텍스트에서 1~k 범위의 답변 추출\"\"\"\n",
    "    numbers = re.findall(rf'[1-{k}]', str(text))\n",
    "    return numbers[-1] if numbers else \"no\"\n",
    "\n",
    "def generate_for_row_with_top5(row_dict, max_new_tokens=30):\n",
    "    \"\"\"한 row에 대해 generation 수행 + 마지막 토큰의 top-5 후보 추출\"\"\"\n",
    "    output = builder.build_message(row_dict)\n",
    "    messages = output[\"messages\"]\n",
    "    \n",
    "    prompt_text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        prompt_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=4096\n",
    "    ).to(device)\n",
    "    \n",
    "    k = int(row_dict[\"choices_len\"])\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "        )\n",
    "    \n",
    "    generated_ids = outputs.sequences[0][input_len:]\n",
    "    generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    last_step_logits = outputs.scores[-2][0]\n",
    "    \n",
    "    top5_values, top5_indices = torch.topk(last_step_logits, k=5)\n",
    "    \n",
    "    top5_candidates = []\n",
    "    probs = torch.softmax(last_step_logits, dim=-1)\n",
    "    \n",
    "    for rank, (logit_val, token_id) in enumerate(zip(top5_values, top5_indices)):\n",
    "        token_text = tokenizer.decode([token_id.item()])\n",
    "        prob_val = probs[token_id].item()\n",
    "        \n",
    "        top5_candidates.append({\n",
    "            \"rank\": rank + 1,\n",
    "            \"token_id\": token_id.item(),\n",
    "            \"token\": token_text,\n",
    "            \"logit\": logit_val.item(),\n",
    "            \"prob\": prob_val,\n",
    "        })\n",
    "    \n",
    "    last_token_id = generated_ids[-1].item()\n",
    "    last_token = tokenizer.decode([last_token_id])\n",
    "    last_token_logit = last_step_logits[last_token_id].item()\n",
    "    last_token_prob = probs[last_token_id].item()\n",
    "    \n",
    "    predicted_answer = extract_answer(generated_text, k=k)\n",
    "    gold = str(row_dict[\"answer\"])\n",
    "    \n",
    "    return {\n",
    "        \"id\": row_dict[\"id\"],\n",
    "        \"choices_len\": k,\n",
    "        \"true_answer\": gold,\n",
    "        \"predicted_answer\": predicted_answer,\n",
    "        \"generated_text\": generated_text,\n",
    "        \"is_correct\": predicted_answer == gold,\n",
    "        \n",
    "        \"last_token\": last_token,\n",
    "        \"last_token_id\": last_token_id,\n",
    "        \"last_token_logit\": last_token_logit,\n",
    "        \"last_token_prob\": last_token_prob,\n",
    "        \n",
    "        \"top5_candidates\": top5_candidates,\n",
    "        \n",
    "        \"prompt\": prompt_text,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "181a8dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'generation-for-nlp-432',\n",
       " 'paragraph': '(가)신라의 한강 유역 확보 (나)관산성 전투(다) 백제의 웅진 천도 (라)고구려의 평양 천도',\n",
       " 'question': '다음 사건을 시기 순으로 바르게 나열한 것은?',\n",
       " 'question_plus': nan,\n",
       " 'choices': ['(가)→(라)→(나)→(다)',\n",
       "  '(나)→(다)→(가)→(라)',\n",
       "  '(다)→(나)→(가)→(라)',\n",
       "  '(라)→(다)→(가)→(나) '],\n",
       " 'choices_len': 4,\n",
       " 'answer': '4',\n",
       " 'predicted_answer': '4',\n",
       " 'is_correct': True,\n",
       " 'generated_text': '<think>\\n\\n</think>\\n\\n4',\n",
       " 'answer_token': '4',\n",
       " 'answer_token_prob': 0.9644182324409485,\n",
       " 'top5_candidates': [{'rank': 1,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 30.5625,\n",
       "   'prob': 0.9644182324409485},\n",
       "  {'rank': 2,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 27.0,\n",
       "   'prob': 0.027358440682291985},\n",
       "  {'rank': 3,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 25.46875,\n",
       "   'prob': 0.005916676949709654},\n",
       "  {'rank': 4,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 24.484375,\n",
       "   'prob': 0.0022109008859843016},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 21.1875,\n",
       "   'prob': 8.180024451576173e-05}],\n",
       " 'margin': 0.9370597917586565,\n",
       " 'prompt': \"<|im_start|>system\\n당신은 **지식 추론(Knowledge Inference) 전문가**입니다.\\n이 유형은 정답이 지문에 그대로 쓰여 있지 않을 수 있으며, 지문은 '조건/단서'를 제공합니다.\\n지문에서 주어진 조건을 정확히 반영하고, 그 조건과 모순되지 않는 범위에서 일반적으로 알려진 지식을 적용해 가장 타당한 선택지 하나를 고르십시오.<|im_end|>\\n<|im_start|>user\\n### 지문\\n(가)신라의 한강 유역 확보 (나)관산성 전투(다) 백제의 웅진 천도 (라)고구려의 평양 천도\\n\\n### 질문\\n다음 사건을 시기 순으로 바르게 나열한 것은?\\n\\n### 선택지\\n1. (가)→(라)→(나)→(다)\\n2. (나)→(다)→(가)→(라)\\n3. (다)→(나)→(가)→(라)\\n4. (라)→(다)→(가)→(나) \\n\\n### 문제 해결 가이드라인\\n1. 지문이 주는 조건/단서를 먼저 정리하세요. (무엇을 가정/설명하고 있는지)\\n2. 필요하면 일반적으로 알려진 지식(개념/원리/사례)을 적용하되, 지문 조건과 모순되면 안 됩니다.\\n3. 선택지 중 조건을 가장 잘 만족하는 것 하나만 고르세요.\\n\\n정답은 1~4 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\\n정답:<|im_end|>\\n<|im_start|>assistant\\n\"}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_for_row_with_top5(train_df.iloc[6,:].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a8dad20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'generation-for-nlp-434',\n",
       " 'choices_len': 4,\n",
       " 'true_answer': '1',\n",
       " 'predicted_answer': '2',\n",
       " 'generated_text': '<think>\\n\\n</think>\\n\\n2',\n",
       " 'is_correct': False,\n",
       " 'last_token': '<|im_end|>',\n",
       " 'last_token_id': 151645,\n",
       " 'last_token_logit': 6.625,\n",
       " 'last_token_prob': 3.967462469667282e-10,\n",
       " 'top5_candidates': [{'rank': 1,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 27.296875,\n",
       "   'prob': 0.376872181892395},\n",
       "  {'rank': 2,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 27.1875,\n",
       "   'prob': 0.33782604336738586},\n",
       "  {'rank': 3,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 26.46875,\n",
       "   'prob': 0.1646432727575302},\n",
       "  {'rank': 4,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 26.15625,\n",
       "   'prob': 0.12045559287071228},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 19.546875,\n",
       "   'prob': 0.00016233487986028194}],\n",
       " 'prompt': \"<|im_start|>system\\n당신은 **지식 추론(Knowledge Inference) 전문가**입니다.\\n이 유형은 정답이 지문에 그대로 쓰여 있지 않을 수 있으며, 지문은 '조건/단서'를 제공합니다.\\n지문에서 주어진 조건을 정확히 반영하고, 그 조건과 모순되지 않는 범위에서 일반적으로 알려진 지식을 적용해 가장 타당한 선택지 하나를 고르십시오.<|im_end|>\\n<|im_start|>user\\n### 지문\\n(가) 황제가 영원히 가시던 길에 엎드려 크게 통곡하던 우리는 …(중략) … 우리민족의 새로운 기백과 책동이 발발하기를 간절히 기대하는 바이다.－동아일보 1926년 6월 12일－\\n\\n### 질문\\n(가) 재위 기간에 있었던 사실이 아닌 것은?\\n\\n### 선택지\\n1. 일본은 동양척식 주식회사를 설립하였다.\\n2. 일본이 간도를 청에 귀속하는 협약을 체결하였다.\\n3. 유생의 병장 중심으로 13도 창의군을 결성하였다.\\n4. 대한제국의 외교권을 박탈하고 통감부를 설치하였다.\\n\\n### 문제 해결 가이드라인\\n1. 지문이 주는 조건/단서를 먼저 정리하세요. (무엇을 가정/설명하고 있는지)\\n2. 필요하면 일반적으로 알려진 지식(개념/원리/사례)을 적용하되, 지문 조건과 모순되면 안 됩니다.\\n3. 선택지 중 조건을 가장 잘 만족하는 것 하나만 고르세요.\\n\\n정답은 1~4 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\\n정답:<|im_end|>\\n<|im_start|>assistant\\n\"}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_for_row_with_top5(train_df.iloc[8,:].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_for_row_with_top5(row_dict, max_new_tokens=30):\n",
    "    \"\"\"한 row에 대해 generation 수행 + 답변 토큰의 top-5 후보 추출\"\"\"\n",
    "    output = builder.build_message(row_dict)\n",
    "    messages = output[\"messages\"]\n",
    "    \n",
    "    prompt_text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        prompt_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=4096\n",
    "    ).to(device)\n",
    "    \n",
    "    k = int(row_dict[\"choices_len\"])\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "        )\n",
    "    \n",
    "    generated_ids = outputs.sequences[0][input_len:]\n",
    "    generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    last_meaningful_idx = -2 if generated_ids[-1].item() == tokenizer.eos_token_id else -1\n",
    "    \n",
    "    answer_step_logits = outputs.scores[last_meaningful_idx][0]\n",
    "    \n",
    "    top5_values, top5_indices = torch.topk(answer_step_logits, k=5)\n",
    "    \n",
    "    top5_candidates = []\n",
    "    probs = torch.softmax(answer_step_logits, dim=-1)\n",
    "    \n",
    "    for rank, (logit_val, token_id) in enumerate(zip(top5_values, top5_indices)):\n",
    "        token_text = tokenizer.decode([token_id.item()])\n",
    "        prob_val = probs[token_id].item()\n",
    "        \n",
    "        top5_candidates.append({\n",
    "            \"rank\": rank + 1,\n",
    "            \"token_id\": token_id.item(),\n",
    "            \"token\": token_text,\n",
    "            \"logit\": logit_val.item(),\n",
    "            \"prob\": prob_val,\n",
    "        })\n",
    "    \n",
    "    answer_token_id = generated_ids[last_meaningful_idx].item()\n",
    "    answer_token = tokenizer.decode([answer_token_id])\n",
    "    answer_token_prob = probs[answer_token_id].item()\n",
    "    \n",
    "    predicted_answer = extract_answer(generated_text, k=k)\n",
    "    gold = str(row_dict[\"answer\"])\n",
    "    \n",
    "    margin = top5_candidates[0]['prob'] - top5_candidates[1]['prob'] if len(top5_candidates) > 1 else 1.0\n",
    "    \n",
    "    return {\n",
    "        \"id\": row_dict[\"id\"],\n",
    "        \"paragraph\": row_dict.get(\"paragraph\", \"\"),\n",
    "        \"question\": row_dict.get(\"question\", \"\"),\n",
    "        \"question_plus\": row_dict.get(\"question_plus\", \"\"),\n",
    "        \"choices\": row_dict.get(\"choices\", []),\n",
    "        \"choices_len\": k,\n",
    "        \n",
    "        \"answer\": gold,\n",
    "        \"predicted_answer\": predicted_answer,\n",
    "        \"is_correct\": predicted_answer == gold,\n",
    "        \n",
    "        \"generated_text\": generated_text,\n",
    "        \"answer_token\": answer_token,\n",
    "        \"answer_token_prob\": answer_token_prob,\n",
    "        \n",
    "        \"top5_candidates\": top5_candidates,\n",
    "        \"margin\": margin,\n",
    "        \n",
    "        \"prompt\": prompt_text,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4862b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'generation-for-nlp-434',\n",
       " 'paragraph': '(가) 황제가 영원히 가시던 길에 엎드려 크게 통곡하던 우리는 …(중략) … 우리민족의 새로운 기백과 책동이 발발하기를 간절히 기대하는 바이다.－동아일보 1926년 6월 12일－',\n",
       " 'question': '(가) 재위 기간에 있었던 사실이 아닌 것은?',\n",
       " 'question_plus': nan,\n",
       " 'choices': ['일본은 동양척식 주식회사를 설립하였다.',\n",
       "  '일본이 간도를 청에 귀속하는 협약을 체결하였다.',\n",
       "  '유생의 병장 중심으로 13도 창의군을 결성하였다.',\n",
       "  '대한제국의 외교권을 박탈하고 통감부를 설치하였다.'],\n",
       " 'choices_len': 4,\n",
       " 'answer': '1',\n",
       " 'predicted_answer': '2',\n",
       " 'is_correct': False,\n",
       " 'generated_text': '<think>\\n\\n</think>\\n\\n2',\n",
       " 'answer_token': '2',\n",
       " 'answer_token_prob': 0.376872181892395,\n",
       " 'top5_candidates': [{'rank': 1,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 27.296875,\n",
       "   'prob': 0.376872181892395},\n",
       "  {'rank': 2,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 27.1875,\n",
       "   'prob': 0.33782604336738586},\n",
       "  {'rank': 3,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 26.46875,\n",
       "   'prob': 0.1646432727575302},\n",
       "  {'rank': 4,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 26.15625,\n",
       "   'prob': 0.12045559287071228},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 19.546875,\n",
       "   'prob': 0.00016233487986028194}],\n",
       " 'margin': 0.039046138525009155,\n",
       " 'prompt': \"<|im_start|>system\\n당신은 **지식 추론(Knowledge Inference) 전문가**입니다.\\n이 유형은 정답이 지문에 그대로 쓰여 있지 않을 수 있으며, 지문은 '조건/단서'를 제공합니다.\\n지문에서 주어진 조건을 정확히 반영하고, 그 조건과 모순되지 않는 범위에서 일반적으로 알려진 지식을 적용해 가장 타당한 선택지 하나를 고르십시오.<|im_end|>\\n<|im_start|>user\\n### 지문\\n(가) 황제가 영원히 가시던 길에 엎드려 크게 통곡하던 우리는 …(중략) … 우리민족의 새로운 기백과 책동이 발발하기를 간절히 기대하는 바이다.－동아일보 1926년 6월 12일－\\n\\n### 질문\\n(가) 재위 기간에 있었던 사실이 아닌 것은?\\n\\n### 선택지\\n1. 일본은 동양척식 주식회사를 설립하였다.\\n2. 일본이 간도를 청에 귀속하는 협약을 체결하였다.\\n3. 유생의 병장 중심으로 13도 창의군을 결성하였다.\\n4. 대한제국의 외교권을 박탈하고 통감부를 설치하였다.\\n\\n### 문제 해결 가이드라인\\n1. 지문이 주는 조건/단서를 먼저 정리하세요. (무엇을 가정/설명하고 있는지)\\n2. 필요하면 일반적으로 알려진 지식(개념/원리/사례)을 적용하되, 지문 조건과 모순되면 안 됩니다.\\n3. 선택지 중 조건을 가장 잘 만족하는 것 하나만 고르세요.\\n\\n정답은 1~4 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\\n정답:<|im_end|>\\n<|im_start|>assistant\\n\"}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_for_row_with_top5(train_df.iloc[8,:].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aadda2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing 100 samples: 100%|██████████| 100/100 [02:11<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 100\n",
      "Correct: 84\n",
      "Accuracy: 0.8400\n",
      "Avg margin: 0.7329\n",
      "\n",
      "--- Sample results ---\n",
      "                       id answer predicted_answer  is_correct    margin\n",
      "0  generation-for-nlp-425      2                2        True  0.825728\n",
      "1  generation-for-nlp-426      1                1        True  0.993448\n",
      "2  generation-for-nlp-427      4                4        True  0.225053\n",
      "3  generation-for-nlp-428      2                2        True  0.643952\n",
      "4  generation-for-nlp-429      3                3        True  0.355850\n",
      "5  generation-for-nlp-431      3                3        True  0.647122\n",
      "6  generation-for-nlp-432      4                4        True  0.937060\n",
      "7  generation-for-nlp-433      3                3        True  0.987931\n",
      "8  generation-for-nlp-434      1                2       False  0.039046\n",
      "9  generation-for-nlp-435      2                2        True  0.876216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = train_df.head(100)\n",
    "\n",
    "results = []\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Testing 100 samples\"):\n",
    "    row_dict = row.to_dict()\n",
    "    result = generate_for_row_with_top5(row_dict, max_new_tokens=30)\n",
    "    results.append(result)\n",
    "\n",
    "dpo_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "print(f\"\\nTotal: {len(dpo_df)}\")\n",
    "print(f\"Correct: {dpo_df['is_correct'].sum()}\")\n",
    "print(f\"Accuracy: {dpo_df['is_correct'].mean():.4f}\")\n",
    "print(f\"Avg margin: {dpo_df['margin'].mean():.4f}\")\n",
    "\n",
    "print(\"\\n--- Sample results ---\")\n",
    "print(dpo_df[['id', 'answer', 'predicted_answer', 'is_correct', 'margin']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eee4e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2031/2031 [52:49<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved to: /data/ephemeral/pro-nlp-generationfornlp-nlp-13/data/dpo_train.csv\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Generating\"):\n",
    "    row_dict = row.to_dict()\n",
    "    result = generate_for_row_with_top5(row_dict, max_new_tokens=30)\n",
    "    results.append(result)\n",
    "\n",
    "dpo_df = pd.DataFrame(results)\n",
    "\n",
    "output_path = project_root / \"data/dpo_train.csv\"\n",
    "dpo_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nSaved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d5b435fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(dpo_df['margin'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "27efb87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2031.000000\n",
       "mean        0.968466\n",
       "std         0.131539\n",
       "min         0.000000\n",
       "25%         0.997708\n",
       "50%         0.999816\n",
       "75%         0.999988\n",
       "max         0.999999\n",
       "Name: margin, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_df['margin'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4e5e6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dpo_df[dpo_df['is_correct'] == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9537febf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'rank': 1,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 30.4375,\n",
       "   'prob': 0.8902146816253662},\n",
       "  {'rank': 2,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 27.8125,\n",
       "   'prob': 0.06448694318532944},\n",
       "  {'rank': 3,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 26.984375,\n",
       "   'prob': 0.02817225456237793},\n",
       "  {'rank': 4,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 26.484375,\n",
       "   'prob': 0.017087338492274284},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 20.0625,\n",
       "   'prob': 2.7777268769568764e-05}],\n",
       " [{'rank': 1,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 32.3125,\n",
       "   'prob': 0.996335506439209},\n",
       "  {'rank': 2,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 26.46875,\n",
       "   'prob': 0.002887335605919361},\n",
       "  {'rank': 3,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 24.578125,\n",
       "   'prob': 0.0004359224403742701},\n",
       "  {'rank': 4,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 24.3125,\n",
       "   'prob': 0.0003342333366163075},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 19.765625,\n",
       "   'prob': 3.5429661693342496e-06}],\n",
       " [{'rank': 1,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 28.171875,\n",
       "   'prob': 0.4932025074958801},\n",
       "  {'rank': 2,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 27.5625,\n",
       "   'prob': 0.26814955472946167},\n",
       "  {'rank': 3,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 26.8125,\n",
       "   'prob': 0.1266648769378662},\n",
       "  {'rank': 4,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 26.6875,\n",
       "   'prob': 0.11178135871887207},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 20.125,\n",
       "   'prob': 0.0001578744559083134}],\n",
       " [{'rank': 1,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 29.71875,\n",
       "   'prob': 0.7793891429901123},\n",
       "  {'rank': 2,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 27.96875,\n",
       "   'prob': 0.1354375034570694},\n",
       "  {'rank': 3,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 27.265625,\n",
       "   'prob': 0.06704643368721008},\n",
       "  {'rank': 4,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 25.953125,\n",
       "   'prob': 0.018045304343104362},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 20.265625,\n",
       "   'prob': 6.113843119237572e-05}],\n",
       " [{'rank': 1,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 27.859375,\n",
       "   'prob': 0.5735424160957336},\n",
       "  {'rank': 2,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 26.890625,\n",
       "   'prob': 0.21769215166568756},\n",
       "  {'rank': 3,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 26.34375,\n",
       "   'prob': 0.12599055469036102},\n",
       "  {'rank': 4,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 25.921875,\n",
       "   'prob': 0.08262662589550018},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 19.25,\n",
       "   'prob': 0.00010460717021487653}],\n",
       " [{'rank': 1,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 28.859375,\n",
       "   'prob': 0.7781912088394165},\n",
       "  {'rank': 2,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 27.078125,\n",
       "   'prob': 0.13106878101825714},\n",
       "  {'rank': 3,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 26.390625,\n",
       "   'prob': 0.06590552628040314},\n",
       "  {'rank': 4,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 25.40625,\n",
       "   'prob': 0.024627093225717545},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 20.46875,\n",
       "   'prob': 0.00017663801554590464}],\n",
       " [{'rank': 1,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 30.5625,\n",
       "   'prob': 0.9644182324409485},\n",
       "  {'rank': 2,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 27.0,\n",
       "   'prob': 0.027358440682291985},\n",
       "  {'rank': 3,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 25.46875,\n",
       "   'prob': 0.005916676949709654},\n",
       "  {'rank': 4,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 24.484375,\n",
       "   'prob': 0.0022109008859843016},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 21.1875,\n",
       "   'prob': 8.180024451576173e-05}],\n",
       " [{'rank': 1,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 30.734375,\n",
       "   'prob': 0.9929025769233704},\n",
       "  {'rank': 2,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 25.4375,\n",
       "   'prob': 0.004971678834408522},\n",
       "  {'rank': 3,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 24.265625,\n",
       "   'prob': 0.001540154218673706},\n",
       "  {'rank': 4,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 23.265625,\n",
       "   'prob': 0.0005665910430252552},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 19.671875,\n",
       "   'prob': 1.5578440070385113e-05}],\n",
       " [{'rank': 1,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 27.296875,\n",
       "   'prob': 0.376872181892395},\n",
       "  {'rank': 2,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 27.1875,\n",
       "   'prob': 0.33782604336738586},\n",
       "  {'rank': 3,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 26.46875,\n",
       "   'prob': 0.1646432727575302},\n",
       "  {'rank': 4,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 26.15625,\n",
       "   'prob': 0.12045559287071228},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 19.546875,\n",
       "   'prob': 0.00016233487986028194}],\n",
       " [{'rank': 1,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 30.96875,\n",
       "   'prob': 0.9192078113555908},\n",
       "  {'rank': 2,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 27.90625,\n",
       "   'prob': 0.04299192503094673},\n",
       "  {'rank': 3,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 27.265625,\n",
       "   'prob': 0.022655151784420013},\n",
       "  {'rank': 4,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 26.859375,\n",
       "   'prob': 0.01509158406406641},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 20.859375,\n",
       "   'prob': 3.7408295611385256e-05}]]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_df['top5_candidates'][:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f885d10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     margin_quantile\n",
      "0.1         0.976541\n",
      "0.2         0.995709\n",
      "0.3         0.998641\n",
      "0.4         0.999511\n",
      "0.5         0.999816\n",
      "0.6         0.999919\n",
      "0.7         0.999977\n",
      "0.8         0.999993\n",
      "0.9         0.999997\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "m = pd.to_numeric(dpo_df[\"margin\"], errors=\"coerce\")\n",
    "\n",
    "qs = np.arange(0.1, 1.0, 0.1)\n",
    "qvals = m.quantile(qs)\n",
    "\n",
    "print(qvals.to_frame(\"margin_quantile\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c02a406c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_correct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.489123</td>\n",
       "      <td>0.359105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151278</td>\n",
       "      <td>0.396594</td>\n",
       "      <td>0.869378</td>\n",
       "      <td>0.995731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1981.0</td>\n",
       "      <td>0.980565</td>\n",
       "      <td>0.092733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998114</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count      mean       std  min       25%       50%       75%  \\\n",
       "is_correct                                                                  \n",
       "False         50.0  0.489123  0.359105  0.0  0.151278  0.396594  0.869378   \n",
       "True        1981.0  0.980565  0.092733  0.0  0.998114  0.999834  0.999989   \n",
       "\n",
       "                 max  \n",
       "is_correct            \n",
       "False       0.995731  \n",
       "True        0.999999  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_df.groupby(\"is_correct\")[\"margin\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c93c1b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d9d023b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_correct</th>\n",
       "      <th>choices_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>4</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.481143</td>\n",
       "      <td>0.367484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136194</td>\n",
       "      <td>0.402413</td>\n",
       "      <td>0.881730</td>\n",
       "      <td>0.995731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.560939</td>\n",
       "      <td>0.295064</td>\n",
       "      <td>0.286102</td>\n",
       "      <td>0.390407</td>\n",
       "      <td>0.390776</td>\n",
       "      <td>0.756370</td>\n",
       "      <td>0.981042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th>4</th>\n",
       "      <td>747.0</td>\n",
       "      <td>0.959025</td>\n",
       "      <td>0.132859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.990799</td>\n",
       "      <td>0.998227</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1234.0</td>\n",
       "      <td>0.993603</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>0.023415</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count      mean       std       min       25%  \\\n",
       "is_correct choices_len                                                   \n",
       "False      4              45.0  0.481143  0.367484  0.000000  0.136194   \n",
       "           5               5.0  0.560939  0.295064  0.286102  0.390407   \n",
       "True       4             747.0  0.959025  0.132859  0.000000  0.990799   \n",
       "           5            1234.0  0.993603  0.051753  0.023415  0.999805   \n",
       "\n",
       "                             50%       75%       max  \n",
       "is_correct choices_len                                \n",
       "False      4            0.402413  0.881730  0.995731  \n",
       "           5            0.390776  0.756370  0.981042  \n",
       "True       4            0.998227  0.999586  0.999993  \n",
       "           5            0.999970  0.999996  0.999999  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_df.groupby([\"is_correct\", \"choices_len\"])[\"margin\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c52d618e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2031.000000\n",
       "mean        0.981106\n",
       "std         0.079558\n",
       "min         0.365699\n",
       "25%         0.998633\n",
       "50%         0.999886\n",
       "75%         0.999993\n",
       "max         1.000000\n",
       "Name: answer_token_prob, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_df['answer_token_prob'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "17cf7418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>question_plus</th>\n",
       "      <th>choices</th>\n",
       "      <th>choices_len</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>answer_token</th>\n",
       "      <th>answer_token_prob</th>\n",
       "      <th>top5_candidates</th>\n",
       "      <th>margin</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>generation-for-nlp-425</td>\n",
       "      <td>상소하여 아뢰기를 , “신이 좌참 찬 송준길이 올린 차자를 보았는데 , 상복(喪服)...</td>\n",
       "      <td>상소한 인물이 속한 붕당에 대한 설명으로 옳은 것만을 모두 고르면?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ㄱ, ㄴ, ㄱ, ㄷ, ㄴ, ㄹ, ㄷ, ㄹ]</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\n2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.890215</td>\n",
       "      <td>[{'rank': 1, 'token_id': 17, 'token': '2', 'lo...</td>\n",
       "      <td>0.825728</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n당신은 **지식 추론(Knowledge Infe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>generation-for-nlp-427</td>\n",
       "      <td>나는 삼한(三韓) 산천의 음덕을 입어 대업을 이루었다.(가)는/은 수덕(水德)이 순...</td>\n",
       "      <td>(가) 지역에 대한 설명으로 옳은 것은?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[이곳에 대장도감을 설치하여 재조대장경을 만들었다., 지눌이 이곳에서 수선사 결사운...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\n4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.493203</td>\n",
       "      <td>[{'rank': 1, 'token_id': 19, 'token': '4', 'lo...</td>\n",
       "      <td>0.225053</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n당신은 **지식 추론(Knowledge Infe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generation-for-nlp-428</td>\n",
       "      <td>이 날 소정방이 부총관 김인문 등과 함께 기 벌포에 도착하여 백제 군사와 마주쳤다....</td>\n",
       "      <td>밑줄 친 ‘그’에 대한 설명으로 옳은 것은?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[살수에서 수의 군대를 물리쳤다 ., 김춘추 의 신라 왕위 계승을 지원하였다 ., ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\n2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.779389</td>\n",
       "      <td>[{'rank': 1, 'token_id': 17, 'token': '2', 'lo...</td>\n",
       "      <td>0.643952</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n당신은 **지식 추론(Knowledge Infe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>generation-for-nlp-429</td>\n",
       "      <td>선비들 수만 명이 대궐 앞에 모여 만 동묘와 서원을 다시 설립할 것을 청하니, (가...</td>\n",
       "      <td>(가) 인물이 추진한 정책으로 옳지 않은 것은?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[사창제를 실시하였다 ., 대전회통을 편찬하였다 ., 비변사의 기능을 강화하였다 ....</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\n3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.573542</td>\n",
       "      <td>[{'rank': 1, 'token_id': 18, 'token': '3', 'lo...</td>\n",
       "      <td>0.355850</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n당신은 **지식 추론(Knowledge Infe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>generation-for-nlp-431</td>\n",
       "      <td>(가)의 사신 고제덕 등이 일본에 와서 왕이 보낸 국서를 전하였다. 그 국서에 이르...</td>\n",
       "      <td>(가) 국가에 대한 설명으로 옳은 것은?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[나 당연합군의 공격으로 멸망하였다 ., 9주 5소경의 지방 행정 구역을 두었다 ....</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\n3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.778191</td>\n",
       "      <td>[{'rank': 1, 'token_id': 18, 'token': '3', 'lo...</td>\n",
       "      <td>0.647122</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n당신은 **지식 추론(Knowledge Infe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>generation-for-nlp-2816</td>\n",
       "      <td>부동산 전문가들은 전·월세 대책 이후 거래와 투자심리가 위축됐다는 점엔 대체로 의견...</td>\n",
       "      <td>부동산 전문가들이 올해 부동산 시장에 대해 예상하는 주된 이유는 무엇인가?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[정부의 내수 활성화 정책, 전셋값 상승세, 금리 인하, 소형 주택 가격 하락, 부...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\n1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.511315</td>\n",
       "      <td>[{'rank': 1, 'token_id': 16, 'token': '1', 'lo...</td>\n",
       "      <td>0.023415</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n당신은 논리적인 **텍스트 분석 및 독해 전문가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>generation-for-nlp-2827</td>\n",
       "      <td>서울 강남 지역에 남아 있는 마지막 무허가 집단거주지인 구룡마을(28만6929㎡) ...</td>\n",
       "      <td>구룡마을 개발이 백지화된 이유로 가장 적절한 것은 무엇인가?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[서울시와 강남구 간의 갈등, 주민들의 반대, 부동산 시장의 침체, 개발계획 수립 ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\n4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.934773</td>\n",
       "      <td>[{'rank': 1, 'token_id': 19, 'token': '4', 'lo...</td>\n",
       "      <td>0.870160</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n당신은 논리적인 **텍스트 분석 및 독해 전문가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>generation-for-nlp-2855</td>\n",
       "      <td>공급 과잉 논란 속에 배후 임대수요 확보 여부가 ‘수익형 부동산’인 오피스텔 선택 ...</td>\n",
       "      <td>오피스텔 투자에서 안정적인 임대수요를 확보하기 위해 가장 중요한 요소는 무엇인가?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[공급 과잉 여부, 업무 밀집지역, 교통 여건, 임대료 수준, 세입자의 연령대]</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\n2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>[{'rank': 1, 'token_id': 17, 'token': '2', 'lo...</td>\n",
       "      <td>0.983466</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n당신은 논리적인 **텍스트 분석 및 독해 전문가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>generation-for-nlp-2878</td>\n",
       "      <td>중국인 관광객이 국내 면세점 이용액에서 처음으로 한국인을 앞섰다.28일 관세청이 국...</td>\n",
       "      <td>중국인이 국내 면세점에서 처음으로 한국인을 앞선 시점은 언제인가?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2010년, 2015년, 2021년, 2022년, 2023년]</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\n5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.926345</td>\n",
       "      <td>[{'rank': 1, 'token_id': 20, 'token': '5', 'lo...</td>\n",
       "      <td>0.876478</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n당신은 논리적인 **텍스트 분석 및 독해 전문가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>generation-for-nlp-2894</td>\n",
       "      <td>넷기어코리아(지사장 김진겸, 이하 넷기어)가 뮤럴 캔버스를 가지고 넷기어 SNS에서...</td>\n",
       "      <td>넷기어가 모집하는 '뮤럴 공식 도슨트'의 주요 역할은 무엇인가?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[전시물 설명 및 안내, 고객 서비스 제공, 제품 판매 촉진, 온라인 강좌 콘텐츠 ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\n4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.985284</td>\n",
       "      <td>[{'rank': 1, 'token_id': 19, 'token': '4', 'lo...</td>\n",
       "      <td>0.971662</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n당신은 논리적인 **텍스트 분석 및 독해 전문가...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id  \\\n",
       "0      generation-for-nlp-425   \n",
       "2      generation-for-nlp-427   \n",
       "3      generation-for-nlp-428   \n",
       "4      generation-for-nlp-429   \n",
       "5      generation-for-nlp-431   \n",
       "...                       ...   \n",
       "1961  generation-for-nlp-2816   \n",
       "1969  generation-for-nlp-2827   \n",
       "1994  generation-for-nlp-2855   \n",
       "2013  generation-for-nlp-2878   \n",
       "2027  generation-for-nlp-2894   \n",
       "\n",
       "                                              paragraph  \\\n",
       "0     상소하여 아뢰기를 , “신이 좌참 찬 송준길이 올린 차자를 보았는데 , 상복(喪服)...   \n",
       "2     나는 삼한(三韓) 산천의 음덕을 입어 대업을 이루었다.(가)는/은 수덕(水德)이 순...   \n",
       "3     이 날 소정방이 부총관 김인문 등과 함께 기 벌포에 도착하여 백제 군사와 마주쳤다....   \n",
       "4     선비들 수만 명이 대궐 앞에 모여 만 동묘와 서원을 다시 설립할 것을 청하니, (가...   \n",
       "5     (가)의 사신 고제덕 등이 일본에 와서 왕이 보낸 국서를 전하였다. 그 국서에 이르...   \n",
       "...                                                 ...   \n",
       "1961  부동산 전문가들은 전·월세 대책 이후 거래와 투자심리가 위축됐다는 점엔 대체로 의견...   \n",
       "1969  서울 강남 지역에 남아 있는 마지막 무허가 집단거주지인 구룡마을(28만6929㎡) ...   \n",
       "1994  공급 과잉 논란 속에 배후 임대수요 확보 여부가 ‘수익형 부동산’인 오피스텔 선택 ...   \n",
       "2013  중국인 관광객이 국내 면세점 이용액에서 처음으로 한국인을 앞섰다.28일 관세청이 국...   \n",
       "2027  넷기어코리아(지사장 김진겸, 이하 넷기어)가 뮤럴 캔버스를 가지고 넷기어 SNS에서...   \n",
       "\n",
       "                                           question  question_plus  \\\n",
       "0             상소한 인물이 속한 붕당에 대한 설명으로 옳은 것만을 모두 고르면?            NaN   \n",
       "2                            (가) 지역에 대한 설명으로 옳은 것은?            NaN   \n",
       "3                          밑줄 친 ‘그’에 대한 설명으로 옳은 것은?            NaN   \n",
       "4                        (가) 인물이 추진한 정책으로 옳지 않은 것은?            NaN   \n",
       "5                            (가) 국가에 대한 설명으로 옳은 것은?            NaN   \n",
       "...                                             ...            ...   \n",
       "1961      부동산 전문가들이 올해 부동산 시장에 대해 예상하는 주된 이유는 무엇인가?            NaN   \n",
       "1969              구룡마을 개발이 백지화된 이유로 가장 적절한 것은 무엇인가?            NaN   \n",
       "1994  오피스텔 투자에서 안정적인 임대수요를 확보하기 위해 가장 중요한 요소는 무엇인가?            NaN   \n",
       "2013           중국인이 국내 면세점에서 처음으로 한국인을 앞선 시점은 언제인가?            NaN   \n",
       "2027            넷기어가 모집하는 '뮤럴 공식 도슨트'의 주요 역할은 무엇인가?            NaN   \n",
       "\n",
       "                                                choices  choices_len answer  \\\n",
       "0                              [ㄱ, ㄴ, ㄱ, ㄷ, ㄴ, ㄹ, ㄷ, ㄹ]            4      2   \n",
       "2     [이곳에 대장도감을 설치하여 재조대장경을 만들었다., 지눌이 이곳에서 수선사 결사운...            4      4   \n",
       "3     [살수에서 수의 군대를 물리쳤다 ., 김춘추 의 신라 왕위 계승을 지원하였다 ., ...            4      2   \n",
       "4     [사창제를 실시하였다 ., 대전회통을 편찬하였다 ., 비변사의 기능을 강화하였다 ....            4      3   \n",
       "5     [나 당연합군의 공격으로 멸망하였다 ., 9주 5소경의 지방 행정 구역을 두었다 ....            4      3   \n",
       "...                                                 ...          ...    ...   \n",
       "1961  [정부의 내수 활성화 정책, 전셋값 상승세, 금리 인하, 소형 주택 가격 하락, 부...            5      1   \n",
       "1969  [서울시와 강남구 간의 갈등, 주민들의 반대, 부동산 시장의 침체, 개발계획 수립 ...            5      4   \n",
       "1994       [공급 과잉 여부, 업무 밀집지역, 교통 여건, 임대료 수준, 세입자의 연령대]            5      2   \n",
       "2013                [2010년, 2015년, 2021년, 2022년, 2023년]            5      5   \n",
       "2027  [전시물 설명 및 안내, 고객 서비스 제공, 제품 판매 촉진, 온라인 강좌 콘텐츠 ...            5      4   \n",
       "\n",
       "     predicted_answer  is_correct            generated_text answer_token  \\\n",
       "0                   2        True  <think>\\n\\n</think>\\n\\n2            2   \n",
       "2                   4        True  <think>\\n\\n</think>\\n\\n4            4   \n",
       "3                   2        True  <think>\\n\\n</think>\\n\\n2            2   \n",
       "4                   3        True  <think>\\n\\n</think>\\n\\n3            3   \n",
       "5                   3        True  <think>\\n\\n</think>\\n\\n3            3   \n",
       "...               ...         ...                       ...          ...   \n",
       "1961                1        True  <think>\\n\\n</think>\\n\\n1            1   \n",
       "1969                4        True  <think>\\n\\n</think>\\n\\n4            4   \n",
       "1994                2        True  <think>\\n\\n</think>\\n\\n2            2   \n",
       "2013                5        True  <think>\\n\\n</think>\\n\\n5            5   \n",
       "2027                4        True  <think>\\n\\n</think>\\n\\n4            4   \n",
       "\n",
       "      answer_token_prob                                    top5_candidates  \\\n",
       "0              0.890215  [{'rank': 1, 'token_id': 17, 'token': '2', 'lo...   \n",
       "2              0.493203  [{'rank': 1, 'token_id': 19, 'token': '4', 'lo...   \n",
       "3              0.779389  [{'rank': 1, 'token_id': 17, 'token': '2', 'lo...   \n",
       "4              0.573542  [{'rank': 1, 'token_id': 18, 'token': '3', 'lo...   \n",
       "5              0.778191  [{'rank': 1, 'token_id': 18, 'token': '3', 'lo...   \n",
       "...                 ...                                                ...   \n",
       "1961           0.511315  [{'rank': 1, 'token_id': 16, 'token': '1', 'lo...   \n",
       "1969           0.934773  [{'rank': 1, 'token_id': 19, 'token': '4', 'lo...   \n",
       "1994           0.991525  [{'rank': 1, 'token_id': 17, 'token': '2', 'lo...   \n",
       "2013           0.926345  [{'rank': 1, 'token_id': 20, 'token': '5', 'lo...   \n",
       "2027           0.985284  [{'rank': 1, 'token_id': 19, 'token': '4', 'lo...   \n",
       "\n",
       "        margin                                             prompt  \n",
       "0     0.825728  <|im_start|>system\\n당신은 **지식 추론(Knowledge Infe...  \n",
       "2     0.225053  <|im_start|>system\\n당신은 **지식 추론(Knowledge Infe...  \n",
       "3     0.643952  <|im_start|>system\\n당신은 **지식 추론(Knowledge Infe...  \n",
       "4     0.355850  <|im_start|>system\\n당신은 **지식 추론(Knowledge Infe...  \n",
       "5     0.647122  <|im_start|>system\\n당신은 **지식 추론(Knowledge Infe...  \n",
       "...        ...                                                ...  \n",
       "1961  0.023415  <|im_start|>system\\n당신은 논리적인 **텍스트 분석 및 독해 전문가...  \n",
       "1969  0.870160  <|im_start|>system\\n당신은 논리적인 **텍스트 분석 및 독해 전문가...  \n",
       "1994  0.983466  <|im_start|>system\\n당신은 논리적인 **텍스트 분석 및 독해 전문가...  \n",
       "2013  0.876478  <|im_start|>system\\n당신은 논리적인 **텍스트 분석 및 독해 전문가...  \n",
       "2027  0.971662  <|im_start|>system\\n당신은 논리적인 **텍스트 분석 및 독해 전문가...  \n",
       "\n",
       "[310 rows x 15 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_df[dpo_df['answer_token_prob'] < 0.995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0be4e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_true = dpo_df.loc[dpo_df.is_correct, \"margin\"].quantile(0.2)\n",
    "soft_true = dpo_df[(dpo_df.is_correct) & (dpo_df.margin <= thr_true)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f13f6b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    397.000000\n",
       "mean       0.942596\n",
       "std        0.115466\n",
       "min        0.382857\n",
       "25%        0.952953\n",
       "50%        0.991295\n",
       "75%        0.996187\n",
       "max        0.998230\n",
       "Name: answer_token_prob, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_true['answer_token_prob'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7f89b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df = dpo_df[dpo_df.is_correct == False]\n",
    "soft_true = dpo_df[(dpo_df.is_correct) & (dpo_df.margin <= 0.995)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "161a4b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'generation-for-nlp-425',\n",
       " 'paragraph': '상소하여 아뢰기를 , “신이 좌참 찬 송준길이 올린 차자를 보았는데 , 상복(喪服) 절차에 대하여 논한 것이 신과는 큰 차이가 있었습니다 . 장자를 위하여 3년을 입는 까닭은 위로 ‘정체(正體)’가 되기 때문이고 또 전 중(傳重: 조상의 제사나 가문의 법통을 전함)하기 때문입니다 . …(중략) … 무엇보다 중요한 것은 할아버지와 아버지의 뒤를 이은 ‘정체’이지, 꼭 첫째이기 때문에 참 최 3년 복을 입는 것은 아닙니다 .”라고 하였다 .－현종실록 －ㄱ.기 사환국으로 정권을 장악하였다 .ㄴ.인 조반정을 주도 하여 집권세력이 되었다 .ㄷ.정조 시기에 탕평 정치의 한 축을 이루었다 .ㄹ.이 이와 성혼의 문인을 중심으로 형성되었다.',\n",
       " 'question': '상소한 인물이 속한 붕당에 대한 설명으로 옳은 것만을 모두 고르면?',\n",
       " 'question_plus': nan,\n",
       " 'choices': ['ㄱ, ㄴ', 'ㄱ, ㄷ', 'ㄴ, ㄹ', 'ㄷ, ㄹ'],\n",
       " 'choices_len': 4,\n",
       " 'answer': '2',\n",
       " 'predicted_answer': '2',\n",
       " 'is_correct': True,\n",
       " 'generated_text': '<think>\\n\\n</think>\\n\\n2',\n",
       " 'answer_token': '2',\n",
       " 'answer_token_prob': 0.8902146816253662,\n",
       " 'top5_candidates': [{'rank': 1,\n",
       "   'token_id': 17,\n",
       "   'token': '2',\n",
       "   'logit': 30.4375,\n",
       "   'prob': 0.8902146816253662},\n",
       "  {'rank': 2,\n",
       "   'token_id': 19,\n",
       "   'token': '4',\n",
       "   'logit': 27.8125,\n",
       "   'prob': 0.06448694318532944},\n",
       "  {'rank': 3,\n",
       "   'token_id': 18,\n",
       "   'token': '3',\n",
       "   'logit': 26.984375,\n",
       "   'prob': 0.02817225456237793},\n",
       "  {'rank': 4,\n",
       "   'token_id': 16,\n",
       "   'token': '1',\n",
       "   'logit': 26.484375,\n",
       "   'prob': 0.017087338492274284},\n",
       "  {'rank': 5,\n",
       "   'token_id': 20,\n",
       "   'token': '5',\n",
       "   'logit': 20.0625,\n",
       "   'prob': 2.7777268769568764e-05}],\n",
       " 'margin': 0.8257277384400368,\n",
       " 'prompt': \"<|im_start|>system\\n당신은 **지식 추론(Knowledge Inference) 전문가**입니다.\\n이 유형은 정답이 지문에 그대로 쓰여 있지 않을 수 있으며, 지문은 '조건/단서'를 제공합니다.\\n지문에서 주어진 조건을 정확히 반영하고, 그 조건과 모순되지 않는 범위에서 일반적으로 알려진 지식을 적용해 가장 타당한 선택지 하나를 고르십시오.<|im_end|>\\n<|im_start|>user\\n### 지문\\n상소하여 아뢰기를 , “신이 좌참 찬 송준길이 올린 차자를 보았는데 , 상복(喪服) 절차에 대하여 논한 것이 신과는 큰 차이가 있었습니다 . 장자를 위하여 3년을 입는 까닭은 위로 ‘정체(正體)’가 되기 때문이고 또 전 중(傳重: 조상의 제사나 가문의 법통을 전함)하기 때문입니다 . …(중략) … 무엇보다 중요한 것은 할아버지와 아버지의 뒤를 이은 ‘정체’이지, 꼭 첫째이기 때문에 참 최 3년 복을 입는 것은 아닙니다 .”라고 하였다 .－현종실록 －ㄱ.기 사환국으로 정권을 장악하였다 .ㄴ.인 조반정을 주도 하여 집권세력이 되었다 .ㄷ.정조 시기에 탕평 정치의 한 축을 이루었다 .ㄹ.이 이와 성혼의 문인을 중심으로 형성되었다.\\n\\n### 질문\\n상소한 인물이 속한 붕당에 대한 설명으로 옳은 것만을 모두 고르면?\\n\\n### 선택지\\n1. ㄱ, ㄴ\\n2. ㄱ, ㄷ\\n3. ㄴ, ㄹ\\n4. ㄷ, ㄹ\\n\\n### 문제 해결 가이드라인\\n1. 지문이 주는 조건/단서를 먼저 정리하세요. (무엇을 가정/설명하고 있는지)\\n2. 필요하면 일반적으로 알려진 지식(개념/원리/사례)을 적용하되, 지문 조건과 모순되면 안 됩니다.\\n3. 선택지 중 조건을 가장 잘 만족하는 것 하나만 고르세요.\\n\\n정답은 1~4 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\\n정답:<|im_end|>\\n<|im_start|>assistant\\n\"}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_df.iloc[0,:].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2971009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "def wrap_answer(d: str) -> str:\n",
    "    return f\"<think>\\n\\n</think>\\n\\n{d}\"\n",
    "\n",
    "def normalize_digit(token_text: str, k: int) -> Optional[str]:\n",
    "    if token_text is None:\n",
    "        return None\n",
    "    m = re.findall(rf\"[1-{k}]\", str(token_text))\n",
    "    return m[-1] if m else None\n",
    "\n",
    "def pick_rejected_digits(row: Dict[str, Any], num_rej: int) -> List[str]:\n",
    "    k = int(row[\"choices_len\"])\n",
    "    gold = str(row[\"answer\"])\n",
    "\n",
    "    picked: List[str] = []\n",
    "\n",
    "    # 1) top5_candidates에서 1..K 숫자만 뽑기\n",
    "    for c in (row.get(\"top5_candidates\") or []):\n",
    "        d = normalize_digit(c.get(\"token\"), k)\n",
    "        if d is None or d == gold or d in picked:\n",
    "            continue\n",
    "        picked.append(d)\n",
    "        if len(picked) >= num_rej:\n",
    "            return picked\n",
    "\n",
    "    # 2) 부족하면 fallback으로 1..K 중 gold 제외로 채우기\n",
    "    for d in map(str, range(1, k + 1)):\n",
    "        if d == gold or d in picked:\n",
    "            continue\n",
    "        picked.append(d)\n",
    "        if len(picked) >= num_rej:\n",
    "            break\n",
    "\n",
    "    return picked\n",
    "\n",
    "def make_pairs_for_row(row: Dict[str, Any], num_rej: int, source: str) -> List[Dict[str, Any]]:\n",
    "    prompt = row[\"prompt\"]          # 이미 <|im_start|>assistant\\n 까지 포함된 prompt\n",
    "    gold = str(row[\"answer\"])\n",
    "    k = int(row[\"choices_len\"])\n",
    "\n",
    "    rejected_digits = pick_rejected_digits(row, num_rej=num_rej)\n",
    "\n",
    "    pairs = []\n",
    "    for rd in rejected_digits:\n",
    "        pairs.append({\n",
    "            \"prompt\": prompt,\n",
    "            \"chosen\": wrap_answer(gold),\n",
    "            \"rejected\": wrap_answer(rd),\n",
    "            \"meta\": {\n",
    "                \"id\": row.get(\"id\"),\n",
    "                \"choices_len\": k,\n",
    "                \"source\": source,\n",
    "                \"margin\": row.get(\"margin\"),\n",
    "                \"gold\": gold,\n",
    "                \"rejected_digit\": rd,\n",
    "                \"is_correct\": bool(row.get(\"is_correct\")),\n",
    "            }\n",
    "        })\n",
    "    return pairs\n",
    "\n",
    "def build_dpo_dataset(dpo_df, margin_thr: float = 0.995) -> List[Dict[str, Any]]:\n",
    "    incorrect_df = dpo_df[dpo_df[\"is_correct\"] == False]\n",
    "    soft_true_df = dpo_df[(dpo_df[\"is_correct\"] == True) & (dpo_df[\"margin\"] <= margin_thr)]\n",
    "\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    # incorrect: 4지=2개, 5지=3개\n",
    "    for _, r in incorrect_df.iterrows():\n",
    "        row = r.to_dict()\n",
    "        k = int(row[\"choices_len\"])\n",
    "        num_rej = 2 if k == 4 else 3\n",
    "        rows.extend(make_pairs_for_row(row, num_rej=num_rej, source=\"incorrect\"))\n",
    "\n",
    "    # soft_true: 1개\n",
    "    for _, r in soft_true_df.iterrows():\n",
    "        row = r.to_dict()\n",
    "        rows.extend(make_pairs_for_row(row, num_rej=1, source=\"soft_true\"))\n",
    "\n",
    "    print(f\"incorrect rows: {len(incorrect_df)}\")\n",
    "    print(f\"soft_true rows: {len(soft_true_df)}\")\n",
    "    print(f\"total DPO pairs: {len(rows)}\")\n",
    "    return rows\n",
    "\n",
    "def save_jsonl(rows: List[Dict[str, Any]], out_path: str):\n",
    "    out_path = str(Path(out_path))\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for x in rows:\n",
    "            f.write(json.dumps(x, ensure_ascii=False) + \"\\n\")\n",
    "    print(\"Saved:\", out_path)\n",
    "\n",
    "# 사용 예시\n",
    "# \n",
    "# save_jsonl(dpo_rows, \"./data/dpo_train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "effbfd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrect rows: 50\n",
      "soft_true rows: 327\n",
      "total DPO pairs: 432\n",
      "Saved: /data/ephemeral/pro-nlp-generationfornlp-nlp-13/data/dpo_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "dpo_rows = build_dpo_dataset(dpo_df, margin_thr=0.995)\n",
    "dpo_rows\n",
    "output_path = project_root / \"data/dpo_dataset.jsonl\"\n",
    "save_jsonl(dpo_rows, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee1c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DPO samples: 432\n",
      "Train: 388, Eval: 44\n",
      "Saved: ./data/dpo_train.jsonl\n",
      "Saved: ./data/dpo_eval.jsonl\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# JSONL 로드\n",
    "with open(output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dpo_data = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"Total DPO samples: {len(dpo_data)}\")\n",
    "\n",
    "# Train/Eval 분리 (80:20)\n",
    "train_data, eval_data = train_test_split(\n",
    "    dpo_data,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_data)}, Eval: {len(eval_data)}\")\n",
    "\n",
    "# Train 저장\n",
    "train_path = project_root / \"data\" / \"dpo_train.jsonl\"\n",
    "with open(train_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in train_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "print(\"Saved: ./data/dpo_train.jsonl\")\n",
    "\n",
    "# Eval 저장\n",
    "eval_path = project_root / \"data\" / \"dpo_eval.jsonl\"\n",
    "with open(eval_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in eval_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "print(\"Saved: ./data/dpo_eval.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49469d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
