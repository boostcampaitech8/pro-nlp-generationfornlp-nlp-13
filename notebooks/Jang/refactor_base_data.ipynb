{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09e5d43",
   "metadata": {},
   "source": [
    "## src/data\n",
    "- data_loader.py\n",
    "- preprocessor.py\n",
    "- tokenizer_wrapper.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4675c64",
   "metadata": {},
   "source": [
    "#### preprocessor.py\n",
    "- parse_problems_column\n",
    "    - problem 열을 flatten\n",
    "- add_choices_len\n",
    "    - choices_len 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ae4fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def parse_problems_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if 'problems' not in df.columns:\n",
    "        return df\n",
    "\n",
    "    df['problems'] = df['problems'].apply(ast.literal_eval)\n",
    "    problems_df = df['problems'].apply(pd.Series)\n",
    "\n",
    "    df = pd.concat([df.drop(columns=['problems']), problems_df], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_choices_len(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if 'choices' in df.columns:\n",
    "        df['choices_len'] = df['choices'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb9bc45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2031 entries, 0 to 2030\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             2031 non-null   object \n",
      " 1   paragraph      2031 non-null   object \n",
      " 2   problems       2031 non-null   object \n",
      " 3   question_plus  0 non-null      float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 63.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question_plus</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>choices_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>generation-for-nlp-425</td>\n",
       "      <td>상소하여 아뢰기를 , “신이 좌참 찬 송준길이 올린 차자를 보았는데 , 상복(喪服)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>상소한 인물이 속한 붕당에 대한 설명으로 옳은 것만을 모두 고르면?</td>\n",
       "      <td>[ㄱ, ㄴ, ㄱ, ㄷ, ㄴ, ㄹ, ㄷ, ㄹ]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>generation-for-nlp-426</td>\n",
       "      <td>(가)은/는 의병계열과 애국계몽 운동 계열의 비밀결사가 모여 결성된 조직으로, 총사...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(가)에 대한 설명으로 옳지 않은 것은?</td>\n",
       "      <td>[고려 문종 때에 남경(南京)으로 승격되었다., 종루(鐘樓), 이현, 칠패 등에서 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>generation-for-nlp-427</td>\n",
       "      <td>나는 삼한(三韓) 산천의 음덕을 입어 대업을 이루었다.(가)는/은 수덕(水德)이 순...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(가) 지역에 대한 설명으로 옳은 것은?</td>\n",
       "      <td>[이곳에 대장도감을 설치하여 재조대장경을 만들었다., 지눌이 이곳에서 수선사 결사운...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generation-for-nlp-428</td>\n",
       "      <td>이 날 소정방이 부총관 김인문 등과 함께 기 벌포에 도착하여 백제 군사와 마주쳤다....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>밑줄 친 ‘그’에 대한 설명으로 옳은 것은?</td>\n",
       "      <td>[살수에서 수의 군대를 물리쳤다 ., 김춘추 의 신라 왕위 계승을 지원하였다 ., ...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>generation-for-nlp-429</td>\n",
       "      <td>선비들 수만 명이 대궐 앞에 모여 만 동묘와 서원을 다시 설립할 것을 청하니, (가...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(가) 인물이 추진한 정책으로 옳지 않은 것은?</td>\n",
       "      <td>[사창제를 실시하였다 ., 대전회통을 편찬하였다 ., 비변사의 기능을 강화하였다 ....</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                          paragraph  \\\n",
       "0  generation-for-nlp-425  상소하여 아뢰기를 , “신이 좌참 찬 송준길이 올린 차자를 보았는데 , 상복(喪服)...   \n",
       "1  generation-for-nlp-426  (가)은/는 의병계열과 애국계몽 운동 계열의 비밀결사가 모여 결성된 조직으로, 총사...   \n",
       "2  generation-for-nlp-427  나는 삼한(三韓) 산천의 음덕을 입어 대업을 이루었다.(가)는/은 수덕(水德)이 순...   \n",
       "3  generation-for-nlp-428  이 날 소정방이 부총관 김인문 등과 함께 기 벌포에 도착하여 백제 군사와 마주쳤다....   \n",
       "4  generation-for-nlp-429  선비들 수만 명이 대궐 앞에 모여 만 동묘와 서원을 다시 설립할 것을 청하니, (가...   \n",
       "\n",
       "   question_plus                               question  \\\n",
       "0            NaN  상소한 인물이 속한 붕당에 대한 설명으로 옳은 것만을 모두 고르면?   \n",
       "1            NaN                 (가)에 대한 설명으로 옳지 않은 것은?   \n",
       "2            NaN                 (가) 지역에 대한 설명으로 옳은 것은?   \n",
       "3            NaN               밑줄 친 ‘그’에 대한 설명으로 옳은 것은?   \n",
       "4            NaN             (가) 인물이 추진한 정책으로 옳지 않은 것은?   \n",
       "\n",
       "                                             choices  answer  choices_len  \n",
       "0                           [ㄱ, ㄴ, ㄱ, ㄷ, ㄴ, ㄹ, ㄷ, ㄹ]       2            4  \n",
       "1  [고려 문종 때에 남경(南京)으로 승격되었다., 종루(鐘樓), 이현, 칠패 등에서 ...       1            4  \n",
       "2  [이곳에 대장도감을 설치하여 재조대장경을 만들었다., 지눌이 이곳에서 수선사 결사운...       4            4  \n",
       "3  [살수에서 수의 군대를 물리쳤다 ., 김춘추 의 신라 왕위 계승을 지원하였다 ., ...       2            4  \n",
       "4  [사창제를 실시하였다 ., 대전회통을 편찬하였다 ., 비변사의 기능을 강화하였다 ....       3            4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEST\n",
    "import os\n",
    "\n",
    "ROOT_DIR = '/data/ephemeral/pro-nlp-generationfornlp-nlp-13'\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "df = pd.read_csv(os.path.join(DATA_DIR,'train.csv'))\n",
    "df.info()\n",
    "\n",
    "\n",
    "df_parse = parse_problems_column(df)\n",
    "\n",
    "df_add_choices = add_choices_len(df_parse)\n",
    "\n",
    "df_add_choices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea172f",
   "metadata": {},
   "source": [
    "#### data_loader.py\n",
    "- load_data()\n",
    "    - csv 로드, Flatten, choices_len 추가\n",
    "- 전처리 함수\n",
    "- hf dataset 만들기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b8fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from \n",
    "\n",
    "\n",
    "def load_csv(data_path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(data_path)\n",
    "\n",
    "\n",
    "def preprocess_dataframe(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    df = parse_problems_column(df)\n",
    "    df = add_choices_len(df)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bf8921",
   "metadata": {},
   "source": [
    "## src/prompt\n",
    "- prompt_builder.py\n",
    "- prompt_registry.py\n",
    "- templates/\n",
    "    system/\n",
    "    user/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba688ce7",
   "metadata": {},
   "source": [
    "#### prompt_registry.py\n",
    "- template(.txt)를 여러 버전으로 조회해서 문자열을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c53943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class PromptRegistry:\n",
    "    def __init__(\n",
    "        self,\n",
    "        templates_dir: Optional[str | Path] = None,\n",
    "        verbose: bool = False\n",
    "    ):\n",
    "        if templates_dir is None:\n",
    "            self.templates_dir = Path(__file__).parent / \"templates\"\n",
    "        else:\n",
    "            self.templates_dir = Path(templates_dir)\n",
    "        \n",
    "        self.templates: Dict[str, str] = {}\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self._load_templates()\n",
    "\n",
    "    def _load_templates(self) -> None:\n",
    "        if not self.templates_dir.exists():\n",
    "            raise FileNotFoundError(f\"templates_dir 경로가 존재하지 않습니다: {self.templates_dir}\")\n",
    "\n",
    "        candidates = defaultdict(dict)\n",
    "\n",
    "        for file_path in self.templates_dir.rglob(\"*.txt\"):\n",
    "            parsed = self._parse_filename(file_path)\n",
    "            if parsed is None:\n",
    "                continue\n",
    "            \n",
    "            role, choices_len, p_type, name = parsed\n",
    "\n",
    "            try:\n",
    "                content = file_path.read_text(encoding=\"utf-8\")\n",
    "            except Exception:\n",
    "                if self.verbose:\n",
    "                    print(f\"파일 읽기 실패: {file_path}\")\n",
    "                continue\n",
    "\n",
    "            key = f\"{role}/{file_path.name}\"\n",
    "            self.templates[key] = content\n",
    "\n",
    "            if role == \"user\":\n",
    "                base_key = (role, choices_len, name)\n",
    "                candidates[base_key][p_type] = key\n",
    "        \n",
    "        self._validate_user_pairs(candidates)\n",
    "\n",
    "        if self.verbose:\n",
    "            system_cnt = sum(k.startswith(\"system/\") for k in self.templates)\n",
    "            user4_cnt = sum(k.startswith(\"user/4_\") for k in self.templates)\n",
    "            user5_cnt = sum(k.startswith(\"user/5_\") for k in self.templates)\n",
    "            print(f\"template loading 완료: system={system_cnt}, user_4={user4_cnt}, user_5={user5_cnt}\")\n",
    "\n",
    "    def _parse_filename(self, file_path: Path) -> Optional[Tuple[str, str, str, str]]:\n",
    "        \"\"\"\n",
    "        파일명 규칙: {role}/{choices_len}_{type}_{name}.txt\n",
    "        - role: system/user\n",
    "        - choices_len: 4/5\n",
    "        - type: user의 경우 question/ no_question\n",
    "        - name: 이름\n",
    "        \"\"\"\n",
    "        \n",
    "        # 규칙에 맞는것만 가져오기. -> 맞지 않는경우에는? -> if verbose: 라면 print로 {file_name}은 안맞다고 하고 다음으로 넘어가는걸로.\n",
    "        role = file_path.parent.name\n",
    "        stem = file_path.stem\n",
    "        parts = stem.split('_')\n",
    "\n",
    "        if role == \"system\":\n",
    "            if len(parts) == 2:\n",
    "                choices_len, name = parts\n",
    "                return role, choices_len, \"default\", name\n",
    "        \n",
    "        elif role == \"user\":\n",
    "            if len(parts) == 3:\n",
    "                choices_len, p_type, name = parts\n",
    "                if p_type in (\"question\", \"no_question\"):\n",
    "                    return role, choices_len, p_type, name\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"규칙에 맞지 않는 파일명입니다. {file_path.name}\")\n",
    "        return None\n",
    "    \n",
    "    def _validate_user_pairs(self, candidates: dict) -> None:\n",
    "        \"\"\"\n",
    "        user의 경우 'question', 'no_question' 쌍이 모두 존재하는지 검증\n",
    "        \"\"\"\n",
    "\n",
    "        for (role, choices_len, name), type_map in candidates.items():\n",
    "            if role != \"user\":\n",
    "                continue\n",
    "\n",
    "            has_q = \"question\" in type_map\n",
    "            has_not_q = \"no_question\" in type_map\n",
    "        \n",
    "            if has_q and has_not_q:\n",
    "                continue\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"user pair 누락: choices_len={choices_len}, name={name}, have={list(type_map.keys())}\")\n",
    "\n",
    "            for key in type_map.values():\n",
    "                self.templates.pop(key, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "432f901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added to sys.path: /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n",
      "template loading 완료: system=0, user_4=0, user_5=0\n"
     ]
    }
   ],
   "source": [
    "### TEST\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path.cwd()\n",
    "if not (root / \"src\").exists():\n",
    "    root = root.parent.parent\n",
    "\n",
    "sys.path.insert(0, str(root))\n",
    "print(\"added to sys.path:\", root)\n",
    "\n",
    "from src.prompt.prompt_registry import PromptRegistry\n",
    "\n",
    "registry = PromptRegistry(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5387e6",
   "metadata": {},
   "source": [
    "#### prompt_builder.py\n",
    "- 데이터를 입력받아 필요한 prompt(message)를 생성\n",
    "- policy에 따라 결정됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = {\n",
    "    \"system\": {4: \"v1\", 5: \"v2\"},\n",
    "    \"user\":   {4: \"v1\", 5: \"v1\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5556020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Any\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class PromptBuilder:\n",
    "    def __init__(\n",
    "            self,\n",
    "            policy: Dict[str, Dict[int, str]],\n",
    "            templates_dir: Optional[str | Path] = None,\n",
    "            mode: str = \"train\",\n",
    "            verbose: bool = False,\n",
    "    ):\n",
    "        self.mode = mode\n",
    "        self.policy = policy\n",
    "        self.registry = PromptRegistry(templates_dir=templates_dir, verbose=verbose)\n",
    "\n",
    "    def build_message(self, row: Dict) -> Dict[str, Any]:\n",
    "        system_message = self._get_system_message(row)\n",
    "        user_message = self._get_user_message(row)\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            assistant_message = self._get_assistant_message(row)\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "\n",
    "        return {\n",
    "            \"id\": row.get(\"id\"),\n",
    "            \"messages\": messages,\n",
    "            \"label\": int(row[\"answer\"]),\n",
    "        }\n",
    "\n",
    "    def _get_system_message(self, row):\n",
    "        choices_len = row[\"choices_len\"]\n",
    "        version = self.policy[\"system\"][choices_len]\n",
    "        key = f\"system/{choices_len}_{version}.txt\"\n",
    "\n",
    "        template = self.registry.templates[key]\n",
    "        return template\n",
    "\n",
    "    def _get_user_message(self, row):\n",
    "        choices_len = int(row[\"choices_len\"])\n",
    "        version = self.policy[\"user\"][choices_len]\n",
    "\n",
    "        paragraph = row[\"paragraph\"]\n",
    "        question = row[\"question\"]\n",
    "        choices = row[\"choices\"]\n",
    "        choices_str = self._format_choices(choices)\n",
    "\n",
    "        q_plus = row.get(\"question_plus\", None)\n",
    "        has_plus = bool(q_plus) and str(q_plus) != \"nan\"\n",
    "        p_type = \"plus\" if has_plus else \"no_plus\"\n",
    "        key = f\"user/{choices_len}_{p_type}_{version}.txt\"\n",
    "\n",
    "        template = self.registry.templates[key]\n",
    "\n",
    "        if has_plus:\n",
    "            return template.format(\n",
    "                paragraph=paragraph,\n",
    "                question_plus=q_plus,\n",
    "                question=question,\n",
    "                choices=choices_str,\n",
    "            )\n",
    "        return template.format(\n",
    "            paragraph=paragraph,\n",
    "            question=question,\n",
    "            choices=choices_str,\n",
    "        )\n",
    "\n",
    "    def _get_assistant_message(row):\n",
    "        return str(row['answer'])\n",
    "\n",
    "    def _format_choices(self, choices: Any) -> str:\n",
    "        if isinstance(choices, list):\n",
    "            return \"\\n\".join([f\"{i+1}. {c}\" for i, c in enumerate(choices)])\n",
    "        return str(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f24624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_root: /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n",
      "sys.path[0]: /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n"
     ]
    }
   ],
   "source": [
    "### TEST\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "nb_dir = Path(os.getcwd())\n",
    "\n",
    "# 프로젝트 루트: notebooks/Jang -> notebooks -> project_root\n",
    "project_root = nb_dir.parents[1]  # /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"project_root:\", project_root)\n",
    "print(\"sys.path[0]:\", sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4954f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template loading 완료: system=2, user_4=2, user_5=2\n",
      "loaded templates: 6\n"
     ]
    }
   ],
   "source": [
    "from src.prompt.prompt_registry import PromptRegistry\n",
    "from src.prompt.prompt_builder import PromptBuilder\n",
    "from src.data.preprocessor import parse_problems_column, add_choices_len\n",
    "\n",
    "\n",
    "registry = PromptRegistry(verbose=True)\n",
    "print(\"loaded templates:\", len(registry.templates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0de53e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template loading 완료: system=2, user_4=2, user_5=2\n"
     ]
    }
   ],
   "source": [
    "policy = {\n",
    "    \"system\": {4: \"v1\", 5: \"v1\"},\n",
    "    \"user\":   {4: \"v1\", 5: \"v1\"},\n",
    "}\n",
    "\n",
    "builder = PromptBuilder(\n",
    "    mode=\"train\",\n",
    "    verbose=True,\n",
    "    policy=policy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5be6c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'generation-for-nlp-428',\n",
       " 'messages': [{'role': 'system',\n",
       "   'content': \"당신은 **지식 추론(Knowledge Inference) 전문가**입니다.\\n이 유형은 정답이 지문에 그대로 쓰여 있지 않을 수 있으며, 지문은 '조건/단서'를 제공합니다.\\n지문에서 주어진 조건을 정확히 반영하고, 그 조건과 모순되지 않는 범위에서 일반적으로 알려진 지식을 적용해 가장 타당한 선택지 하나를 고르십시오.\"},\n",
       "  {'role': 'user',\n",
       "   'content': '### 지문\\n이 날 소정방이 부총관 김인문 등과 함께 기 벌포에 도착하여 백제 군사와 마주쳤다. …(중략) …소정방이 신라군이 늦게 왔다는 이유로 군문에서 신라 독군 김문영의 목을 베고자 하니, 그가 군사들 앞에 나아가 “황산 전투를 보지도 않고 늦게 온 것을 이유로 우리를 죄 주려 하는구나. 죄도 없이 치욕을 당할 수는 없으니, 결단코 먼저 당나라 군사와 결전을 한 후에 백제를 쳐야겠다.”라고 말하였다.\\n\\n### 질문\\n밑줄 친 ‘그’에 대한 설명으로 옳은 것은?\\n\\n### 선택지\\n1. 살수에서 수의 군대를 물리쳤다 .\\n2. 김춘추 의 신라 왕위 계승을 지원하였다 .\\n3. 청해진을 설치하고 해상 무역을 전개하였다 .\\n4. 대가야를 정벌하여 낙동강 유역을 확보하였다 .\\n\\n### 문제 해결 가이드라인\\n1. 지문이 주는 조건/단서를 먼저 정리하세요. (무엇을 가정/설명하고 있는지)\\n2. 필요하면 일반적으로 알려진 지식(개념/원리/사례)을 적용하되, 지문 조건과 모순되면 안 됩니다.\\n3. 선택지 중 조건을 가장 잘 만족하는 것 하나만 고르세요.\\n\\n정답은 1~4 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\\n정답:'},\n",
       "  {'role': 'assistant', 'content': '2'}],\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.build_message(df_add_choices.iloc[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed47523d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 869 entries, 0 to 868\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Unnamed: 0     869 non-null    int64 \n",
      " 1   id             869 non-null    object\n",
      " 2   paragraph      869 non-null    object\n",
      " 3   question       869 non-null    object\n",
      " 4   choices        869 non-null    object\n",
      " 5   answer         869 non-null    object\n",
      " 6   question_plus  44 non-null     object\n",
      " 7   choices_len    869 non-null    int64 \n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 54.4+ KB\n"
     ]
    }
   ],
   "source": [
    "### TEST\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = '/data/ephemeral/pro-nlp-generationfornlp-nlp-13'\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "df_test = pd.read_csv(os.path.join(DATA_DIR,'test.csv'))\n",
    "\n",
    "df_pars_test = parse_problems_column(df_test)\n",
    "\n",
    "df_add_choices_test = add_choices_len(df_pars_test)\n",
    "\n",
    "df_add_choices_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ccfc13f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: {'question': '윗글의 내용과 일치하지 않는  것은?', 'choices': ['같은 책을 읽은 독자라도 서로 다른 의미를 구성할 수 있다 .', '다른 독자와의 소통은 독자가 인식의 폭을 확장하도록 돕는다 .', '독자는 직접 경험해 보지 못했던 다양한 삶을 책의 필자를  매개로 접할 수 있다.', '독자의 배경지식,  관점 ,  읽기 환경 ,  과제는 독자의 의미 구성에   영향을 주는 독자 요인이다.', '독자는 책을 읽을 때 자신이 속한 사회나 시대의 영향을  받으며 필자와 간접적으로 대화한다.'], 'answer': ''}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_pars_test \u001b[38;5;241m=\u001b[39m \u001b[43mparse_problems_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m, in \u001b[0;36mparse_problems_column\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblems\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m----> 8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblems\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproblems\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m problems_df \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblems\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mSeries)\n\u001b[1;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblems\u001b[39m\u001b[38;5;124m'\u001b[39m]), problems_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/data/ephemeral/pro-nlp-generationfornlp-nlp-13/.venv/lib/python3.10/site-packages/pandas/core/series.py:4943\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4809\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4810\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4816\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4817\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4934\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4937\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4941\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/ephemeral/pro-nlp-generationfornlp-nlp-13/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1422\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/ephemeral/pro-nlp-generationfornlp-nlp-13/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1502\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1502\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1507\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/data/ephemeral/pro-nlp-generationfornlp-nlp-13/.venv/lib/python3.10/site-packages/pandas/core/base.py:925\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/ephemeral/pro-nlp-generationfornlp-nlp-13/.venv/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2999\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ast.py:110\u001b[0m, in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ast.py:109\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_signed_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ast.py:83\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ast.py:74\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[0;32m---> 74\u001b[0m         \u001b[43m_raise_malformed_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ast.py:71\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lno \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     70\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: {'question': '윗글의 내용과 일치하지 않는  것은?', 'choices': ['같은 책을 읽은 독자라도 서로 다른 의미를 구성할 수 있다 .', '다른 독자와의 소통은 독자가 인식의 폭을 확장하도록 돕는다 .', '독자는 직접 경험해 보지 못했던 다양한 삶을 책의 필자를  매개로 접할 수 있다.', '독자의 배경지식,  관점 ,  읽기 환경 ,  과제는 독자의 의미 구성에   영향을 주는 독자 요인이다.', '독자는 책을 읽을 때 자신이 속한 사회나 시대의 영향을  받으며 필자와 간접적으로 대화한다.'], 'answer': ''}"
     ]
    }
   ],
   "source": [
    "df_pars_test = parse_problems_column(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67998643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>problems</th>\n",
       "      <th>question_plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>generation-for-nlp-0</td>\n",
       "      <td>사람들이 지속적으로 책을 읽는 이유 중 하나는 즐거움이다 .   독서의 즐거움에는 ...</td>\n",
       "      <td>{'question': '윗글의 내용과 일치하지 않는  것은?', 'choices'...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>generation-for-nlp-1</td>\n",
       "      <td>사람들이 지속적으로 책을 읽는 이유 중 하나는 즐거움이다 .   독서의 즐거움에는 ...</td>\n",
       "      <td>{'question': '윗글을 읽고 ㉠에 대해 보인 반응으로 적절하지 않은  것은...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>generation-for-nlp-2</td>\n",
       "      <td>(가 ) 중국에서 비롯된 유서( 類書)는 고금의 서적에서 자료를  수집하고 항목별로...</td>\n",
       "      <td>{'question': '(가 )와 (나 )에 대한 설명으로 가장 적절한 것은?',...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>generation-for-nlp-3</td>\n",
       "      <td>(가 ) 중국에서 비롯된 유서( 類書)는 고금의 서적에서 자료를  수집하고 항목별로...</td>\n",
       "      <td>{'question': '[A ]에 대한 이해로 적절하지 않은  것은?', 'cho...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>generation-for-nlp-4</td>\n",
       "      <td>(가 ) 중국에서 비롯된 유서( 類書)는 고금의 서적에서 자료를  수집하고 항목별로...</td>\n",
       "      <td>{'question': '㉮에 대한 이해를 바탕으로 ㉠ ,  ㉡에 대해 파악한 내용...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                    id  \\\n",
       "0           0  generation-for-nlp-0   \n",
       "1           1  generation-for-nlp-1   \n",
       "2           2  generation-for-nlp-2   \n",
       "3           3  generation-for-nlp-3   \n",
       "4           4  generation-for-nlp-4   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  사람들이 지속적으로 책을 읽는 이유 중 하나는 즐거움이다 .   독서의 즐거움에는 ...   \n",
       "1  사람들이 지속적으로 책을 읽는 이유 중 하나는 즐거움이다 .   독서의 즐거움에는 ...   \n",
       "2  (가 ) 중국에서 비롯된 유서( 類書)는 고금의 서적에서 자료를  수집하고 항목별로...   \n",
       "3  (가 ) 중국에서 비롯된 유서( 類書)는 고금의 서적에서 자료를  수집하고 항목별로...   \n",
       "4  (가 ) 중국에서 비롯된 유서( 類書)는 고금의 서적에서 자료를  수집하고 항목별로...   \n",
       "\n",
       "                                            problems question_plus  \n",
       "0  {'question': '윗글의 내용과 일치하지 않는  것은?', 'choices'...           NaN  \n",
       "1  {'question': '윗글을 읽고 ㉠에 대해 보인 반응으로 적절하지 않은  것은...           NaN  \n",
       "2  {'question': '(가 )와 (나 )에 대한 설명으로 가장 적절한 것은?',...           NaN  \n",
       "3  {'question': '[A ]에 대한 이해로 적절하지 않은  것은?', 'cho...           NaN  \n",
       "4  {'question': '㉮에 대한 이해를 바탕으로 ㉠ ,  ㉡에 대해 파악한 내용...           NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(os.path.join(DATA_DIR,'test.csv'))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea75f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0647420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 869 entries, 0 to 868\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Unnamed: 0     869 non-null    int64 \n",
      " 1   id             869 non-null    object\n",
      " 2   paragraph      869 non-null    object\n",
      " 3   question_plus  44 non-null     object\n",
      " 4   question       869 non-null    object\n",
      " 5   choices        869 non-null    object\n",
      " 6   answer         869 non-null    object\n",
      " 7   question_plus  44 non-null     object\n",
      " 8   choices_len    869 non-null    int64 \n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 61.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_pars_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3ed862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template loading 완료: system=2, user_4=2, user_5=2\n"
     ]
    }
   ],
   "source": [
    "policy = {\n",
    "    \"system\": {4: \"v1\", 5: \"v1\"},\n",
    "    \"user\":   {4: \"v1\", 5: \"v1\"},\n",
    "}\n",
    "\n",
    "builder = PromptBuilder(\n",
    "    mode=\"test\",\n",
    "    verbose=True,\n",
    "    policy=policy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc6b4849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'generation-for-nlp-7',\n",
       " 'messages': [{'role': 'system',\n",
       "   'content': '당신은 논리적인 **텍스트 분석 및 독해 전문가**입니다.\\n이 문제는 오직 **제공된 지문 내의 정보**만으로 풀어야 합니다.\\n당신의 외부 배경지식을 배제하고, 철저하게 지문에 명시된 내용에 근거하여 판단하십시오.'},\n",
       "  {'role': 'user',\n",
       "   'content': '### 지문\\n(가 ) 중국에서 비롯된 유서( 類書)는 고금의 서적에서 자료를  수집하고 항목별로 분류,  정리하여 이용에 편리하도록 편찬한   서적이다.  일반적으로 유서는 기존 서적에서 필요한 부분을   뽑아 배열할 뿐 상호 비교하거나 편찬자의 해석을 가하지  않았다.  유서는 모든 주제를 망라한 일반 유서와 특정 주제를   다룬  전문 유서로 나눌 수 있으며,  편찬 방식은 책에 따라   다른 경우가 많았다.  중국에서는 대체로 왕조 초기에 많은  학자를 동원하여 국가 주도로 대규모 유서를 편찬하여 간행 하였다.  이를 통해 이전까지의 지식을 집성하고 왕조의  위엄을 과시할 수 있었다. 고려 때 중국 유서를 수용한 이후,  조선에서는 중국 유서를   활용하는 한편,  중국 유서의 편찬 방식에 ⓐ따라  필요에  맞게 유서를 편찬하였다.  조선의 유서는 대체로 국가보다  개인이 소규모로 편찬하는 경우가 많았고 ,  목적에 따른 특정   주제의 전문 유서가 집중적으로 편찬되었다.  전문 유서  가운데 편찬자가 미상인 유서가 많은데,  대체로 간행을  염두에 두지 않고 기존 서적에서 필요한 부분을 발췌 ,  기록 하여 시문 창작 ,  과거 시험 등 개인적 목적으로 유서를 활용 하고자 하였기 때문이었다. 이 같은 유서 편찬 경향이 지속되는 가운데 17세기부터 실학의   학풍이 하나의 조류를 형성하면서 유서 편찬에 변화가 나타났다 .   ㉮실학자들의 유서 는 현실 개혁의 뜻을 담았고,  편찬 의도를  지식의 제공과 확산에 두었다.  또한 단순 정리를 넘어 지식을  재분류하여 범주화하고 평가를 더하는 등 저술의 성격을 드러 냈다.  독서와 견문을 통해 주자학에서 중시되지 않았던 지식을  집적했고,  증거를 세워 이론적으로 밝히는 고증과 이에 대한  의견  등 ‘안설’을 덧붙이는 경우가 많았다.  주자학의 지식을  ⓑ이어받는  한편,  주자학이 아닌 새로운 지식을 수용하는 유연 성과 개방성을 보였다.  광범위하게 정리한 지식을 식자층이  ⓒ쉽게  접할 수 있어야 한다고 생각했고 ,  객관적 사실 탐구를  중시하여  박물학과 자연 과학에 관심을 기울였다. 조선 후기 실학자들이 편찬한 유서가 주자학의 관념적 사유에  국한되지 않고 새로운 지식의 축적과 확산을 촉진한 것은 지식의   역사에서 적지 않은 의미를 지닌다. (나 ) 예수회 선교사들이 중국에 소개한 서양의 학문 ,  곧 서학은  조선 후기 유서( 類書)의 지적 자원 중 하나로 활용되었다.  조선  후기 실학자들 가운데 이수광,  이익,  이규경 등이 편찬한 백과 전서식 유서는 주자학의 지적 영역 내에서 서학의 지식을 어떻게   수용하였는지를 보여 주는 대표적인 사례이다 . 17세기의 이수광은 주자학뿐 아니라 다른 학문에 대해서도  열린 태도를 가지고 있었다.  주자학에 기초하여 도덕에 관한  학문과 경전에 관한 학문 등이 주류였던 당시 상황에서,  그는  \\U000f0854지봉유설\\U000f0855을 통해 당대 조선의 지식을 망라하여 항목화하고  자신의 견해를 덧붙였을 뿐 아니라 사신의 일원으로 중국에서 접한 서양 관련 지식을 객관적으로 소개했다.  이에 대해 심성  수양에 절실하지 않을뿐더러 주자학이 아닌 것이 ⓓ뒤섞여  순수 하지 않다는 ㉯일부 주자학자의 비판 이 있었지만,  그가 소개한  서양 관련 지식은 중국과 큰 시간 차이 없이 주변에 알려졌다 . 18세기의 이익은 서학 지식 자체를 ㉠\\U000f0854성호사설\\U000f0855의 표제어로   삼았고,  기존의 학설을 정당화하거나 배제하는 근거로 서학을  수용하는 등 서학을 지적 자원으로 활용하였다.  특히 그는  서학의 세부 내용을 다른 분야로 확대하며 상호 참조하는 방식 으로 지식을 심화하고 확장하여 소개하였다 .  서학의 해부학과  생리학을 그 자체로 수용하지 않고 주자학 심성론의 하위 이론 으로 재분류하는 등 지식의 범주를 ⓔ바꾸어  수용하였다.  또한  서학의 수학을 주자학의 지식 영역 안에서 재구성하기도 하였다 . 19세기의 이규경도 ㉡\\U000f0854오주연문장전산고 \\U000f0855를 편찬하면서  서학을 적극 활용하였다.  그는 \\U000f0854성호사설\\U000f0855의 분류 체계를 적용 하였고 이익과 마찬가지로 서학의 천문학 ,  우주론 등의 내용을  수록하였다.  그가 주로 유서의 지적 자원으로 활용한 중국의  서학 연구서들은 서학을 소화하여 중국의 학문과 절충한 것이 었고,  서학이 가지는 진보성의 토대가 중국이라는 서학 중국  원류설을 반영한 것이었다.  이에 따라 이규경은 이 책들에  담긴 중국화한 서학 지식과 서학 중국 원류설을 받아들였고 ,   문명의 척도로 여겨진 기존의 중화 관념에서 탈피하지 않으면 서도 서학 수용의 이질감과 부담감에서 자유로울 수 있었다 .   이렇듯 이규경은 중국의 서학 연구서들을 활용해 매개적 방식 으로 서학을 수용하였다. \\n\\n### 질문\\n문맥상 ⓐ ～ⓔ와 바꾸어 쓰기에 적절하지 않은  것은?\\n\\n### 선택지\\n1. ⓐ :의거(依據)하여\\n2. ⓑ :계몽(啓蒙)하는\\n3. ⓒ :용이(容易)하게\\n4. ⓓ :혼재(混在)되어\\n5. ⓔ :변경(變更)하여\\n\\n### 문제 해결 가이드라인\\n1. 지문을 끝까지 읽고 핵심 정보를 정리하세요.\\n2. 질문이 요구하는 정보(수치/인물/원인/결과/요지 등)가 무엇인지 정확히 확인하세요.\\n3. 각 선택지가 지문의 어느 부분과 일치하는지 1:1로 대조하세요.\\n4. 지문과 모순되거나 지문에 근거가 없는 선택지는 제외하세요.\\n5. 가장 확실한 근거를 가진 선택지 번호 하나만 선택하세요.\\n\\n정답은 1~5 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\\n정답:'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.build_message(df_add_choices_test.iloc[7,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a959d6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                       7\n",
       "id                                            generation-for-nlp-7\n",
       "paragraph        (가 ) 중국에서 비롯된 유서( 類書)는 고금의 서적에서 자료를  수집하고 항목별로...\n",
       "question                            문맥상 ⓐ ～ⓔ와 바꾸어 쓰기에 적절하지 않은  것은?\n",
       "choices          [ⓐ :의거(依據)하여, ⓑ :계몽(啓蒙)하는, ⓒ :용이(容易)하게, ⓓ :혼재(...\n",
       "answer                                                            \n",
       "question_plus                                                  NaN\n",
       "choices_len                                                      5\n",
       "Name: 7, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_add_choices_test.iloc[7,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6425a31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                       6\n",
       "id                                            generation-for-nlp-6\n",
       "paragraph        (가 ) 중국에서 비롯된 유서( 類書)는 고금의 서적에서 자료를  수집하고 항목별로...\n",
       "question         (가 ),  (나 )를 읽은 학생이 <보기>의 󰡔임원경제지 󰡕에 대해 보인  반응으...\n",
       "choices          [현실 개혁의 뜻을 담았던 (가 )의 실학자들의 유서와 마찬가 지로 현실의 문제를 ...\n",
       "answer                                                            \n",
       "question_plus     서유구의 󰡔임원경제지 󰡕는 19세기까지의 조선과 중국 서적 들에서 향촌 관련 부분...\n",
       "choices_len                                                      5\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_add_choices_test.iloc[6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7b0f100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'generation-for-nlp-6',\n",
       " 'messages': [{'role': 'system',\n",
       "   'content': '당신은 논리적인 **텍스트 분석 및 독해 전문가**입니다.\\n이 문제는 오직 **제공된 지문 내의 정보**만으로 풀어야 합니다.\\n당신의 외부 배경지식을 배제하고, 철저하게 지문에 명시된 내용에 근거하여 판단하십시오.'},\n",
       "  {'role': 'user',\n",
       "   'content': '### 지문\\n(가 ) 중국에서 비롯된 유서( 類書)는 고금의 서적에서 자료를  수집하고 항목별로 분류,  정리하여 이용에 편리하도록 편찬한   서적이다.  일반적으로 유서는 기존 서적에서 필요한 부분을   뽑아 배열할 뿐 상호 비교하거나 편찬자의 해석을 가하지  않았다.  유서는 모든 주제를 망라한 일반 유서와 특정 주제를   다룬  전문 유서로 나눌 수 있으며,  편찬 방식은 책에 따라   다른 경우가 많았다.  중국에서는 대체로 왕조 초기에 많은  학자를 동원하여 국가 주도로 대규모 유서를 편찬하여 간행 하였다.  이를 통해 이전까지의 지식을 집성하고 왕조의  위엄을 과시할 수 있었다. 고려 때 중국 유서를 수용한 이후,  조선에서는 중국 유서를   활용하는 한편,  중국 유서의 편찬 방식에 ⓐ따라  필요에  맞게 유서를 편찬하였다.  조선의 유서는 대체로 국가보다  개인이 소규모로 편찬하는 경우가 많았고 ,  목적에 따른 특정   주제의 전문 유서가 집중적으로 편찬되었다.  전문 유서  가운데 편찬자가 미상인 유서가 많은데,  대체로 간행을  염두에 두지 않고 기존 서적에서 필요한 부분을 발췌 ,  기록 하여 시문 창작 ,  과거 시험 등 개인적 목적으로 유서를 활용 하고자 하였기 때문이었다. 이 같은 유서 편찬 경향이 지속되는 가운데 17세기부터 실학의   학풍이 하나의 조류를 형성하면서 유서 편찬에 변화가 나타났다 .   ㉮실학자들의 유서 는 현실 개혁의 뜻을 담았고,  편찬 의도를  지식의 제공과 확산에 두었다.  또한 단순 정리를 넘어 지식을  재분류하여 범주화하고 평가를 더하는 등 저술의 성격을 드러 냈다.  독서와 견문을 통해 주자학에서 중시되지 않았던 지식을  집적했고,  증거를 세워 이론적으로 밝히는 고증과 이에 대한  의견  등 ‘안설’을 덧붙이는 경우가 많았다.  주자학의 지식을  ⓑ이어받는  한편,  주자학이 아닌 새로운 지식을 수용하는 유연 성과 개방성을 보였다.  광범위하게 정리한 지식을 식자층이  ⓒ쉽게  접할 수 있어야 한다고 생각했고 ,  객관적 사실 탐구를  중시하여  박물학과 자연 과학에 관심을 기울였다. 조선 후기 실학자들이 편찬한 유서가 주자학의 관념적 사유에  국한되지 않고 새로운 지식의 축적과 확산을 촉진한 것은 지식의   역사에서 적지 않은 의미를 지닌다. (나 ) 예수회 선교사들이 중국에 소개한 서양의 학문 ,  곧 서학은  조선 후기 유서( 類書)의 지적 자원 중 하나로 활용되었다.  조선  후기 실학자들 가운데 이수광,  이익,  이규경 등이 편찬한 백과 전서식 유서는 주자학의 지적 영역 내에서 서학의 지식을 어떻게   수용하였는지를 보여 주는 대표적인 사례이다 . 17세기의 이수광은 주자학뿐 아니라 다른 학문에 대해서도  열린 태도를 가지고 있었다.  주자학에 기초하여 도덕에 관한  학문과 경전에 관한 학문 등이 주류였던 당시 상황에서,  그는  \\U000f0854지봉유설\\U000f0855을 통해 당대 조선의 지식을 망라하여 항목화하고  자신의 견해를 덧붙였을 뿐 아니라 사신의 일원으로 중국에서 접한 서양 관련 지식을 객관적으로 소개했다.  이에 대해 심성  수양에 절실하지 않을뿐더러 주자학이 아닌 것이 ⓓ뒤섞여  순수 하지 않다는 ㉯일부 주자학자의 비판 이 있었지만,  그가 소개한  서양 관련 지식은 중국과 큰 시간 차이 없이 주변에 알려졌다 . 18세기의 이익은 서학 지식 자체를 ㉠\\U000f0854성호사설\\U000f0855의 표제어로   삼았고,  기존의 학설을 정당화하거나 배제하는 근거로 서학을  수용하는 등 서학을 지적 자원으로 활용하였다.  특히 그는  서학의 세부 내용을 다른 분야로 확대하며 상호 참조하는 방식 으로 지식을 심화하고 확장하여 소개하였다 .  서학의 해부학과  생리학을 그 자체로 수용하지 않고 주자학 심성론의 하위 이론 으로 재분류하는 등 지식의 범주를 ⓔ바꾸어  수용하였다.  또한  서학의 수학을 주자학의 지식 영역 안에서 재구성하기도 하였다 . 19세기의 이규경도 ㉡\\U000f0854오주연문장전산고 \\U000f0855를 편찬하면서  서학을 적극 활용하였다.  그는 \\U000f0854성호사설\\U000f0855의 분류 체계를 적용 하였고 이익과 마찬가지로 서학의 천문학 ,  우주론 등의 내용을  수록하였다.  그가 주로 유서의 지적 자원으로 활용한 중국의  서학 연구서들은 서학을 소화하여 중국의 학문과 절충한 것이 었고,  서학이 가지는 진보성의 토대가 중국이라는 서학 중국  원류설을 반영한 것이었다.  이에 따라 이규경은 이 책들에  담긴 중국화한 서학 지식과 서학 중국 원류설을 받아들였고 ,   문명의 척도로 여겨진 기존의 중화 관념에서 탈피하지 않으면 서도 서학 수용의 이질감과 부담감에서 자유로울 수 있었다 .   이렇듯 이규경은 중국의 서학 연구서들을 활용해 매개적 방식 으로 서학을 수용하였다. \\n\\n### 질문\\n(가 ),  (나 )를 읽은 학생이 <보기>의 \\U000f0854임원경제지 \\U000f0855에 대해 보인  반응으로 적절하지 않은  것은?\\n\\n### 보기\\n 서유구의 \\U000f0854임원경제지 \\U000f0855는 19세기까지의 조선과 중국 서적 들에서 향촌 관련 부분을 발췌,  분류하고 고증한 유서이다.   국가를 위한다는 목적의식을 명시한 이 유서에는 향촌 사대부 의 이상적인 삶을 제시하는 과정에서 향촌 구성원 전체의  삶의 조건을 개선할 수 있는 방안이 실렸고 ,  향촌 실생활에서   활용할 수 있는 내용이 집성되었다 .  주자학을 기반으로 실증과   실용의 자세를 견지했던 서유구의 입장,  서학 중국 원류설,   중국과 비교한 조선의 현실 등이 반영되었다.  안설을 부기 했으며 ,  제한적으로 색인을 넣어 검색이 가능하도록 하였다 . \\n\\n### 선택지\\n1. 현실 개혁의 뜻을 담았던 (가 )의 실학자들의 유서와 마찬가 지로 현실의 문제를 개선하려는 목적의식이 확인되겠군 .\\n2. 증거를 제시하여 이론적으로 밝히거나 의견을 제시하는 경우가   많았던 (가 )의 실학자들의 유서와 마찬가지로 편찬자의 고증과   의견이 반영된 것이 확인되겠군.\\n3. 당대 지식을 망라하고 서양 관련 지식을 소개하고자 한 (나 )의   \\U000f0854지봉유설\\U000f0855에 비해 특정한 주제를 중심으로 편찬되는 전문  유서의 성격이 두드러지게 드러나겠군.\\n4. 기존 학설의 정당화 내지 배제에 관심을 두었던 (나 )의 \\U000f0854성호 사설\\U000f0855에 비해 향촌 사회 구성원의 삶에 필요한 실용적인 지식의   활용에 대한 관심이 드러나겠군.\\n5. 중국을 문명의 척도로 받아들였던 (나 )의 \\U000f0854오주연문장전산고 \\U000f0855 와  달리 중화 관념에 구애되지 않고 중국의 현실과 조선의  현실을 비교한 내용이 확인되겠군.\\n\\n### 문제 해결 가이드라인\\n1. 지문을 끝까지 읽고 핵심 정보를 정리하세요.\\n2. 질문이 요구하는 정보(수치/인물/원인/결과/요지 등)가 무엇인지 정확히 확인하세요.\\n3. 각 선택지가 지문의 어느 부분과 일치하는지 1:1로 대조하세요.\\n4. 지문과 모순되거나 지문에 근거가 없는 선택지는 제외하세요.\\n5. 가장 확실한 근거를 가진 선택지 번호 하나만 선택하세요.\\n\\n정답은 1~5 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\\n정답:'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.build_message(df_add_choices_test.iloc[6,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c457ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1201965725.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    2. 그럼 내가 지금 만들어야 하는 함수? 동작?을 기준으로 보면\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# load_csv\n",
    "\n",
    "# \n",
    "\n",
    "### 해야하는 동작\n",
    "# .csv 불러오기.\n",
    "# preprocessor.py 에 있는걸로 df 반환됨 (choices_len, parse_problems_column) \n",
    "# pd.DataFrame을 dataset으로 바꾸기.? \n",
    "# src/prompt 에 있는걸로 df 하나의 행을 프롬프트로 변경???\n",
    "# 여기가 헷갈림. huggingface의 dataset으로 해야하는건지 아닌건지\n",
    "# tokenize_wrapper 사용해서 -> -> -> \n",
    "# 최종 형태는 huggingface의 학습 가능한 형태의 dataset\n",
    "\n",
    "# train_test_split도 여기서 해야하는건가...?\n",
    "# 어디서 해야하는거지? \n",
    "# 아니면, 이건 따로 train.py에서 하는거고??\n",
    "# train/test 를 따로 봐야하는건가\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e106c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.data.preprocessor import parse_problems_column, add_choices_len\n",
    "from src.prompt.prompt_builder import PromptBuilder, PromptConfig\n",
    "from src.data.tokenizer_wrapper import TokenizerWrapper, TokenizerConfig\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataConfig:\n",
    "    train_path: Optional[Union[str, Path]] = None\n",
    "    test_path: Optional[Union[str, Path]] = None\n",
    "    valid_ratio: float = 0.1\n",
    "    seed: int = 42\n",
    "\n",
    "    do_split: bool = True\n",
    "\n",
    "\n",
    "def load_csv(path: Union[str, Path]) -> pd.DataFrame:\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "def build_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = parse_problems_column(df)\n",
    "    df = add_choices_len(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_to_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return Dataset.from_pandas(df, preserve_index=False)\n",
    "\n",
    "\n",
    "def make_train_valid_dataset(\n",
    "    data_cfg: DataConfig,\n",
    "    prompt_cfg: PromptConfig,\n",
    "    tokenize_cfg_train: TokenizerConfig,\n",
    "    tokenize_cfg_gen: TokenizerConfig,\n",
    "    tokenizer,\n",
    ") -> DatasetDict:\n",
    "    \n",
    "    df = load_csv(data_cfg.train_path)\n",
    "    df = build_dataframe(df)\n",
    "\n",
    "    if data_cfg.do_split:\n",
    "        train_df, valid_df = train_test_split(\n",
    "            df,\n",
    "            test_size = data_cfg.valid_ratio,\n",
    "            stratify=df[\"choices_len\"],\n",
    "            random_state = data_cfg.seed,\n",
    "        )\n",
    "        train_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "        valid_ds = Dataset.from_pandas(valid_df, preserve_index=False)\n",
    "    else:\n",
    "        train_ds = Dataset.from_pandas(df, preserve_index=False)\n",
    "        valid_ds = None\n",
    "    \n",
    "    prompt_cfg_train = PromptConfig(\n",
    "        policy=prompt_cfg.policy,\n",
    "        mode=\"train\",\n",
    "        templates_dir=prompt_cfg.templates_dir,\n",
    "        verbose=prompt_cfg.verbose,\n",
    "    )\n",
    "    prompt_cfg_test = PromptConfig(\n",
    "        policy=prompt_cfg.policy,\n",
    "        mode=\"test\",\n",
    "        templates_dir=prompt_cfg.templates_dir,\n",
    "        verbose=prompt_cfg.verbose,\n",
    "    )\n",
    "\n",
    "    builder_train = PromptBuilder(prompt_cfg_train)\n",
    "    builder_test = PromptBuilder(prompt_cfg_train)\n",
    "\n",
    "    tokenize_wrapper_train = TokenizerWrapper(tokenizer, tokenize_cfg_train)\n",
    "    tokenize_wrapper_gen = TokenizerWrapper(tokenizer, tokenize_cfg_gen)\n",
    "\n",
    "    train_msg = train_ds.map(\n",
    "        builder_train.build_message,\n",
    "        batched=False,\n",
    "        remove_columns=train_ds.column_names,\n",
    "        desc=\"Build train messages (teacher forcing)\",\n",
    "    )\n",
    "    train_text = train_msg.map(\n",
    "        tokenize_wrapper_train.to_text,\n",
    "        batched=False,\n",
    "        remove_columns=[\"messages\"],\n",
    "        desc=\"Serialize train to text\",\n",
    "    )\n",
    "    train_tf = train_text.map(\n",
    "        tokenize_wrapper_train.tokenize_fn,\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\"],\n",
    "        desc=\"Tokenize train\",\n",
    "    )\n",
    "\n",
    "    valid_msg = valid_ds.map(\n",
    "        builder_test.build_message,\n",
    "        batched=False,\n",
    "        remove_columns=valid_ds.column_names,\n",
    "        desc=\"Build valid messages (teacher forcing)\",\n",
    "    )\n",
    "    valid_text = valid_msg.map(\n",
    "        tokenize_wrapper_train.to_text,\n",
    "        batched=False,\n",
    "        remove_columns=[\"messages\"],\n",
    "        desc=\"Serialize valid to text\",\n",
    "    )\n",
    "    valid_tf = valid_text.map(\n",
    "        tokenize_wrapper_train.tokenize_fn,\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\"],\n",
    "        desc=\"Tokenize valid\",\n",
    "    )\n",
    "\n",
    "    valid_gen_msg = valid_ds.map(\n",
    "        builder_test.build_message,\n",
    "        batched=False,\n",
    "        desc=\"Build valid_gen messages (prompt only)\",\n",
    "    )\n",
    "\n",
    "    # 이게 맞는건지 모르겠음. -> 일단 보류\n",
    "    def _to_text_keep_meta(ex):\n",
    "        out = tokenize_wrapper_gen.to_text(ex)  \n",
    "        out[\"id\"] = ex.get(\"id\")\n",
    "        out[\"answer\"] = ex.get(\"answer\")      \n",
    "        out[\"choices_len\"] = ex.get(\"choices_len\")\n",
    "        return out\n",
    "\n",
    "    valid_gen_text = valid_gen_msg.map(\n",
    "        _to_text_keep_meta,\n",
    "        batched=False,\n",
    "        # message \n",
    "        remove_columns=[\"messages\"],\n",
    "        desc=\"Serialize valid_gen to text (+meta)\",\n",
    "    )\n",
    "\n",
    "    def _tokenize_keep_meta(batch):\n",
    "        tok = tokenize_wrapper_gen.tokenize_fn({\"text\": batch[\"text\"]})\n",
    "        tok[\"id\"] = batch[\"id\"]\n",
    "        tok[\"answer\"] = batch[\"answer\"]\n",
    "        tok[\"choices_len\"] = batch[\"choices_len\"]\n",
    "        return tok\n",
    "\n",
    "    valid_gen = valid_gen_text.map(\n",
    "        _tokenize_keep_meta,\n",
    "        batched=True,\n",
    "        remove_columns=valid_gen_text.column_names,\n",
    "        desc=\"Tokenize valid_gen (+meta)\",\n",
    "    )\n",
    "\n",
    "    return DatasetDict(\n",
    "        {\n",
    "            \"train\": train_tf,\n",
    "            \"validation\": valid_tf,\n",
    "            \"validation_gen\": valid_gen,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# 원래 하나의 행씩 했으니까 일단 이건 빼자. \n",
    "# def make_test_dataset(\n",
    "#     data_cfg: DataConfig,\n",
    "#     prompt_cfg: PromptConfig,\n",
    "#     tokenize_cfg_gen: TokenizerConfig,\n",
    "#     tokenizer,\n",
    "# ) -> Dataset:\n",
    "    \n",
    "#     df = build_dataframe(load_csv(data_cfg.test_path))\n",
    "#     ds = df_to_dataset(df)\n",
    "\n",
    "#     test_prompt_cfg = PromptConfig(\n",
    "#         policy=prompt_cfg.policy,\n",
    "#         mode=\"test\",\n",
    "#         templates_dir=prompt_cfg.templates_dir,\n",
    "#         verbose=prompt_cfg.verbose,\n",
    "#     )\n",
    "#     builder = PromptBuilder(test_prompt_cfg)\n",
    "\n",
    "#     # test는 generation prompt True\n",
    "#     tw = TokenizerWrapper(tokenizer, TokenizerConfig(\n",
    "#         max_length=tokenize_cfg_gen.max_length,\n",
    "#         padding=tokenize_cfg_gen.padding,\n",
    "#         truncation=tokenize_cfg_gen.truncation,\n",
    "#         add_generation_prompt=True,\n",
    "#     ))\n",
    "\n",
    "#     orig_cols = ds.column_names\n",
    "#     ds_msg = ds.map(lambda ex: builder.build_message(ex), remove_columns=orig_cols)\n",
    "#     ds_text = ds_msg.map(tw.to_text, remove_columns=[\"messages\"])\n",
    "#     ds_tok = ds_text.map(tw.tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "#     return ds_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00638899",
   "metadata": {},
   "source": [
    "### 최종적으로 검토 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01ccee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_root: /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n",
      "sys.path[0]: /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n"
     ]
    }
   ],
   "source": [
    "### TEST\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "nb_dir = Path(os.getcwd())\n",
    "\n",
    "# 프로젝트 루트: notebooks/Jang -> notebooks -> project_root\n",
    "project_root = nb_dir.parents[1]  # /data/ephemeral/pro-nlp-generationfornlp-nlp-13\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"project_root:\", project_root)\n",
    "print(\"sys.path[0]:\", sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e3e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_loader import DataConfig, make_train_valid_dataset\n",
    "from src.prompt.prompt_builder import PromptConfig\n",
    "from src.data.tokenizer_wrapper import TokenizerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee73b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen3-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef31f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cfg = DataConfig(\n",
    "    train_path=project_root / \"data\" / \"train.csv\",\n",
    "    valid_ratio=0.1,\n",
    "    seed=42,\n",
    "    do_split=True,\n",
    ")\n",
    "\n",
    "policy = {\n",
    "    \"system\": {4: \"v1\", 5: \"v1\"},\n",
    "    \"user\":   {4: \"v1\", 5: \"v1\"},\n",
    "}\n",
    "\n",
    "prompt_cfg = PromptConfig(\n",
    "    policy=policy,\n",
    "    templates_dir=project_root / \"src\" / \"prompt\" / \"templates\",\n",
    "    verbose=False,\n",
    "    mode=\"train\",  # 여기 값은 dataloader 내부에서 train/test로 다시 만들어 쓰게 되어있음\n",
    ")\n",
    "\n",
    "tokenize_cfg_train = TokenizerConfig(\n",
    "    max_length=2048,\n",
    "    truncation=True,\n",
    "    padding=False,\n",
    "    add_generation_prompt=False,\n",
    ")\n",
    "\n",
    "tokenize_cfg_gen = TokenizerConfig(\n",
    "    max_length=2048,\n",
    "    truncation=True,\n",
    "    padding=False,\n",
    "    add_generation_prompt=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac25bc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1bbc0fc0b84b948fce916650968a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build train messages (teacher forcing):   0%|          | 0/1827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f67b745c4e4387948d80b5e20b5811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Serialize train to text:   0%|          | 0/1827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cbb21f5a10473ea0a94e2d025fe281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenize train:   0%|          | 0/1827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4bd03f3aef4b0485ced86762711b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build valid messages (teacher forcing):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877da57c28964c879ac054d9ca80576f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Serialize valid to text:   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2426265203464cf190c125f2f163e57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenize valid:   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17bfd3b1ae74028b436a4d96b1afb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build valid_gen messages (prompt only):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d4aab08fbf4692acc64be3d7dcb72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Serialize valid_gen to text (+meta):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7b34ac2aa240aca9152bf27261262e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenize valid_gen:   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1827\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 204\n",
       "    })\n",
       "    validation_gen: Dataset({\n",
       "        features: ['id', 'answer', 'choices_len', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 204\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = make_train_valid_dataset(\n",
    "    data_cfg=data_cfg,\n",
    "    prompt_cfg=prompt_cfg,\n",
    "    tokenize_cfg_train=tokenize_cfg_train,\n",
    "    tokenize_cfg_gen=tokenize_cfg_gen,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e741690f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [train] sample 3 ===\n",
      "\n",
      "--- #1 idx=1309 ---\n",
      "len(input_ids): 928\n",
      "label: 1\n",
      "id: generation-for-nlp-2150\n",
      "len(attention_mask): 928 | attn sum: 928\n",
      "\n",
      "[decoded]\n",
      "<|im_start|>system\n",
      "당신은 논리적인 **텍스트 분석 및 독해 전문가**입니다.\n",
      "이 문제는 오직 **제공된 지문 내의 정보**만으로 풀어야 합니다.\n",
      "당신의 외부 배경지식을 배제하고, 철저하게 지문에 명시된 내용에 근거하여 판단하십시오.<|im_end|>\n",
      "<|im_start|>user\n",
      "### 지문\n",
      "미국 제너럴모터스(GM)의 자동차도 해킹을 통해 원격조종이 가능하다는 주장이 제기됐다. 피아트 크라이슬러가 같은 우려로 140만대 자동차에 대해 리콜을 결정한 지 1주일 만이다.로이터통신은 30일(현지시간) “범죄 의도가 없어 ‘화이트 햇’으로 불리는 전문해커 새미 캄카가 해킹으로 GM자동차의 문을 강제로 열고 시동까지 거는 모습을 유튜브에 공개했다”며 “캄카는 운전자에게 GM의 원격조종용 모바일 애플리케이션(앱)을 사용하지 말라고 조언했다”고 보도했다.캄카가 시연한 해킹은 GM이 내놓은 온스타 시스템을 탑재한 차량을 대상으로 이뤄졌다. 온스타는 자동차와 스마트폰을 연결해 차량을 제어하는 시스템이다. GM의 온스타 모바일 앱을 스마트폰에 설치, 사용한 사람은 300만명이 넘는다. 로이터에 따르면 캄카는 “100달러(약 11만원)를 들여 제작한 별도의 단말기를 이용해 자동차와 스마트폰의 연결 과정에 침투했다”고 주장했다.이에 대해 GM은 성명을 통해 “캄카의 주장은 이미 회사 기술자들이 점검했던 것”이라며 “지금은 개선을 마친 상태”라고 해명했다. 하지만 캄카는 “GM 관계자들과 논의한 결과 회사 조치는 보안의 취약성을 해결할 수 없었다”고 반박하면서 “다음주 미국 라스베이거스에서 열리는 데프콘퍼런스에서 해킹 방법에 대한 원리를 설명하겠다”고 밝혔다.로이터는 “GM에 문제점을 해결했는지 추가로 취재했으나 이미 발표한 성명 이외에는 이렇다 할 반응을 내놓지 않았다”고 전했다.해킹으로 자동차를 원격조종할 수 있다는 가능성이 제기된 것은 처음이 아니다. 피아트 크라이슬러는 해커들이 4륜구동 자동차인 지프 크로키 기종이 보안에 취약하다는 주장을 제기하자 지난 24일 140만대의 리콜을 결정했다.\n",
      "\n",
      "### 질문\n",
      "GM 자동차의 해킹 시연을 한 해커의 이름은 무엇인가?\n",
      "\n",
      "### 선택지\n",
      "1. 새미 캄카\n",
      "2. 존 스미스\n",
      "3. 마크 저커버그\n",
      "4. 앨런 튜링\n",
      "5. 리처드 스톨먼\n",
      "\n",
      "### 문제 해결 가이드라인\n",
      "1. 지문을 끝까지 읽고 핵심 정보를 정리하세요.\n",
      "2. 질문이 요구하는 정보(수치/인물/원인/결과/요지 등)가 무엇인지 정확히 확인하세요.\n",
      "3. 각 선택지가 지문의 어느 부분과 일치하는지 1:1로 대조하세요.\n",
      "4. 지문과 모순되거나 지문에 근거가 없는 선택지는 제외하세요.\n",
      "5. 가장 확실한 근거를 가진 선택지 번호 하나만 선택하세요.\n",
      "\n",
      "정답은 1~5 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\n",
      "정답:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "1<|im_end|>\n",
      "\n",
      "\n",
      "--- #2 idx=228 ---\n",
      "len(input_ids): 712\n",
      "label: 1\n",
      "id: generation-for-nlp-2556\n",
      "len(attention_mask): 712 | attn sum: 712\n",
      "\n",
      "[decoded]\n",
      "<|im_start|>system\n",
      "당신은 논리적인 **텍스트 분석 및 독해 전문가**입니다.\n",
      "이 문제는 오직 **제공된 지문 내의 정보**만으로 풀어야 합니다.\n",
      "당신의 외부 배경지식을 배제하고, 철저하게 지문에 명시된 내용에 근거하여 판단하십시오.<|im_end|>\n",
      "<|im_start|>user\n",
      "### 지문\n",
      "한국인터넷진흥원(KISA, 원장 김석환)은 국민과 함께 기관을 혁신하고 사회적 가치를 창출하고자 ‘제3기 KISA혁신참여단’을 모집한다고 2020. 12. 2.(수) 밝혔다. 혁신참여단은 KISA에 관심 있는 국민이면 누구나 지원할 수 있으며, 2021년 한 해 동안 ▲기관 경영·사업 추진 방향에 대한 의견 수렴 및 자문 ▲청렴, 윤리, 지역상생을 위한 아이디어 제안 등 주요 기관 혁신활동에 참여하게 된다. 참여자에게는 위촉장 수여 및 활동 내용에 따른 소정의 사례가 지급되며, 우수 활동자에게는 별도 포상이 부여될 예정이다. 더 자세한 내용 및 지원 방법은 KISA 누리집 공지사항에서 확인할 수 있다. KISA 이성수 경영기획본부장은 “코로나19로 사회 전반의 서비스가 비대면·디지털로 급속하게 전환되면서 KISA에 더 많은 역할과 높은 책임감이 요구되는 상황이다”며, “KISA는 앞으로 국민의 목소리에 더욱 귀 기울여 경영혁신을 이루는 등 국민이 신뢰할 수 있는 공공기관으로 성장할 수 있도록 최선의 노력을 다하겠다”고 말했다.\n",
      "\n",
      "### 질문\n",
      "제3기 KISA혁신참여단의 모집 목적은 무엇인가?\n",
      "\n",
      "### 선택지\n",
      "1. 국민과 함께 기관을 혁신하고 사회적 가치를 창출하기 위해\n",
      "2. KISA의 경영진을 교체하기 위해\n",
      "3. KISA의 예산을 증대시키기 위해\n",
      "4. KISA의 비대면 서비스만을 강화하기 위해\n",
      "5. KISA의 해외 진출을 도모하기 위해\n",
      "\n",
      "### 문제 해결 가이드라인\n",
      "1. 지문을 끝까지 읽고 핵심 정보를 정리하세요.\n",
      "2. 질문이 요구하는 정보(수치/인물/원인/결과/요지 등)가 무엇인지 정확히 확인하세요.\n",
      "3. 각 선택지가 지문의 어느 부분과 일치하는지 1:1로 대조하세요.\n",
      "4. 지문과 모순되거나 지문에 근거가 없는 선택지는 제외하세요.\n",
      "5. 가장 확실한 근거를 가진 선택지 번호 하나만 선택하세요.\n",
      "\n",
      "정답은 1~5 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\n",
      "정답:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "1<|im_end|>\n",
      "\n",
      "\n",
      "--- #3 idx=51 ---\n",
      "len(input_ids): 655\n",
      "label: 3\n",
      "id: generation-for-nlp-1034\n",
      "len(attention_mask): 655 | attn sum: 655\n",
      "\n",
      "[decoded]\n",
      "<|im_start|>system\n",
      "당신은 **지식 추론(Knowledge Inference) 전문가**입니다.\n",
      "이 유형은 정답이 지문에 그대로 쓰여 있지 않을 수 있으며, 지문은 '조건/단서'를 제공합니다.\n",
      "지문에서 주어진 조건을 정확히 반영하고, 그 조건과 모순되지 않는 범위에서 일반적으로 알려진 지식을 적용해 가장 타당한 선택지 하나를 고르십시오.<|im_end|>\n",
      "<|im_start|>user\n",
      "### 지문\n",
      "하지만 전 우리 역사의 이 특별한 순간 시민의 자유가 중요함을 누구보다 더 잘 알고 있을 겁니다. 전국을 여행하고 사람들을 만나고 힘 없는 사람들에게 일어난 일들을 보니까요. 저는 시민의 자유를 지키기 위한 민주주의가 무엇을 의미하는지 깨닫습니다. 우리는 수년 동안 시민의 자유를 위해 싸워야 했습니다. 빛이 다소 어두워질 때마다 민주주의가 위험에 처한다는 점을 압니다. 현재 세계 전체의 혼란스러운 상황으로 다른 많은 나라에서는 시민의 자유가 사라졌습니다. 물론 전쟁 중에 언론의 자유, 표현의 자유, 집회의 자유를 지키는 것은 불가능합니다. 자동으로 사라집니다. 그래서 평소에는 안전했던 많은 나라에서 현재는 사라졌습니다. 다른 나라에서는 전쟁 발발 전부터 언론의 자유, 집회의 자유, 발언의 자유는 물론 종교의 자유도 사라졌습니다. 그래서 우리는 이 나라에 중대한 책임이 있다는 것을 알고 있습니다. 우리는 평화롭습니다. 우리에게는 전 세계 수많은 다른 민족을 지배하는 두려움이 있을 이유가 없습니다. 그러므로 우리는 민주주의의 자유를 지켜야 합니다.\n",
      "\n",
      "### 질문\n",
      "루즈벨트의 우려는 다음 중 어떤 사안에 대해 토론한 사람들의 우려와 가장 직접 비견되는가?\n",
      "\n",
      "### 선택지\n",
      "1. 1964년 통킹만 결의\n",
      "2. 1965년 투표권법\n",
      "3. 2001년 미국 애국법\n",
      "4. 2010년 부담 적정 의료법(Affordable Care Act)\n",
      "\n",
      "### 문제 해결 가이드라인\n",
      "1. 지문이 주는 조건/단서를 먼저 정리하세요. (무엇을 가정/설명하고 있는지)\n",
      "2. 필요하면 일반적으로 알려진 지식(개념/원리/사례)을 적용하되, 지문 조건과 모순되면 안 됩니다.\n",
      "3. 선택지 중 조건을 가장 잘 만족하는 것 하나만 고르세요.\n",
      "\n",
      "정답은 1~4 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\n",
      "정답:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "3<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 확인용\n",
    "from typing import Optional, List\n",
    "import random\n",
    "\n",
    "def _safe_decode(tokenizer, input_ids: List[int], skip_special_tokens: bool = False) -> str:\n",
    "    # skip_special_tokens=False 추천: chat_template 특수토큰/role 토큰이 보이면 원인 파악이 쉬움\n",
    "    return tokenizer.decode(input_ids, skip_special_tokens=skip_special_tokens)\n",
    "\n",
    "def show_samples(\n",
    "    ds,\n",
    "    tokenizer,\n",
    "    split_name: str,\n",
    "    n: int = 3,\n",
    "    seed: int = 42,\n",
    "    skip_special_tokens: bool = False,\n",
    "    head_chars: int = 800,\n",
    "    tail_chars: int = 300,\n",
    "):\n",
    "    \"\"\"\n",
    "    ds: DatasetDict or Dataset\n",
    "    split_name: \"train\" / \"validation\" / \"validation_gen\" (DatasetDict일 때)\n",
    "    \"\"\"\n",
    "    if hasattr(ds, \"keys\"):  # DatasetDict\n",
    "        split = ds[split_name]\n",
    "    else:\n",
    "        split = ds\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "    idxs = rng.sample(range(len(split)), k=min(n, len(split)))\n",
    "\n",
    "    print(f\"\\n=== [{split_name}] sample {len(idxs)} ===\")\n",
    "    for i, idx in enumerate(idxs, 1):\n",
    "        ex = split[idx]\n",
    "        input_ids = ex[\"input_ids\"]\n",
    "        attn = ex.get(\"attention_mask\", None)\n",
    "\n",
    "        text = _safe_decode(tokenizer, input_ids, skip_special_tokens=skip_special_tokens)\n",
    "\n",
    "        print(f\"\\n--- #{i} idx={idx} ---\")\n",
    "        print(\"len(input_ids):\", len(input_ids))\n",
    "\n",
    "        # label/answer 확인\n",
    "        if \"label\" in ex:\n",
    "            print(\"label:\", ex[\"label\"])\n",
    "        if \"answer\" in ex:\n",
    "            print(\"answer:\", ex[\"answer\"])\n",
    "        if \"choices_len\" in ex:\n",
    "            print(\"choices_len:\", ex[\"choices_len\"])\n",
    "        if \"id\" in ex:\n",
    "            print(\"id:\", ex[\"id\"])\n",
    "\n",
    "        # attention mask 간단 체크\n",
    "        if attn is not None:\n",
    "            print(\"len(attention_mask):\", len(attn), \"| attn sum:\", sum(attn))\n",
    "\n",
    "        # 텍스트 미리보기\n",
    "        print(\"\\n[decoded]\")\n",
    "        print(text)\n",
    "\n",
    "# 사용 예시:\n",
    "# ds = make_train_valid_dataset(...) 결과 DatasetDict\n",
    "show_samples(ds, tokenizer, \"train\", n=3, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b3a5aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [validation] sample 3 ===\n",
      "\n",
      "--- #1 idx=163 ---\n",
      "len(input_ids): 1585\n",
      "label: 1\n",
      "id: generation-for-nlp-2474\n",
      "len(attention_mask): 1585 | attn sum: 1585\n",
      "\n",
      "[decoded]\n",
      "<|im_start|>system\n",
      "당신은 논리적인 **텍스트 분석 및 독해 전문가**입니다.\n",
      "이 문제는 오직 **제공된 지문 내의 정보**만으로 풀어야 합니다.\n",
      "당신의 외부 배경지식을 배제하고, 철저하게 지문에 명시된 내용에 근거하여 판단하십시오.<|im_end|>\n",
      "<|im_start|>user\n",
      "### 지문\n",
      "한동안 잠잠하던 유로존(유로화 사용 17개국) 경제 상황이 심상치 않다. 유럽중앙은행(ECB)은 7일(현지시간) 통화정책회의에서 올해 유로존 성장률을 -0.5%로 전망했다. 지난해 12월에 내놓은 전망치보다 0.1%포인트 낮췄다. 올해 1.8%로 예상한 물가상승률도 내년에 1.3% 수준으로 떨어질 것으로 전망했다. 유로존에 경제성장률과 물가가 장기간 동시에 침체되는 ‘일본식 디플레이션’이 올 것이라는 우려가 커지는 이유다.○유로존 ‘일본식 디플레이션’ 오나마리오 드라기 ECB 총재는 이날 통화정책회의에서 기준금리를 연 0.75%로 동결했다. “통화정책만으로 문제를 해결할 수 없다”는 이유에서다. 또 “하반기부터는 경제 상황이 나아질 것”이라며 낙관론을 폈다. 그러나 전문가들은 “ECB가 시장을 너무 낙관적으로 보고 있다”고 지적했다. 덴마크 단스크은행의 라스 크리스텐센 이코노미스트도 “어떤 방식으로든 통화량을 늘리지 않으면 유로존은 디플레이션에 빠질 것”이라고 지적했다. ECB는 내년 유로존 물가상승률을 0.6~2.0%로 전망했다. 평균 1.3%다. 일반적으로 물가상승률이 1% 선으로 떨어지면 심각한 디플레이션으로 여긴다. 유로존 실업률은 사상 최고인 11.9%다. 유로존 은행의 기업대출은 지난 6개월간 1000억유로 줄었다. 그만큼 돈이 돌지 않는다는 얘기다. 독일의 지난 1월 산업생산은 전달과 같은 수준에 그쳐 시장예상치(0.4% 증가)를 밑돌았다. 전년 동기 대비로도 1.3% 줄었다. 독일도 유로존의 경제회복을 이끌지 못하고 있다. 크리스틴 라가르드 국제통화기금(IMF) 총재는 “위기가 끝났다고 섣불리 말하는 건 위험하다”며 “최악의 상황이 지나간 것은 맞지만 위기는 언제든 재발할 수 있다”고 지적했다.○ECB 국채 매입 못 할 수도정치 상황도 좋지 않다. 이탈리아 차기 총리로 유력시되는 피에르 루이지 베르사니 민주당 대표는 이날 “긴축 감옥에서 벗어나겠다”고 말했다. 원래 베르사니는 긴축정책을 유지하겠다는 입장이었지만 여론의 압박이 심해지자 공식적으로 노선을 바꿨다. 정치 불안이 계속되면서 지난 2월에만 340억유로가 이탈리아에서 유출된 것으로 나타났다. 프랑스 정국도 불안하다. 프랑수아 올랑드 프랑스 대통령의 지지율은 지난해 5월 대선 때 55%에서 현재 30%까지 떨어졌다. 프랑스 일간 르 피가로는 “역대 대통령 중 지지율이 가장 빨리 떨어지고 있다”고 전했다. 실업률이 역대 최고인 10.6%까지 오르는 등 경제 상황이 악화했기 때문이다. 피에르 모스코비시 프랑스 재무장관은 최근 “유럽연합(EU)이 제시한 적자 감축 목표를 달성하지 못하더라도 올해 긴축은 하지 않을 것”이라고 말했다. 문제는 프랑스, 이탈리아 등이 긴축하지 않으면 ECB가 이들 국가의 국채를 사들일 수 없다는 것이다. ECB는 지난해 9월 단기국채 무제한 매입 조치를 발표하며 “EU의 긴축 조건을 엄격히 이행하는 국가만 지원하겠다”는 전제를 달았다. 하지만 각국 정부가 공개적으로 ‘반긴축’을 천명함에 따라 ECB가 국채 매입을 재개할 수 없게 됐다. ECB의 국채 매입 조치 발표 이후로 상승세를 유지했던 유럽 금융시장이 일시에 흔들릴 수도 있다. 크리스티안 슐츠 베렌베르크은행 선임 이코노미스트는 “이탈리아 등 몇몇 국가가 스스로 ECB의 안전망에서 벗어나는 것을 선택하고 있다”고 지적했다.\n",
      "\n",
      "### 질문\n",
      "유로존의 경제 상황에 대한 우려가 커지는 이유로 언급된 것은 무엇인가?\n",
      "\n",
      "### 선택지\n",
      "1. 물가상승률이 1% 이하로 떨어질 가능성\n",
      "2. 실업률이 사상 최고치를 기록하고 있기 때문\n",
      "3. 유럽중앙은행이 기준금리를 인상했기 때문\n",
      "4. 유로존의 정치적 불안정성이 심화되고 있기 때문\n",
      "5. 경제성장률이 지속적으로 증가하고 있기 때문\n",
      "\n",
      "### 문제 해결 가이드라인\n",
      "1. 지문을 끝까지 읽고 핵심 정보를 정리하세요.\n",
      "2. 질문이 요구하는 정보(수치/인물/원인/결과/요지 등)가 무엇인지 정확히 확인하세요.\n",
      "3. 각 선택지가 지문의 어느 부분과 일치하는지 1:1로 대조하세요.\n",
      "4. 지문과 모순되거나 지문에 근거가 없는 선택지는 제외하세요.\n",
      "5. 가장 확실한 근거를 가진 선택지 번호 하나만 선택하세요.\n",
      "\n",
      "정답은 1~5 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\n",
      "정답:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "1<|im_end|>\n",
      "\n",
      "\n",
      "--- #2 idx=28 ---\n",
      "len(input_ids): 355\n",
      "label: 2\n",
      "id: generation-for-nlp-679\n",
      "len(attention_mask): 355 | attn sum: 355\n",
      "\n",
      "[decoded]\n",
      "<|im_start|>system\n",
      "당신은 **지식 추론(Knowledge Inference) 전문가**입니다.\n",
      "이 유형은 정답이 지문에 그대로 쓰여 있지 않을 수 있으며, 지문은 '조건/단서'를 제공합니다.\n",
      "지문에서 주어진 조건을 정확히 반영하고, 그 조건과 모순되지 않는 범위에서 일반적으로 알려진 지식을 적용해 가장 타당한 선택지 하나를 고르십시오.<|im_end|>\n",
      "<|im_start|>user\n",
      "### 지문\n",
      "1939년 조직개편안 1호와 행정명령 8248호에 따라 대통령이 선발할 수 있는 직원은 누구입니까?\n",
      "\n",
      "### 질문\n",
      "대통령이 선발할 수 있는 직원은 누구입니까?\n",
      "\n",
      "### 선택지\n",
      "1. 평화봉사단 단원\n",
      "2. 백악관 비서실 직원\n",
      "3. 상원 세출위원회 직원\n",
      "4. 내각 참모진\n",
      "\n",
      "### 문제 해결 가이드라인\n",
      "1. 지문이 주는 조건/단서를 먼저 정리하세요. (무엇을 가정/설명하고 있는지)\n",
      "2. 필요하면 일반적으로 알려진 지식(개념/원리/사례)을 적용하되, 지문 조건과 모순되면 안 됩니다.\n",
      "3. 선택지 중 조건을 가장 잘 만족하는 것 하나만 고르세요.\n",
      "\n",
      "정답은 1~4 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\n",
      "정답:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "2<|im_end|>\n",
      "\n",
      "\n",
      "--- #3 idx=6 ---\n",
      "len(input_ids): 1000\n",
      "label: 1\n",
      "id: generation-for-nlp-1912\n",
      "len(attention_mask): 1000 | attn sum: 1000\n",
      "\n",
      "[decoded]\n",
      "<|im_start|>system\n",
      "당신은 논리적인 **텍스트 분석 및 독해 전문가**입니다.\n",
      "이 문제는 오직 **제공된 지문 내의 정보**만으로 풀어야 합니다.\n",
      "당신의 외부 배경지식을 배제하고, 철저하게 지문에 명시된 내용에 근거하여 판단하십시오.<|im_end|>\n",
      "<|im_start|>user\n",
      "### 지문\n",
      "한동안 잠잠했던 건설업계에 경영악화에 따른 구조조정 불안감이 고조되고 있다. 보유자산이 많아 안정적이라고 평가됐던 경남기업이 두 번째 워크아웃(기업개선작업)을 신청했기 때문이다. 상당수 건설사가 올겨울 건설경기 한파를 넘기기 위해 증자와 자산매각 등 ‘현금 확보’를 위한 자구노력에 경쟁적으로 나서고 있다. 29일 건설업계에 따르면 3분기 실적 악화로 충격에 빠진 삼성엔지니어링은 자금 확보를 위해 서울 도곡동 사옥 2채(1500억원 규모)를 매각하는 방안을 추진 중이다. SK건설도 최근 SK(주)와 SK케미칼 등 주요 주주 참여로 4800억원 규모의 유상증자에 나섰다. GS건설은 서울역 GS역전타워와 문정동 롯데마트 건물 등의 매각을 추진했고 1조5000억원 규모의 유보 현금을 확보해 놓고 있다.대형 건설사들 가운데 상당수는 2~3년 전에 저가로 수주했던 해외공사 때문에 올해 적자를 이어갔다. 올 3분기까지 누적 영업손실을 보면 삼성엔지니어링이 1조원을 넘었고 GS건설은 7993억원에 이른다.부동산시장 장기 침체에 시달리는 중견 건설사들도 유동성 확보를 위해 자산 매각에 나서고 있다. 동부건설은 서울 동자동 오피스빌딩 지분 매각과 동부익스프레스 지분 매각 등으로 연말까지 총 5000억원에 가까운 자금을 확보키로 했다. 동부건설은 동자동 오피스빌딩의 투자 지분은 매각하되 이를 다시 임대해 다음달 1일 입주할 예정이다. 두산건설도 주택사업 미분양에 발목이 잡혀 올해 초 이미 두산중공업에서 1조원의 자금을 수혈받았다. 하지만 전문가들은 연말을 전후해서 추가로 구조조정될 건설사가 나올 수 있다고 보고 있다. 대한건설협회 관계자는 “건설사들이 미리미리 자구노력을 해가고 있지만, 건설경기 침체가 장기화 조짐을 보이고 있어 누적적자가 많은 중견기업의 경우 올겨울에 구조조정을 맞을 수도 있다”고 내다봤다.\n",
      "\n",
      "### 질문\n",
      "경남기업이 신청한 두 번째 워크아웃의 주된 원인은 무엇인가?\n",
      "\n",
      "### 선택지\n",
      "1. 경영악화\n",
      "2. 자산 매각\n",
      "3. 유상증자\n",
      "4. 부동산시장 호황\n",
      "5. 해외공사 수익 증가\n",
      "\n",
      "### 문제 해결 가이드라인\n",
      "1. 지문을 끝까지 읽고 핵심 정보를 정리하세요.\n",
      "2. 질문이 요구하는 정보(수치/인물/원인/결과/요지 등)가 무엇인지 정확히 확인하세요.\n",
      "3. 각 선택지가 지문의 어느 부분과 일치하는지 1:1로 대조하세요.\n",
      "4. 지문과 모순되거나 지문에 근거가 없는 선택지는 제외하세요.\n",
      "5. 가장 확실한 근거를 가진 선택지 번호 하나만 선택하세요.\n",
      "\n",
      "정답은 1~5 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\n",
      "정답:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "1<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_samples(ds, tokenizer, \"validation\", n=3, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b552b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [validation_gen] sample 3 ===\n",
      "\n",
      "--- #1 idx=163 ---\n",
      "len(input_ids): 1578\n",
      "answer: 1\n",
      "choices_len: 5\n",
      "id: generation-for-nlp-2474\n",
      "len(attention_mask): 1578 | attn sum: 1578\n",
      "\n",
      "[decoded]\n",
      "<|im_start|>system\n",
      "당신은 논리적인 **텍스트 분석 및 독해 전문가**입니다.\n",
      "이 문제는 오직 **제공된 지문 내의 정보**만으로 풀어야 합니다.\n",
      "당신의 외부 배경지식을 배제하고, 철저하게 지문에 명시된 내용에 근거하여 판단하십시오.<|im_end|>\n",
      "<|im_start|>user\n",
      "### 지문\n",
      "한동안 잠잠하던 유로존(유로화 사용 17개국) 경제 상황이 심상치 않다. 유럽중앙은행(ECB)은 7일(현지시간) 통화정책회의에서 올해 유로존 성장률을 -0.5%로 전망했다. 지난해 12월에 내놓은 전망치보다 0.1%포인트 낮췄다. 올해 1.8%로 예상한 물가상승률도 내년에 1.3% 수준으로 떨어질 것으로 전망했다. 유로존에 경제성장률과 물가가 장기간 동시에 침체되는 ‘일본식 디플레이션’이 올 것이라는 우려가 커지는 이유다.○유로존 ‘일본식 디플레이션’ 오나마리오 드라기 ECB 총재는 이날 통화정책회의에서 기준금리를 연 0.75%로 동결했다. “통화정책만으로 문제를 해결할 수 없다”는 이유에서다. 또 “하반기부터는 경제 상황이 나아질 것”이라며 낙관론을 폈다. 그러나 전문가들은 “ECB가 시장을 너무 낙관적으로 보고 있다”고 지적했다. 덴마크 단스크은행의 라스 크리스텐센 이코노미스트도 “어떤 방식으로든 통화량을 늘리지 않으면 유로존은 디플레이션에 빠질 것”이라고 지적했다. ECB는 내년 유로존 물가상승률을 0.6~2.0%로 전망했다. 평균 1.3%다. 일반적으로 물가상승률이 1% 선으로 떨어지면 심각한 디플레이션으로 여긴다. 유로존 실업률은 사상 최고인 11.9%다. 유로존 은행의 기업대출은 지난 6개월간 1000억유로 줄었다. 그만큼 돈이 돌지 않는다는 얘기다. 독일의 지난 1월 산업생산은 전달과 같은 수준에 그쳐 시장예상치(0.4% 증가)를 밑돌았다. 전년 동기 대비로도 1.3% 줄었다. 독일도 유로존의 경제회복을 이끌지 못하고 있다. 크리스틴 라가르드 국제통화기금(IMF) 총재는 “위기가 끝났다고 섣불리 말하는 건 위험하다”며 “최악의 상황이 지나간 것은 맞지만 위기는 언제든 재발할 수 있다”고 지적했다.○ECB 국채 매입 못 할 수도정치 상황도 좋지 않다. 이탈리아 차기 총리로 유력시되는 피에르 루이지 베르사니 민주당 대표는 이날 “긴축 감옥에서 벗어나겠다”고 말했다. 원래 베르사니는 긴축정책을 유지하겠다는 입장이었지만 여론의 압박이 심해지자 공식적으로 노선을 바꿨다. 정치 불안이 계속되면서 지난 2월에만 340억유로가 이탈리아에서 유출된 것으로 나타났다. 프랑스 정국도 불안하다. 프랑수아 올랑드 프랑스 대통령의 지지율은 지난해 5월 대선 때 55%에서 현재 30%까지 떨어졌다. 프랑스 일간 르 피가로는 “역대 대통령 중 지지율이 가장 빨리 떨어지고 있다”고 전했다. 실업률이 역대 최고인 10.6%까지 오르는 등 경제 상황이 악화했기 때문이다. 피에르 모스코비시 프랑스 재무장관은 최근 “유럽연합(EU)이 제시한 적자 감축 목표를 달성하지 못하더라도 올해 긴축은 하지 않을 것”이라고 말했다. 문제는 프랑스, 이탈리아 등이 긴축하지 않으면 ECB가 이들 국가의 국채를 사들일 수 없다는 것이다. ECB는 지난해 9월 단기국채 무제한 매입 조치를 발표하며 “EU의 긴축 조건을 엄격히 이행하는 국가만 지원하겠다”는 전제를 달았다. 하지만 각국 정부가 공개적으로 ‘반긴축’을 천명함에 따라 ECB가 국채 매입을 재개할 수 없게 됐다. ECB의 국채 매입 조치 발표 이후로 상승세를 유지했던 유럽 금융시장이 일시에 흔들릴 수도 있다. 크리스티안 슐츠 베렌베르크은행 선임 이코노미스트는 “이탈리아 등 몇몇 국가가 스스로 ECB의 안전망에서 벗어나는 것을 선택하고 있다”고 지적했다.\n",
      "\n",
      "### 질문\n",
      "유로존의 경제 상황에 대한 우려가 커지는 이유로 언급된 것은 무엇인가?\n",
      "\n",
      "### 선택지\n",
      "1. 물가상승률이 1% 이하로 떨어질 가능성\n",
      "2. 실업률이 사상 최고치를 기록하고 있기 때문\n",
      "3. 유럽중앙은행이 기준금리를 인상했기 때문\n",
      "4. 유로존의 정치적 불안정성이 심화되고 있기 때문\n",
      "5. 경제성장률이 지속적으로 증가하고 있기 때문\n",
      "\n",
      "### 문제 해결 가이드라인\n",
      "1. 지문을 끝까지 읽고 핵심 정보를 정리하세요.\n",
      "2. 질문이 요구하는 정보(수치/인물/원인/결과/요지 등)가 무엇인지 정확히 확인하세요.\n",
      "3. 각 선택지가 지문의 어느 부분과 일치하는지 1:1로 대조하세요.\n",
      "4. 지문과 모순되거나 지문에 근거가 없는 선택지는 제외하세요.\n",
      "5. 가장 확실한 근거를 가진 선택지 번호 하나만 선택하세요.\n",
      "\n",
      "정답은 1~5 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\n",
      "정답:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "--- #2 idx=28 ---\n",
      "len(input_ids): 348\n",
      "answer: 2\n",
      "choices_len: 4\n",
      "id: generation-for-nlp-679\n",
      "len(attention_mask): 348 | attn sum: 348\n",
      "\n",
      "[decoded]\n",
      "<|im_start|>system\n",
      "당신은 **지식 추론(Knowledge Inference) 전문가**입니다.\n",
      "이 유형은 정답이 지문에 그대로 쓰여 있지 않을 수 있으며, 지문은 '조건/단서'를 제공합니다.\n",
      "지문에서 주어진 조건을 정확히 반영하고, 그 조건과 모순되지 않는 범위에서 일반적으로 알려진 지식을 적용해 가장 타당한 선택지 하나를 고르십시오.<|im_end|>\n",
      "<|im_start|>user\n",
      "### 지문\n",
      "1939년 조직개편안 1호와 행정명령 8248호에 따라 대통령이 선발할 수 있는 직원은 누구입니까?\n",
      "\n",
      "### 질문\n",
      "대통령이 선발할 수 있는 직원은 누구입니까?\n",
      "\n",
      "### 선택지\n",
      "1. 평화봉사단 단원\n",
      "2. 백악관 비서실 직원\n",
      "3. 상원 세출위원회 직원\n",
      "4. 내각 참모진\n",
      "\n",
      "### 문제 해결 가이드라인\n",
      "1. 지문이 주는 조건/단서를 먼저 정리하세요. (무엇을 가정/설명하고 있는지)\n",
      "2. 필요하면 일반적으로 알려진 지식(개념/원리/사례)을 적용하되, 지문 조건과 모순되면 안 됩니다.\n",
      "3. 선택지 중 조건을 가장 잘 만족하는 것 하나만 고르세요.\n",
      "\n",
      "정답은 1~4 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\n",
      "정답:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "--- #3 idx=6 ---\n",
      "len(input_ids): 993\n",
      "answer: 1\n",
      "choices_len: 5\n",
      "id: generation-for-nlp-1912\n",
      "len(attention_mask): 993 | attn sum: 993\n",
      "\n",
      "[decoded]\n",
      "<|im_start|>system\n",
      "당신은 논리적인 **텍스트 분석 및 독해 전문가**입니다.\n",
      "이 문제는 오직 **제공된 지문 내의 정보**만으로 풀어야 합니다.\n",
      "당신의 외부 배경지식을 배제하고, 철저하게 지문에 명시된 내용에 근거하여 판단하십시오.<|im_end|>\n",
      "<|im_start|>user\n",
      "### 지문\n",
      "한동안 잠잠했던 건설업계에 경영악화에 따른 구조조정 불안감이 고조되고 있다. 보유자산이 많아 안정적이라고 평가됐던 경남기업이 두 번째 워크아웃(기업개선작업)을 신청했기 때문이다. 상당수 건설사가 올겨울 건설경기 한파를 넘기기 위해 증자와 자산매각 등 ‘현금 확보’를 위한 자구노력에 경쟁적으로 나서고 있다. 29일 건설업계에 따르면 3분기 실적 악화로 충격에 빠진 삼성엔지니어링은 자금 확보를 위해 서울 도곡동 사옥 2채(1500억원 규모)를 매각하는 방안을 추진 중이다. SK건설도 최근 SK(주)와 SK케미칼 등 주요 주주 참여로 4800억원 규모의 유상증자에 나섰다. GS건설은 서울역 GS역전타워와 문정동 롯데마트 건물 등의 매각을 추진했고 1조5000억원 규모의 유보 현금을 확보해 놓고 있다.대형 건설사들 가운데 상당수는 2~3년 전에 저가로 수주했던 해외공사 때문에 올해 적자를 이어갔다. 올 3분기까지 누적 영업손실을 보면 삼성엔지니어링이 1조원을 넘었고 GS건설은 7993억원에 이른다.부동산시장 장기 침체에 시달리는 중견 건설사들도 유동성 확보를 위해 자산 매각에 나서고 있다. 동부건설은 서울 동자동 오피스빌딩 지분 매각과 동부익스프레스 지분 매각 등으로 연말까지 총 5000억원에 가까운 자금을 확보키로 했다. 동부건설은 동자동 오피스빌딩의 투자 지분은 매각하되 이를 다시 임대해 다음달 1일 입주할 예정이다. 두산건설도 주택사업 미분양에 발목이 잡혀 올해 초 이미 두산중공업에서 1조원의 자금을 수혈받았다. 하지만 전문가들은 연말을 전후해서 추가로 구조조정될 건설사가 나올 수 있다고 보고 있다. 대한건설협회 관계자는 “건설사들이 미리미리 자구노력을 해가고 있지만, 건설경기 침체가 장기화 조짐을 보이고 있어 누적적자가 많은 중견기업의 경우 올겨울에 구조조정을 맞을 수도 있다”고 내다봤다.\n",
      "\n",
      "### 질문\n",
      "경남기업이 신청한 두 번째 워크아웃의 주된 원인은 무엇인가?\n",
      "\n",
      "### 선택지\n",
      "1. 경영악화\n",
      "2. 자산 매각\n",
      "3. 유상증자\n",
      "4. 부동산시장 호황\n",
      "5. 해외공사 수익 증가\n",
      "\n",
      "### 문제 해결 가이드라인\n",
      "1. 지문을 끝까지 읽고 핵심 정보를 정리하세요.\n",
      "2. 질문이 요구하는 정보(수치/인물/원인/결과/요지 등)가 무엇인지 정확히 확인하세요.\n",
      "3. 각 선택지가 지문의 어느 부분과 일치하는지 1:1로 대조하세요.\n",
      "4. 지문과 모순되거나 지문에 근거가 없는 선택지는 제외하세요.\n",
      "5. 가장 확실한 근거를 가진 선택지 번호 하나만 선택하세요.\n",
      "\n",
      "정답은 1~5 중 하나의 정수로만 출력하세요. 다른 글자는 출력하지 마세요.\n",
      "정답:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "show_samples(ds, tokenizer, \"validation_gen\", n=3, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52790e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
