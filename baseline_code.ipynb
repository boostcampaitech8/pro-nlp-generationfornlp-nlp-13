{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation for NLP Baseline Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python3.10 -m venv --system-site-packages /data/ephemeral/home/py310\n",
    "source /data/ephemeral/home/py310/bin/activate\n",
    "pip install --upgrade pip\n",
    "```\n",
    "위에 커맨드를 사용하여 가상환경을 만들고 IDE의 커널을 생성한 가상환경으로 변경해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipykernel==6.29.5 (from -r requirements.txt (line 1))\n",
      "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting ipywidgets==8.1.5 (from -r requirements.txt (line 2))\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting transformers==4.40.2 (from -r requirements.txt (line 3))\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "Collecting trl==0.11.4 (from -r requirements.txt (line 4))\n",
      "  Downloading trl-0.11.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting scikit-learn==1.5.2 (from -r requirements.txt (line 5))\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting matplotlib==3.9.2 (from -r requirements.txt (line 6))\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting evaluate==0.4.3 (from -r requirements.txt (line 7))\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting peft==0.13.2 (from -r requirements.txt (line 8))\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting requests==2.32.5 (from -r requirements.txt (line 9))\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting numpy==1.26.4 (from -r requirements.txt (line 10))\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 1)) (1.8.18)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 1)) (8.37.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 1)) (8.7.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 1)) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 1)) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 1)) (7.1.3)\n",
      "Requirement already satisfied: pyzmq>=24 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 1)) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 1)) (6.5.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 1)) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets==8.1.5->-r requirements.txt (line 2))\n",
      "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets==8.1.5->-r requirements.txt (line 2))\n",
      "  Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting filelock (from transformers==4.40.2->-r requirements.txt (line 3))\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.40.2->-r requirements.txt (line 3))\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.40.2->-r requirements.txt (line 3))\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.40.2->-r requirements.txt (line 3))\n",
      "  Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.2->-r requirements.txt (line 3))\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.40.2->-r requirements.txt (line 3))\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.40.2->-r requirements.txt (line 3))\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.4.0 (from trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting accelerate (from trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets (from trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tyro>=0.5.11 (from trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading tyro-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn==1.5.2->-r requirements.txt (line 5))\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn==1.5.2->-r requirements.txt (line 5))\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.5.2->-r requirements.txt (line 5))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.9.2->-r requirements.txt (line 6))\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.9.2->-r requirements.txt (line 6))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.9.2->-r requirements.txt (line 6))\n",
      "  Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.9.2->-r requirements.txt (line 6))\n",
      "  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib==3.9.2->-r requirements.txt (line 6))\n",
      "  Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.9.2->-r requirements.txt (line 6))\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib==3.9.2->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Collecting dill (from evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting xxhash (from evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading multiprocess-0.70.18-py310-none-any.whl.metadata (7.5 kB)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests==2.32.5->-r requirements.txt (line 9))\n",
      "  Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests==2.32.5->-r requirements.txt (line 9))\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests==2.32.5->-r requirements.txt (line 9))\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests==2.32.5->-r requirements.txt (line 9))\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2->-r requirements.txt (line 3)) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2->-r requirements.txt (line 3))\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting httpx<1.0.0 (from datasets->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2021.05.0->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting anyio (from httpx<1.0.0->datasets->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (0.8.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.29.5->-r requirements.txt (line 1)) (4.5.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.9.2->-r requirements.txt (line 6)) (1.17.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting docstring-parser>=0.15 (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.4.0->trl==0.11.4->-r requirements.txt (line 4))\n",
      "  Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->evaluate==0.4.3->-r requirements.txt (line 7))\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.29.5->-r requirements.txt (line 1)) (0.2.3)\n",
      "Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.11.4-py3-none-any.whl (316 kB)\n",
      "Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Downloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading multiprocess-0.70.18-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (47.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.3/770.3 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m791.7/791.7 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m  \u001b[33m0:01:23\u001b[0m6m0:00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m  \u001b[33m0:00:54\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m  \u001b[33m0:01:05\u001b[0m6m0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:17\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:24\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m  \u001b[33m0:00:26\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m  \u001b[33m0:00:26\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m  \u001b[33m0:00:29\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.3/170.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:15\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading tyro-1.0.1-py3-none-any.whl (179 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)\n",
      "Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: pytz, nvidia-cusparselt-cu12, mpmath, xxhash, widgetsnbextension, urllib3, tzdata, typeguard, triton, tqdm, threadpoolctl, sympy, safetensors, regex, pyyaml, pyparsing, pyarrow, propcache, pillow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, MarkupSafe, kiwisolver, jupyterlab-widgets, joblib, idna, hf-xet, h11, fsspec, frozenlist, fonttools, filelock, docstring-parser, dill, cycler, charset_normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, tyro, scipy, requests, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, jinja2, httpcore, contourpy, anyio, aiosignal, scikit-learn, nvidia-cusolver-cu12, matplotlib, ipywidgets, ipykernel, huggingface-hub, httpx, aiohttp, torch, tokenizers, transformers, datasets, accelerate, trl, peft, evaluate\n",
      "\u001b[2K  Attempting uninstall: ipykernel━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m68/81\u001b[0m [ipywidgets]lver-cu12]2]\n",
      "\u001b[2K    Found existing installation: ipykernel 7.1.0[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m68/81\u001b[0m [ipywidgets]\n",
      "\u001b[2K    Uninstalling ipykernel-7.1.0:━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m68/81\u001b[0m [ipywidgets]\n",
      "\u001b[2K      Successfully uninstalled ipykernel-7.1.0\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m69/81\u001b[0m [ipykernel]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81/81\u001b[0m [evaluate]evaluate]trl]lerate]s]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 anyio-4.12.0 async-timeout-5.0.1 attrs-25.4.0 certifi-2025.11.12 charset_normalizer-3.4.4 contourpy-1.3.2 cycler-0.12.1 datasets-4.4.1 dill-0.4.0 docstring-parser-0.17.0 evaluate-0.4.3 filelock-3.20.0 fonttools-4.61.1 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 idna-3.11 ipykernel-6.29.5 ipywidgets-8.1.5 jinja2-3.1.6 joblib-1.5.3 jupyterlab-widgets-3.0.16 kiwisolver-1.4.9 matplotlib-3.9.2 mpmath-1.3.0 multidict-6.7.0 multiprocess-0.70.18 networkx-3.4.2 numpy-1.26.4 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pandas-2.3.3 peft-0.13.2 pillow-12.0.0 propcache-0.4.1 pyarrow-22.0.0 pyparsing-3.2.5 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 scikit-learn-1.5.2 scipy-1.15.3 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.19.1 torch-2.9.1 tqdm-4.67.1 transformers-4.40.2 triton-3.5.1 trl-0.11.4 typeguard-4.4.4 tyro-1.0.1 tzdata-2025.3 urllib3-2.6.2 widgetsnbextension-4.0.15 xxhash-3.6.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt"
=======
   "outputs": [],
   "source": [
    "# !pip install --no-cache-dir torch==2.9.1+cu128 --index-url https://download.pytorch.org/whl/cu128\n",
    "# !pip install --no-cache-dir -r requirements.txt"
>>>>>>> 36b13efda00c70c26be40923e51acacf8d15453e
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /opt/conda/lib/python3.10/site-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from ast import literal_eval\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM, SFTConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import evaluate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 고정\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "set_seed(42) # magic number :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the train dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# TODO Train Data 경로 입력\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Flatten the JSON dataset\u001b[39;00m\n\u001b[1;32m      6\u001b[0m records \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/data/ephemeral/pro-nlp-generationfornlp-nlp-13/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/ephemeral/pro-nlp-generationfornlp-nlp-13/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/data/ephemeral/pro-nlp-generationfornlp-nlp-13/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/ephemeral/pro-nlp-generationfornlp-nlp-13/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/data/ephemeral/pro-nlp-generationfornlp-nlp-13/.venv/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "# Load the train dataset\n",
    "# TODO Train Data 경로 입력\n",
    "dataset = pd.read_csv('train.csv') \n",
    "\n",
    "# Flatten the JSON dataset\n",
    "records = []\n",
    "for _, row in dataset.iterrows():\n",
    "    problems = literal_eval(row['problems'])\n",
    "    record = {\n",
    "        'id': row['id'],\n",
    "        'paragraph': row['paragraph'],\n",
    "        'question': problems['question'],\n",
    "        'choices': problems['choices'],\n",
    "        'answer': problems.get('answer', None),\n",
    "        \"question_plus\": problems.get('question_plus', None),\n",
    "    }\n",
    "    # Include 'question_plus' if it exists\n",
    "    if 'question_plus' in problems:\n",
    "        record['question_plus'] = problems['question_plus']\n",
    "    records.append(record)\n",
    "        \n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on 'question' and 'choices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'question' and 'question_plus' if available\n",
    "df['question_plus'] = df['question_plus'].fillna('')\n",
    "df['full_question'] = df.apply(lambda x: x['question'] + ' ' + x['question_plus'] if x['question_plus'] else x['question'], axis=1)\n",
    "\n",
    "# Calculate the length of each question\n",
    "df['question_length'] = df['full_question'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(df['question_length'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Question Lengths')\n",
    "plt.xlabel('Question Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering using TF-IDF\n",
    "\n",
    "- TF-IDF 참고 링크: https://ko.wikipedia.org/wiki/Tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and transform the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['full_question'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTF-IDF Features:\")\n",
    "display(tfidf_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "- https://huggingface.co/beomi/gemma-ko-2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 본인의 Huggingface auth token 입력\n",
    "## Jupyter lab에서 로그인 하는 textbox가 나오지 않을 경우, terminal에서 로그인 하실 수 있습니다.\n",
    "# !huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델과 토크나이저를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"beomi/gemma-ko-2b\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"beomi/gemma-ko-2b\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gemma-ko-2b 모델에는 chat template 이 없기 때문에 직접 입력해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = \"{% if messages[0]['role'] == 'system' %}{% set system_message = messages[0]['content'] %}{% endif %}{% if system_message is defined %}{{ system_message }}{% endif %}{% for message in messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<start_of_turn>user\\n' + content + '<end_of_turn>\\n<start_of_turn>model\\n' }}{% elif message['role'] == 'assistant' %}{{ content + '<end_of_turn>\\n' }}{% endif %}{% endfor %}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = \"{% if messages[0]['role'] == 'system' %}{% set system_message = messages[0]['content'] %}{% endif %}{% if system_message is defined %}{{ system_message }}{% endif %}{% for message in messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<start_of_turn>user\\n' + content + '<end_of_turn>\\n<start_of_turn>model\\n' }}{% elif message['role'] == 'assistant' %}{{ content + '<end_of_turn>\\n' }}{% endif %}{% endfor %}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=6,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=['q_proj', 'k_proj'],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_NO_QUESTION_PLUS = \"\"\"지문:\n",
    "{paragraph}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "선택지:\n",
    "{choices}\n",
    "\n",
    "1, 2, 3, 4, 5 중에 하나를 정답으로 고르세요.\n",
    "정답:\"\"\"\n",
    "\n",
    "PROMPT_QUESTION_PLUS = \"\"\"지문:\n",
    "{paragraph}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "<보기>:\n",
    "{question_plus}\n",
    "\n",
    "선택지:\n",
    "{choices}\n",
    "\n",
    "1, 2, 3, 4, 5 중에 하나를 정답으로 고르세요.\n",
    "정답:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = []\n",
    "for i in range(len(dataset)):\n",
    "    choices_string = \"\\n\".join([f\"{idx + 1} - {choice}\" for idx, choice in enumerate(dataset[i][\"choices\"])])\n",
    "\n",
    "    # <보기>가 있을 때\n",
    "    if dataset[i][\"question_plus\"]:\n",
    "        user_message = PROMPT_QUESTION_PLUS.format(\n",
    "            paragraph=dataset[i][\"paragraph\"],\n",
    "            question=dataset[i][\"question\"],\n",
    "            question_plus=dataset[i][\"question_plus\"],\n",
    "            choices=choices_string,\n",
    "        )\n",
    "    # <보기>가 없을 때\n",
    "    else:\n",
    "        user_message = PROMPT_NO_QUESTION_PLUS.format(\n",
    "            paragraph=dataset[i][\"paragraph\"],\n",
    "            question=dataset[i][\"question\"],\n",
    "            choices=choices_string,\n",
    "        )\n",
    "\n",
    "    # chat message 형식으로 변환\n",
    "    processed_dataset.append(\n",
    "        {\n",
    "            \"id\": dataset[i][\"id\"],\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"지문을 읽고 질문의 답을 구하세요.\"},\n",
    "                {\"role\": \"user\", \"content\": user_message},\n",
    "                {\"role\": \"assistant\", \"content\": f\"{dataset[i]['answer']}\"}\n",
    "            ],\n",
    "            \"label\": dataset[i][\"answer\"],\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = Dataset.from_pandas(pd.DataFrame(processed_dataset))\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example[\"messages\"])):\n",
    "        output_texts.append(\n",
    "            tokenizer.apply_chat_template(\n",
    "                example[\"messages\"][i],\n",
    "                tokenize=False,\n",
    "            )\n",
    "        )\n",
    "    return output_texts\n",
    "\n",
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        formatting_prompts_func(element),\n",
    "        truncation=False,\n",
    "        padding=False,\n",
    "        return_overflowing_tokens=False,\n",
    "        return_length=False,\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": outputs[\"input_ids\"],\n",
    "        \"attention_mask\": outputs[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "# 데이터 토큰화\n",
    "tokenized_dataset = processed_dataset.map(\n",
    "    tokenize,\n",
    "    remove_columns=list(processed_dataset.features),\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Tokenizing\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "# vram memory 제약으로 인해 인풋 데이터의 길이가 1024 초과인 데이터는 제외하였습니다. *힌트: 1024보다 길이가 더 긴 데이터를 포함하면 더 높은 점수를 달성할 수 있을 것 같습니다!\n",
    "tokenized_dataset = tokenized_dataset.filter(lambda x: len(x[\"input_ids\"]) <= 1024)  \n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "train_dataset = tokenized_dataset['train']\n",
    "eval_dataset = tokenized_dataset['test']\n",
    "# 데이터 확인\n",
    "print(tokenizer.decode(train_dataset[0][\"input_ids\"], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(train_dataset[0][\"input_ids\"], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_token_lengths = [len(train_dataset[i][\"input_ids\"]) for i in range(len(train_dataset))]\n",
    "print(f\"max token length: {max(train_dataset_token_lengths)}\")\n",
    "print(f\"min token length: {min(train_dataset_token_lengths)}\")\n",
    "print(f\"avg token length: {np.mean(train_dataset_token_lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completion 부분만 학습하기 위한 data collator 설정\n",
    "\n",
    "- 텍스트 중 response_template 까지는 ignore_index 로 loss 계산에서 제외\n",
    "- 텍스트 중 response_template 이후는 학습에 포함 (정답 + eos 토큰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_template = \"<start_of_turn>model\"\n",
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template=response_template,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 logits 를 조정하여 정답 토큰 부분만 출력하도록 설정\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    logits = logits if not isinstance(logits, tuple) else logits[0]\n",
    "    logit_idx = [tokenizer.vocab[\"1\"], tokenizer.vocab[\"2\"], tokenizer.vocab[\"3\"], tokenizer.vocab[\"4\"], tokenizer.vocab[\"5\"]]\n",
    "    logits = logits[:, -2, logit_idx] # -2: answer token, -1: eos token\n",
    "    return logits\n",
    "\n",
    "# metric 로드\n",
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# 정답 토큰 매핑\n",
    "int_output_map = {\"1\": 0, \"2\": 1, \"3\": 2, \"4\": 3, \"5\": 4}\n",
    "\n",
    "# metric 계산 함수\n",
    "def compute_metrics(evaluation_result):\n",
    "    logits, labels = evaluation_result\n",
    "\n",
    "    # 토큰화된 레이블 디코딩\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    labels = list(map(lambda x: x.split(\"<end_of_turn>\")[0].strip(), labels))\n",
    "    labels = list(map(lambda x: int_output_map[x], labels))\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 로그트 변환\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1)\n",
    "    predictions = np.argmax(probs, axis=-1)\n",
    "\n",
    "    # 정확도 계산\n",
    "    acc = acc_metric.compute(predictions=predictions, references=labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad token 설정\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_seq_length=1024,\n",
    "    output_dir=\"outputs_gemma\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    save_only_model=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    peft_config=peft_config,\n",
    "    args=sft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 학습된 Checkpoint 경로 입력\n",
    "checkpoint_path = \"outputs_gemma/checkpoint-4491\"\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    checkpoint_path,\n",
    "    trust_remote_code=True,\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    checkpoint_path,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "# TODO Test Data 경로 입력\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Flatten the JSON dataset\n",
    "records = []\n",
    "for _, row in test_df.iterrows():\n",
    "    problems = literal_eval(row['problems'])\n",
    "    record = {\n",
    "        'id': row['id'],\n",
    "        'paragraph': row['paragraph'],\n",
    "        'question': problems['question'],\n",
    "        'choices': problems['choices'],\n",
    "        'answer': problems.get('answer', None),\n",
    "        \"question_plus\": problems.get('question_plus', None),\n",
    "    }\n",
    "    # Include 'question_plus' if it exists\n",
    "    if 'question_plus' in problems:\n",
    "        record['question_plus'] = problems['question_plus']\n",
    "    records.append(record)\n",
    "        \n",
    "# Convert to DataFrame\n",
    "test_df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "for i, row in test_df.iterrows():\n",
    "    choices_string = \"\\n\".join([f\"{idx + 1} - {choice}\" for idx, choice in enumerate(row[\"choices\"])])\n",
    "    len_choices = len(row[\"choices\"])\n",
    "    \n",
    "    # <보기>가 있을 때\n",
    "    if row[\"question_plus\"]:\n",
    "        user_message = PROMPT_QUESTION_PLUS.format(\n",
    "            paragraph=row[\"paragraph\"],\n",
    "            question=row[\"question\"],\n",
    "            question_plus=row[\"question_plus\"],\n",
    "            choices=choices_string,\n",
    "        )\n",
    "    # <보기>가 없을 때\n",
    "    else:\n",
    "        user_message = PROMPT_NO_QUESTION_PLUS.format(\n",
    "            paragraph=row[\"paragraph\"],\n",
    "            question=row[\"question\"],\n",
    "            choices=choices_string,\n",
    "        )\n",
    "\n",
    "    test_dataset.append(\n",
    "        {\n",
    "            \"id\": row[\"id\"],\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"지문을 읽고 질문의 답을 구하세요.\"},\n",
    "                {\"role\": \"user\", \"content\": user_message},\n",
    "            ],\n",
    "            \"label\": row[\"answer\"],\n",
    "            \"len_choices\": len_choices,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "infer_results = []\n",
    "\n",
    "pred_choices_map = {0: \"1\", 1: \"2\", 2: \"3\", 3: \"4\", 4: \"5\"}\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for data in tqdm(test_dataset):\n",
    "        _id = data[\"id\"]\n",
    "        messages = data[\"messages\"]\n",
    "        len_choices = data[\"len_choices\"]\n",
    "\n",
    "        outputs = model(\n",
    "            tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=True,\n",
    "                add_generation_prompt=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(\"cuda\")\n",
    "        )\n",
    "\n",
    "        logits = outputs.logits[:, -1].flatten().cpu()\n",
    "\n",
    "        target_logit_list = [logits[tokenizer.vocab[str(i + 1)]] for i in range(len_choices)]\n",
    "\n",
    "        probs = (\n",
    "            torch.nn.functional.softmax(\n",
    "                torch.tensor(target_logit_list, dtype=torch.float32)\n",
    "            )\n",
    "            .detach()\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "\n",
    "        predict_value = pred_choices_map[np.argmax(probs, axis=-1)]\n",
    "        infer_results.append({\"id\": _id, \"answer\": predict_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(infer_results).to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(infer_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
