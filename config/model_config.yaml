model:
  # 4지선다(지식형) 특화 설정
  knowledge_model:
    base_model: "beomi/gemma-ko-2b"
    torch_dtype: "float16"
    device_map: "auto"

  # 5지선다(독해형) 특화 설정
  inferential:
    base_model: "beomi/gemma-ko-2b"
    torch_dtype: "float16"
    device_map: "auto"
  
lora:
  # 공통 설정
  default:
    r: 6
    lora_alpha: 8
    lora_dropout: 0.05
    target_modules: ["q_proj", "k_proj"]
    bias: "none"
    task_type: "CAUSAL_LM"
  
  # 4지선다(지식형) 특화 설정
  knowledge:
    r: 6
    lora_alpha: 8
    lora_dropout: 0.05
    target_modules: ["q_proj", "k_proj"]
    bias: "none"
    task_type: "CAUSAL_LM"
  
  # 5지선다(독해형) 특화 설정
  inferential:
    r: 6
    lora_alpha: 8
    lora_dropout: 0.05
    target_modules: ["q_proj", "k_proj"]
    bias: "none"
    task_type: "CAUSAL_LM"